## MySQL 的存储引擎

### InnoDB

InnoDB 是通用的存储引擎，在 MySQL 5.6 后作为默认的存储引擎

- 支持 ACID 事务，默认为可重读的事务级别
- 外键
- 行级锁
- 通过 MVCC 实现高并发
- 在磁盘中聚集存储，根据主键进行顺序存储

### MyISAM

MyISAM 在 MySQL 5.5.8 前作为默认的存储引擎

- 不支持事务
- 表级锁
- 支持全文索引
- 缓存索引而非数据

## 连接 MySQL

MySQL 的数据库连接是一个通信进程和数据库实例之间的通信，本质上是进程间通信：

- TCP/IP
- 命名管道和共享内存/Unix 域套接字：通信进程需要在一台服务器上

## InnoDB 体系架构

InnoDB 引擎有多个内存块，这些内存块组成了一个大的内存池，用于作为引擎和磁盘之的缓存(缓存频繁读取的数据与需要写入磁盘的脏数据)

### 后台线程

InnoDB 是多线程架构：

- Master Thread：核心线程，负责将缓冲池的数据写回磁盘，保证数据一致性
  - 脏页刷新
  - Undo Page 回收
  - 合并插入缓存
- IO Thread：InnoDB 使用大量的 AIO 处理写 IO 请求，IO Thread 用于负责 AIO 的回调处理
- Purge Thread：在事务提交后，undolog 不再被需要，Purge Thread 就是用于回收已使用并分配的 Undo Page
- Page Cleaner Thread：负责脏页刷新操作，减轻主线程负担

### 内存

#### 缓冲池

InnoDB 是基于磁盘的数据库系统，将数据以页为单位在磁盘存储与管理，为了平衡 CPU 与磁盘的性能差异，InnoDB 在内存中维护一个内存池作为缓冲

当需要读取数据时，CPU 会先从缓冲池中读取，如果没有命中则从磁盘读取并将数据 FIX 在缓冲池

修改数据时也是先对缓冲池中的数据进行修改，在到达 checkpoint 后再统一写回磁盘

### LRU List、Free List  和 Flush List

缓冲池中对数据使用 LRU List 进行维护，将最频繁访问的数据放在队列头部，而最少使用的数据在尾部。因为在全表搜索的情况下，将最近读取的数据放在头部会影响性能(读入的大部分数据都只用一次)，所以 InnoDB 会将新数据插入 LRU List 的 midpoint 位置(在 LRU List 的 5/8 处，由 innodb_old_blocks_pct 控制)

Free List 用于记录缓存池中的空闲页面，当要将数据从磁盘读到缓冲池时，会先从 Free List 中尝试获取可用的空闲页，再将该页移出 Free List 并加入 LRU List；从 LRU List 淘汰的数据页也会被清空后加入 Free List

Flush List 会记录被修改的数据(脏页)，脏页可以同时存在于 LRU List 和 Flush List，并在 checkpoint 节点写回磁盘(Master Thread / Page Cleaner Thread)

#### 重做日志缓存

InnoDB 会先将 redo log 写入缓存池中的 redo log buffer，再写回磁盘：

- Master Thread 按每秒一次写回磁盘
- 事务提交后
- redo log buffer 容量不足

#### Checkpoint

缓冲池用于平衡 CPU 与磁盘之间的性能差距，但何时将数据从内存持久化到磁盘还需要考虑，InnoDB 使用 checkpoint 来定义一个检查点，表示再次之前的数据修改都被持久化，以解决以下问题：

- redo log 恢复时间长
  - 在 checkpoint 之前的数据都已经被写回磁盘，所以在恢复数据时只需要执行 checkpoint 后的 redo log 即可
- redo log 不可用
  - redo log 是一种环形结构，过期的 redo log 会被新的取代，当 redo log 被重用时必须产生 checkpoint 确保被覆盖的 redo log 不再被需要
- 缓冲池不够用，将脏页写回磁盘
  - 写回磁盘时必须触发 checkpoint

InnoDB 使用 LSN(Log Sequence Number) 来标记 redo log 和 checkpoint 版本，所有小于 LSN checkpoint 的 redo log 都已经写回磁盘

- Sharp Checkpoint：在数据库关闭前进行的将脏页全量写回磁盘，会阻塞主线程
- Fuzzy Checkpoint：部分写回，对系统可用性影响小
  - Master Thread 定期写回
  - 缓冲池不足
  - redo log buffer 空间不足

### Master Thread

Master Thread 具有最高线程优先级，内部由四个循环组成：

- Loop：主循环，分为每秒和每十秒执行的操作，通过 Thread.sleep() 实现，所以时间间隔不一定准确
  - 每秒：
    - 将缓冲池中的日志写回磁盘，即使事务未提交(总是)
    - 合并插入缓存
    - 刷新缓冲池中的脏页
    - 如果当前没有用户活动，切换至 Backgroud Loop
  - 每十秒：
    - 合并插入缓存(总是)
    - 写回日志和脏页(总是)
    - 回收 Undo Page(总是)
- Background Loop：当前没有用户活动或数据库关闭
  - 合并插入缓存
  - 回收 Undo Page
  - 跳回主循环
- Flush Loop：刷新页
- Suspend Loop：挂起主线程，等待事件发生

### 插入缓存

通常行记录的插入顺序是按照主键递增的顺序进行插入的(UUID 等非自增的是随机的)，所以插入聚集索引一般是顺序的，不需要磁盘的随机读取

但一个表还会有多个非聚集的辅助索引，它们的插入不是顺序的(B+ 树的特性)，这时需要通过离散访问非聚集索引页，由此产生的磁盘随机读会影响操作性能

Insert Buffer 就是为了提高非聚集索引插入的性能，当需要插入非聚集索引时，InnoDB 先判断需要插入的非聚集索引页是否在缓冲池中，如果不在则先放入到一个 Insert Buffer 对象中，之后再将 Insert Buffer 和辅助索引页子节点合并

Insert Buffer 的使用需要同时满足：

- 非聚集索引
- 不唯一：插入缓冲时，如果索引唯一，数据库还需要查找索引页来判断插入记录的唯一性，导致离散读的情况发生，这就令避免离散读的 Insert Buffer 失去意义

#### Change Buffer

Insert Buffer 的升级版，对所有修改数据的 DML 都进行缓冲(update insert delete)：

- Insert Buffer
- Delete Buffer：将记录标记删除
- Purge Buffer：真正删除记录

#### Insert Buffer 内部实现

Insert Buffer 的底层结构是一个 B+ 树，它的中间节点存储辅助索引的 key，叶子节点存储辅助索引的值：

- key：mark + space + offset
  - mark：兼容老版本的 Insert Buffer
  - space：辅助索引所在表的表空间 id
  - offset：页所在的偏移量
- value：mark + space + offset + metadata + secondary index record

当一个辅助索引要插入到页时，如果该页不在缓冲池，InnoDB 会先构造一个 search key，再查询 Insert Buffer 的 B+ 树，将记录插入到叶节点中

#### Merge Insert Buffer

插入缓冲与辅助索引页合并的时机：

- 用户查询相关数据，辅助页被读入缓冲区
- 辅助索引页大小不足，避免页分裂造成更大的开销
- 主线程

### Double Write

两次写主要用来保证 InnoDB 的可用性，虽然 redo log 可以在 InnoDB 宕机后对页进行数据恢复，但如果需要恢复的页本身已损坏时再对其进行重做是没有意义的

页损坏：因为 InnoDB 的页大小(16 KB)与磁盘物理页大小(4 KB)不匹配，即一个 InnoDB 页可能需要多个磁盘物理页，当脏页从缓冲区刷回磁盘时，可能在部分页写回后宕机，导致页部分更新，而 redo log 记录的是脏页的变化量，无法判断应该基于那个部分来进行还原，所以无法使用 redo log 进行页重做

double write 通过对页进行备份，当页损坏时可以直接从备份中进行恢复后再重做

double write 分为三步：

1. 内存中的脏页会写入内存中的 double write buffer
2. double write buffer 会先将脏页写入共享表空间(ibdata)的物理磁盘，这一步为顺序写入
3. 之后立即通过 fsync 将页同步到 InnoDB 的数据空间中(.idb 文件)，这一步为随机写入

### 自适应哈希

InnoDB 会监控对表上各个索引页的查询，如果发现可以建立哈希索引来提高性能，则建立哈希索引

AHI 通过缓冲池的 B+ 树构造而来，所以建立的速度很快，而且不需要对整个表建立索引，InnoDB 会根据访问的频率和模式自动为热点数据建立哈希索引

AHI 有一个要求，对索引数据的访问模式必须一致，如对于 (a, b) 这样的联合索引，如果交替查询 a = xxx 和 a = xxx and b = xxx 时则不会建立索引

### 异步 IO

InnoDB 采用 AIO 处理磁盘操作，不需要等待 IO 请求返回响应即可处理下一个请求，还可以将多个 IO 请求合并提交(请求同一个或相邻的页)

### 启动、关闭与恢复

在关闭时，innodb_fast_shutdown 管理关闭前的行为，参数默认为 1：

- 0：在关闭前必须将缓冲区所有脏页写回磁盘，完成所有的 full purge 和 merge insert buffer，可能耗费大量时间
- 1：只写回脏页
- 2：不写回脏页，不完成 full purge 和 merge insert buffer，只写入日志并在启动时进行恢复

参数 innodb_force_recovery 影响了 InnoDB 异常关闭后重启时的恢复操作，默认为 0：

- 0：进行所有的恢复操作，当出现页损坏等无法恢复的情况时，中止启动并将错误信息写入日志
- 1：忽略检查到的损坏页
- 2：阻止 Master Thread 运行
- 3：不进行事务回滚
- 4：不进行插入缓存的合并操作
- 5：不查看 undo log，将所有的事务视为已提交
- 6：不进行前滚操作

在设置了 innodb_force_recovery > 0 后，可以进行 create、drop、select 等操作，但不允许 insert、update、delete 等 DML

## 文件

### 参数文件

告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置，还会介绍各种参数的类型。

### 日志文件

#### 错误日志

错误日志文件对MySQL的启动、运行、关闭过程进行了记录。该文件不仅记录了所有的错误信息，也记录一些警告信息或正确的信息。用户可以通过命令SHOW VARIABLES LIKE 'log_error'来定位该文件

#### 慢查询日志

慢查询日志（slow log）可帮助DBA定位可能存在问题的SQL语句，从而进行SQL语句层面的优化。例如，可以在MySQL启动时设一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询日志文件中。DBA每天或每过一段时间对其进行检查，确认是否有SQL语句需要进行优化。该阈值可以通过参数long_query_time来设置，默认值为10，代表10秒。

mysqldumpslow命令可以用于分析慢日志中大量的 SQL 查询

#### 查询日志

查询日志记录了所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行。

#### 二进制日志

二进制日志（binary log）记录了对MySQL数据库执行更改的所有操作(bin log 隶属于 MySQL 而非 InnoDB)，它的主要作用：

- 恢复：某些数据需要 bin log 进行恢复，可以实现精确到时间点的恢复(point-in-time)
- 复制：通过复制和执行 bin log 可以实现数据库的复制(主从同步)
- 审计

bin log 在默认情况下会先写入缓冲区，在写入 N 条后再写回磁盘中的二进制日志，sync_binlog = N 表示写入 N 条：

- N 默认为 0，表示由操作系统决定何时调用 fsync 来写回磁盘
- 当 N = 1 时表示同步写，即不使用缓冲直接写入磁盘，虽然能够提高可用性(防止宕机导致缓存丢失)，但可能出现执行事务时，修改写入磁盘的 bin log，但在 commit 前宕机，在恢复时事务因为没提交而需要回滚，但修改已经写入 bin log 又不能回滚。这个问题可以通过将参数innodb_support_xa设为1来解决，虽然innodb_support_xa与XA事务有关，但它同时也确保了二进制日志和InnoDB存储引擎数据文件的同步。

binlog_format参数十分重要，它影响了记录二进制日志的格式。该参数可设的值有STATEMENT、ROW和MIXED：

- STATEMENT：二进制日志文件记录的是日志的逻辑SQL语句。对于复制是有一定要求的。如在主服务器运行rand、uuid等函数，又或者使用触发器等操作，这些都可能会导致主从服务器上表中数据的不一致（not sync）。另一个影响是，会发现InnoDB存储引擎的默认事务隔离级别是REPEATABLE READ。这其实也是因为二进制日志文件格式的关系，如果使用READ COMMITTED的事务隔离级别（大多数数据库，如Oracle，Microsoft SQL Server数据库的默认隔离级别），会出现类似丢失更新的现象，从而出现主从数据库上的数据不一致。

- ROW：记录表的行更改情况。可以为数据库的恢复和复制带来更好的可靠性。但是不能忽略的一点是，这会带来二进制文件大小的增加，有些语句下的ROW格式可能需要更大的容量。

- MIXED：MySQL默认采用STATEMENT格式进行二进制日志文件的记录，但是在一些情况下会使用ROW格式，可能的情况有：
  1）表的存储引擎为NDB，这时对表的DML操作都会以ROW格式记录。
  2）使用了UUID()、USER()、CURRENT_USER()、FOUND_ROWS()、ROW_COUNT()等不确定函数。
  3）使用了INSERT DELAY语句。
  4）使用了用户定义函数（UDF）。
  5）使用了临时表（temporary table）。

二进制日志文件的文件格式为二进制，不能像错误日志文件、慢查询日志文件那样用cat、head、tail等命令来查看。要查看二进制日志文件的内容，必须通过MySQL提供的工具mysqlbinlog。

### Socket 文件

在UNIX系统下本地连接MySQL可以采用UNIX域套接字方式，这种方式需要一个套接字（socket）文件。套接字文件可由参数socket控制。

### pid 文件

当MySQL实例启动时，会将自己的进程ID写入一个文件中——该文件即为pid文件。该文件可由参数pid_file控制，默认位于数据库目录下

### 表结构定义文件

MySQL数据的存储是根据表进行的，每个表都会有与之对应的文件。但不论表采用何种存储引擎，MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。

### InnoDB存储引擎文件

#### 表空间文件

InnoDB采用将存储的数据按表空间（tablespace）进行存放的设计。在默认配置下会有一个初始大小为10MB，名为ibdata1的文件。

设置innodb_data_file_path参数后，所有基于InnoDB存储引擎的表的数据都会记录到该共享表空间中。若设置了参数innodb_file_per_table，则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。这些单独的表空间文件仅存储该表的数据、索引和插入缓冲BITMAP等信息，其余信息还是存放在默认的表空间中。

#### 重做日志文件

每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组下至少有2个重做日志文件，如默认的ib_logfile0和ib_logfile1。为了得到更高的可靠性，用户可以设置多个的镜像日志组（mirrored log groups），将不同的文件组放在不同的磁盘上，以此提高重做日志的高可用性。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。InnoDB存储引擎先写重做日志文件1，当达到文件的最后时，会切换至重做日志文件2，再当重做日志文件2也被写满时，会再切换到重做日志文件1中。

重做日志文件的大小设置对于InnoDB存储引擎的性能有着非常大的影响。一方面重做日志文件不能设置得太大，如果设置得很大，在恢复时可能需要很长的时间；另一方面又不能设置得太小了，否则可能导致一个事务的日志需要多次切换重做日志文件。此外，重做日志文件太小会导致频繁地发生async checkpoint，导致性能的抖动。

redo log vs bin log：

- 隶属不同：二进制日志会记录所有与MySQL数据库有关的日志记录，包括InnoDB、MyISAM、Heap等其他存储引擎的日志。而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。
- 记录的内容不同：无论用户将二进制日志文件记录的格式设为STATEMENT还是ROW，又或者是MIXED，其记录的都是关于一个事务的具体操作内容，即该日志是逻辑日志。而InnoDB存储引擎的重做日志文件记录的是关于每个页（Page）的更改的物理情况。
- 写入的时间不同：二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大。而在事务进行的过程中，却不断有重做日志条目（redo entry）被写入到重做日志文件中。

写入重做日志文件的操作不是直接写，而是先写入一个重做日志缓冲（redo log buffer）中，然后按照一定的条件顺序地写入日志文件。从重做日志缓冲往磁盘写入时，是按512个字节，也就是一个扇区的大小进行写入。因为扇区是写入的最小单位，因此可以保证写入必定是成功的。因此在重做日志的写入过程中不需要有doublewrite。

## 表

表就是关于特定实体的数据集合，这也是关系型数据库模型的核心。

### 索引组织表

在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。

### InnoDB逻辑存储结构

- 表空间：表空间可以看做是InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。
  - 如果启用了innodb_file_per_table的参数，需要注意的是每张表的表空间内存放的只是数据、索引和插入缓冲Bitmap页，其他类的数据，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲（Double write buffer）等还是存放在原来的共享表空间内。
  - InnoDB存储引擎不会在执行rollback时去收缩共享表空间。虽然InnoDB不会回收这些空间，但是会自动判断这些undo信息是否还需要，如果不需要，则会将这些空间标记为可用空间，供下次undo使用。
- 段：表空间是由各个段组成的，常见的段有数据段、索引段、回滚段等。
  - InnoDB存储引擎表是索引组织的（index organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点，索引段即为B+树的非叶子节点。
- 区：区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。
  - 在每个段开始时，先用32个页大小的碎片页（fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请。这样做的目的是，对于一些小表，或者是undo这类的段，可以在开始时申请较少的空间，节省磁盘容量的开销。
- 页：页是InnoDB磁盘管理的最小单位。在InnoDB存储引擎中，默认每个页的大小为16KB。
  - 若设置完成，则所有表中页的大小都为innodb_page_size，不可以对其再次进行修改。除非通过mysqldump导入和导出操作来产生新的库。
- 行：InnoDB存储引擎是面向行的（row-oriented），也就说数据是按行进行存放的。每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200行的记录，即7992行记录。

### InnoDB行记录格式

- Compact：Compact行记录是在MySQL 5.0中引入的，其设计目标是高效地存储数据。简单来说，一个页中存放的行数据越多，其性能就越高。
  - 变长字段长度列表：按照列的顺序逆序放置的
  - NULL 标志位：指示该行是否存在 NULL 值，NULL不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间
  - 记录头信息
  - 实际存储的每个列数据
- Redundant：对于VARCHAR类型的NULL值，Redundant行记录格式同样不占用任何存储空间，而CHAR类型的NULL值需要占用空间。
  - 字段长度偏移列表
  - 记录头信息
  - 实际存储的每个列数据
- Compressed：对于存放在BLOB中的数据采用了完全的行溢出的方式，在数据页中只存放20个字节的指针，实际的数据都存放在Off Page中。存储在其中的行数据会以zlib的算法进行压缩，因此对于BLOB、TEXT、VARCHAR这类大长度类型的数据能够进行非常有效的存储。
- Dynamic

### 行溢出数据

InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外，在一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node中。但是当发生行溢出时，数据存放在页类型为Uncompress BLOB页中。

B-tree node数据页面其实只保存了VARCHAR（65532）的前768字节的前缀（prefix）数据（这里都是a），之后是偏移量，指向行溢出页，也就是Uncompressed BLOB Page。

InnoDB存储引擎表是索引组织的，即B+Tree的结构，这样每个页中至少应该有两条行记录（否则失去了B+Tree的意义，变成链表了，因为 MySQL 从磁盘读取的最小单位为页，如果每页只存储一行记录，则查询 n 条数据就要读取 n 页）。因此，如果页中只能存放下一条记录，那么InnoDB存储引擎会自动将行数据存放到溢出页中。

### InnoDB数据页结构

InnoDB数据页由以下7个部分组成：

❑File Header（文件头）：用来记录页的一些头信息

❑Page Header（页头）：用来记录数据页的状态信息

❑Infimun和Supremum Records：每个数据页中有两个虚拟的行记录，用来限定记录的边界。Infimum记录是比该页中任何主键值都要小的值，Supremum指比任何可能大的值还要大的值。这两个值在页创建时被建立，并且在任何情况下不会被删除。

❑User Records（用户记录，即行记录）：实际存储行记录的内容

❑Free Space（空闲空间）：空闲空间，同样也是个链表数据结构。在一条记录被删除后，该空间会被加入到空闲链表中。

❑Page Directory（页目录）：存放了记录的相对位置（注意，这里存放的是页相对位置，而不是偏移量），有些时候这些记录指针称为Slots（槽）或目录槽（Directory Slots）。与其他数据库系统不同的是，在InnoDB中并不是每个记录拥有一个槽，InnoDB存储引擎的槽是一个稀疏目录（sparse directory），即一个槽中可能包含多个记录(n_owned)。

​    ❑B+树索引本身并不能找到具体的一条记录，能找到只是该记录所在的页。数据库把页载入到内存，然后通过Page Directory再进行二叉查找。

❑File Trailer（文件结尾信息）：为了检测页是否已经完整地写入磁盘

### 约束

#### 数据完整性

关系数据库本身能保证存储数据的完整性，不需要应用程序的控制，当前几乎所有的关系型数据库都提供了约束（constraint）机制，该机制提供了一条强大而简易的途径来保证数据库中数据的完整性。一般来说，数据完整性有以下三种形式：

- 实体完整性保证表中有一个主键。
- 域完整性保证数据每列的值满足特定的条件。在InnoDB存储引擎表中，域完整性可以通过以下几种途径来保证：
  - 选择合适的数据类型确保一个数据值满足特定条件。
  - 外键（Foreign Key）约束。
  - 编写触发器。
  - 用DEFAULT约束作为强制域完整性的一个方面。
- 参照完整性保证两张表之间的关系。InnoDB存储引擎支持外键，因此允许用户定义外键以强制参照完整性，也可以通过编写触发器以强制执行。

### 视图

视图（View）是一个命名的虚表，它由一个SQL查询来定义，可以当做表使用。与持久表（permanent table）不同的是，视图中的数据没有实际的物理存储。

#### 物化视图

该视图不是基于基表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算并保存多表的链接（JOIN）或聚集（GROUP BY）等耗时较多的SQL操作结果。这样，在执行复杂查询时，就可以避免进行这些耗时的操作，从而快速得到结果。

查询重写是指当对物化视图的基表进行查询时，数据库会自动判断能否通过查询物化视图来直接得到最终的结果，如果可以，则避免了聚集或连接等这类较为复杂的SQL操作，直接从已经计算好的物化视图中得到所需的数据。

物化视图的刷新是指当基表发生了DML操作后，物化视图何时采用哪种方式和基表进行同步。刷新的模式有两种：

- on demand：物化视图在用户需要的时候进行刷新

- on commit：在 DML 语句提交后刷新

### 分区

分区的过程是将一个表或索引分解为多个更小、更可管理的部分。数据库支持的分区类型为水平分区，并不支持垂直分区。此外，MySQL数据库的分区是局部分区索引，一个分区中既存放了数据又存放了索引。而全局分区是指，数据存放在各个分区中，但是所有数据的索引放在一个对象中。

MySQL数据库支持以下几种类型的分区：

- Range：行数据基于属于一个给定连续区间的列值被放入分区

- List：类似 Range，面向离散数据

- Hash：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数

- Key：使用 MySQL 的哈希函数

不论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分

## 索引

InnoDB存储引擎支持以下几种常见的索引：

- 哈希索引：InnoDB存储引擎支持的哈希索引是自适应的，InnoDB存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。

- B+树索引：B+树索引就是传统意义上的索引，这是目前关系型数据库系统中查找最为常用和最为有效的索引。B+树索引的构造类似于二叉树，根据键值（Key Value）快速找到数据。

- 全文索引

### B+ 树

B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。

B+树的插入必须保证插入后叶子节点中的记录依然排序，同时需要考虑插入到B+树的三种情况，每种情况都可能会导致不同的插入算法：

- 叶节点与索引节点都未满：直接插入叶节点

- 叶节点已满：拆分叶节点，将中间节点加入上层索引节点并按其划分左右叶节点

- 叶节点与索引节点都满：拆分叶节点，拆分索引节点

不管怎么变化，B+树总是会保持平衡。但是为了保持平衡对于新插入的键值可能需要做大量的拆分页（split）操作。因为B+树结构主要用于磁盘，页的拆分意味着磁盘的操作，所以应该在可能的情况下尽量减少页的拆分操作。

旋转发生在Leaf Page已经满，但是其的左右兄弟节点没有满的情况下。这时B+树并不会急于去做拆分页的操作，而是将记录移到所在页的兄弟节点上。在通常情况下，左兄弟会被首先检查用来做旋转操作

B+树使用填充因子（fill factor）来控制树的删除变化，50%是填充因子可设的最小值。B+树的删除操作同样必须保证删除后叶子节点中的记录依然排序，同插入一样，B+树的删除操作同样需要考虑以下的三种情况，与插入不同的是，删除根据填充因子的变化来衡量。

- 叶节点和索引节点都大于填充因子：直接删除叶节点记录，如果该记录还是索引，则用其右节点代替

- 叶节点小于填充因子：合并叶节点和兄弟节点(优先左兄弟节点)，更新索引节点

- 叶节点和索引节点都小于填充因子：合并叶节点，合并索引节点

#### B+ 树索引

B+树索引的本质就是B+树在数据库中的实现。但是B+索引在数据库中有一个特点是高扇出性，因此在数据库中，B+树的高度一般都在2～4层，这也就是说查找某一键值的行记录时最多只需要2到4次IO

数据库中的B+树索引可以分为聚集索引（clustered inex）和辅助索引（secondary index）：

- 聚集索引：聚集索引（clustered index）就是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。它对于主键的排序查找和范围查找速度非常快。叶子节点的数据就是用户所要查询的数据。

- 辅助索引：对于辅助索引（Secondary Index，也称非聚集索引），叶子节点并不包含行记录的全部数据。叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含了一个书签（bookmark）。该书签用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。

B+树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费(当插入是以自增顺序进行时，按照中间记录分裂会导致前半部分存在永远不会被用到的空间)

### Cardinality值

Cardinality值非常关键，表示索引中不重复记录数量的预估值。同时需要注意的是，Cardinality是一个预估值，而不是一个准确值，基本上用户也不可能得到一个准确的值。在实际应用中，Cardinality/n_rows_in_table应尽可能地接近1。如果非常小，那么用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对这个字段添加B+树索引是非常有必要的。

### 联合索引

联合索引是对多个列建立的索引，从本质上来说，联合索引也是一棵B+树，不同的是联合索引的键值的数量不是1，而是大于等于2。

联合索引会在为第二个索引进行排序，所以在执行 where a = xxx order by b 时，使用联合索引 (a, b) 可以不需要再对 b 进行排序

### 覆盖索引

当二级索引的叶节点中完全包含了需要查询的所有数据，则不再需要回表至聚集索引查询，可以直接返回叶节点中的数据

当执行统计操作时，优化器可能会选择使用覆盖索引而非聚集索引，因为覆盖索引远小于聚集索引，可以大大减少 IO 操作

在二级索引不能提供范围查询所需的所有数据时，优化器会选择使用聚集索引(全表扫描)，因为虽然二级索引是按照索引顺序进行排序的，但其指向的主键是离散的，所以使用二级索引进行范围查询时还需要多次的离散 IO。如果要求访问的数据量很小，则优化器还是会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%左右），优化器会选择通过聚集索引来查找数据。

### Multi-Range Read优化

Multi-Range Read优化的目的就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问，这对于IO-bound类型的SQL查询语句可带来性能极大的提升。

MRR 会将从二级索引处查询得到的主键加入缓存，排序后再进行回表操作，尽量减少随机 IO

Multi-Range Read还可以将某些范围查询，拆分为键值对，以此来进行批量的数据查询。这样做的好处是可以在拆分过程中，直接过滤一些不符合查询条件的数据，例如对于查询 where partA >= 1000 and partA <= 2000 and partB = 100，不使用 MRR 时优化器会先查出所有符合 partA 条件的数据，再对其继续筛选，导致取出大量无用数据；而使用 MRR 时优化器会将查询拆分成 (1000, 1000) (1001, 1000) 的形式，最后再根据这些拆分出的条件进行数据的查询。

### Index Condition Pushdown（ICP）优化

索引条件下推指的是将可以过滤的索引条件判断从服务层下推至引擎层，从而减少回表的次数

例如对于联合索引 (a, b) 执行查询 where a = xxx and b like '%x%' and c = xxx，如果不使用 ICP，存储引擎会先从二级索引中查询所有 a = xxx 的记录，将其回表得到完整数据后返回给 MySQL 服务层，再由服务层对数据进行 b 和 c 的条件过滤；在应用 ICP 后，存储引擎会对二级索引中的 a = xxx 的记录再进一步筛选出 b like '%x%' 后才返回给 MySQL 服务层，避免了大量无用记录的回表

### 哈希算法

InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。对于缓冲池页的哈希表来说，在缓冲池中的Page页都有一个chain指针，它指向相同哈希函数值的页。而对于除法散列，m的取值为略大于2倍的缓冲池页数量的质数。

### 全文检索

全文检索（Full-Text Search）是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种统计和分析。

#### 倒排索引

全文检索通常使用倒排索引（inverted index）来实现。倒排索引同B+树索引一样，也是一种索引结构。它在辅助表（auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。

#### InnoDB全文检索

在InnoDB存储引擎中，将(DocumentId，Position)视为一个“ilist”。因此在全文检索的表中，有两个列，一个是word字段，另一个是ilist字段，并且在word字段上有设有索引。

倒排索引需要将word存放到一张表中，这个表称为Auxiliary Table（辅助表）。在InnoDB存储引擎中，为了提高全文检索的并行性能，共有6张Auxiliary Table，目前每张表根据word的Latin编码进行分区。

Auxiliary Table是持久的表，存放于磁盘上。然而在InnoDB存储引擎的全文索引中，还有另外一个重要的概念FTS Index Cache（全文检索索引缓存），其用来提高全文检索的性能。

FTS Index Cache是一个红黑树结构，其根据（word，ilist）进行排序。InnoDB存储引擎会批量对Auxiliary Table进行更新，而不是每次插入后更新一次Auxiliary Table。当对全文检索进行查询时，Auxiliary Table首先会将在FTS Index Cache中对应的word字段合并到Auxiliary Table中，然后再进行查询。如果当数据库发生宕机时，一些FTS Index Cache中的数据库可能未被同步到磁盘上。那么下次重启数据库时，当用户对表进行全文检索（查询或者插入操作）时，InnoDB存储引擎会自动读取未完成的文档，然后进行分词操作，再将分词的结果放入到FTS Index Cache中。

## 锁

InnoDB存储引擎锁的实现和Oracle数据库非常类似，提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。

### lock与latch

latch一般称为闩锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在InnoDB存储引擎中，latch又可以分为mutex（互斥量）和rwlock（读写锁）。其目的是用来保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制。

lock的对象是事务，用来锁定的是数据库中的对象，如表、页、行。并且一般lock的对象仅在事务commit或rollback后进行释放（不同事务隔离级别释放的时间可能不同）。此外，lock，正如在大多数数据库中一样，是有死锁机制的。

### InnoDB存储引擎中的锁

InnoDB存储引擎实现了如下两种标准的行级锁：

- 共享锁

- 排他锁

InnoDB存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁

如果不使用意向锁，则当事务需要加表锁时，需要检查表中的所有行是否加行锁；事务需要加行锁时，需要检查表是否加锁，如此会产生大量的锁检查开销和死锁风险；使用意向锁后，只需要判断表是否有加 IX 锁即可

#### 一致性非锁定读

一致性的非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB存储引擎会去读取行的一个快照数据。

在事务隔离级别READ COMMITTED和REPEATABLE READ（InnoDB存储引擎的默认事务隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。然而，对于快照数据的定义却不相同。在READ COMMITTED事务隔离级别下，对于快照数据，非一致性读总是读取被锁定行的最新一份快照数据(其他事务的每次提交都会影响读数据的结果)。而在REPEATABLE READ事务隔离级别下，对于快照数据，非一致性读总是读取事务开始时的行数据版本。

#### 一致性锁定读

InnoDB存储引擎对于SELECT语句支持两种一致性的锁定读（locking read）操作：

❑SELECT…FOR UPDATE

❑SELECT…LOCK IN SHARE MODE

SELECT…FOR UPDATE对读取的行记录加一个X锁，其他事务不能对已锁定的行加上任何锁。SELECT…LOCK IN SHARE MODE对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X锁，则会被阻塞。

### 锁的算法

InnoDB 包含三种行锁算法：

- record lock：锁定一条记录

- gap lock：间隙锁，锁定一个范围，不包含记录
  
  - Gap Lock的作用是为了阻止多个事务将记录插入到同一范围内，而这会导致Phantom Problem问题的产生。

- next-key lock：g + r，锁定一个范围与其中的记录
  
  - 对于唯一键值的锁定，Next-Key Lock降级为Record Lock仅存在于查询所有的唯一索引列。若唯一索引由多个列组成，而查询仅是查找多个唯一索引列中的其中一个，那么查询其实是range类型查询，而不是point类型查询，故InnoDB存储引擎依然使用Next-Key Lock进行锁定。

在默认的事务隔离级别下，即REPEATABLE READ下，InnoDB存储引擎采用Next-Key Locking机制来避免Phantom Problem（幻读问题）。

Phantom Problem是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行(事务执行途中，查询的数据范围被其他事务插入新的数据)。

### 锁问题

- 脏读：脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据

- 不可重读：同一个事务中，两次读取相同的数据结果不同，即读到其他事务对同一个数据提交的修改
  
  - 幻读是不可重读的一种

- 丢失更新：一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。
  
  - 在数据库层面，因为进行修改的 DML 操作会对数据加锁，所以并不会发生丢失更新
  
  - 但在多用户计算机系统中有可能产生：两个事务将同一份数据读入本地内存并分别提交，此时后提交的更新会覆盖之前的更新 
