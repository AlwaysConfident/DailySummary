# 数据库

- 元组：关系是一张表，表中的每行就是一个元组
- 码：唯一标识实体的属性，对应表中的列
- 候选码：关系中的某一属性/属性组的值能唯一标识一个元组，而其任何子集都不能再标识，则该属性组为候选码
  - 主键 → 学号
  - 候选码 → 姓名，班级(只有这两者也能唯一标识一个学生)
- 主键：从候选码中选出的一个，一个表中只能有一个且不能为空，不能重复
- 外键：一个关系中的属性是另一个关系中的主键，一个表中可以有多个外键，且可以为空，可以重复
  - 一般不适用外键：
    - 增加复杂性：每次 DELETE 和 UPDATE 都需要考虑外键约束；外键的关系是定死的，故需求变化时也需要对表做修改
    - 分库分表：分库分表下外键无法生效
  - 外键保证数据库的一致性和完整性，级联操作方便，减轻程序代码量，在不涉及分库分表且并发量不高的情况下可以使用
- 主属性：候选码中出现过的属性
- 非主属性：不在任何一个候选码中出现的属性

## 范式

- 1NF：属性不可再分
- 2NF：1NF 的基础上，消除了非主属性对于键的部分函数依赖(所以非主属性都依赖于主键)
- 3NF：2NF 的基础上，消除了非主属性对于键的传递函数依赖(所有非主属性都不依赖于其他非主属性)

范式有助于维护数据一致性和完整性，高级别的范式通常可以减少数据冗余，提高数据一致性，但也可能增加复杂性和查询性能的开销(联表查询)

### 1NF

属性不能再被分割，即这个字段只能是一个值，无法再分为多个其他的字段，1NF 是所有关系型数据库的基本要求

存在数据冗余过大、删除异常、插入异常、修改异常的问题

### 2NF

在 1NF 基础上，消除了非主属性对于键的部分函数依赖，2NF 在 1NF 的基础上增加了一个主键列，非主属性都依赖于主键

![第二范式](https://oss.javaguide.cn/github/javaguide/csdn/bd1d31be3779342427fc9e462bf7f05c.png)

- 函数依赖：在一张表中，可以由 X 确定 Y，即 X → Y，则 Y 函数依赖于 X
- 部分函数依赖：X → Y 且存在 X 的真子集 X0 → Y，则 Y 对X 部分函数依赖
  - 学生表 R(学号、身份证号、姓名)中，有 (学号、身份证号) → (姓名)、(学号) → (姓名)、(身份证号) → (姓名)，则姓名部分依赖于 (学号、身份证号)
- 完全函数依赖：某个非主属性数据项依赖于全部候选项，则为完全函数依赖
  - 学生表 R(学号、班级、姓名)中，有 (学号、班级) → (姓名)，即只有确定了学号和班级后才能唯一确定姓名，只知道学号或班级则无法确定姓名，故姓名完全函数依赖于 (学号、班级)
- 传递函数依赖：在 R(U) 中， X → Y，Y —/→ X，Y → Z，Z 不属于 Y，则 Z 对 X 传递函数依赖
  - 学生表 R(学号、姓名、系名、系主任) 中，学号 → 系名，系名 → 系主任，所以存在非主属性系名对学号的传递函数依赖

### 3NF

3NF 在 2NF 的基础上，消除了非主属性对键的传递函数依赖(任何非主属性不依赖于其他非主属性)，符合 3NF 要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常

## 存储过程

存储过程可以看作一些 SQL 语句的集合，中间加入逻辑控制语句，在业务复杂时比较实用，可以方便调用。

存储过程一旦调试完成后就能稳定运行，且使用存储过程比单纯 SQL 语句执行要快，因为存储过程预编译过

但存储过程在高并发、分库分表、需求更新频繁的场景应用不多，因为存储过程难以调试和扩展(无法配合中间件使用)，且没有移植性(数据库的升级、迁移)，还会消耗数据库资源

## drop vs delete vs truncate

|            | drop                                                         | delete                                              | truncate                                                     |
| ---------- | ------------------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ |
| 用法       | 删除表                                                       | 删除某一行数据，若不带筛选条件，则同 truncate       | 删除表数据，主键 id 从 1 开始                                |
| 数据库语言 | DDL，操作立即生效，原数据不放入 rollback segment，不能回滚，操作不触发 trigger | DML，操作放入 rollback segment 中，事务提交后才生效 | DDL                                                          |
| 执行速度   | 直接释放表占用的空间，速度最快                               | 执行时会产生数据库的 binlog 日志，需要消耗时间      | 执行时不会产生 binlog，但需要把表的自增值重置和索引恢复到初始大小 |

## NoSQL 

Not Only SQL，非关系型数据库，主要针对键值、文档、图形类型数据存储。

NoSQL 天生支持分布式、数据冗余、数据分片等特性，旨在提供可扩展的高可用高性能数据存储解决方案

NoSQL 适合需要灵活、可扩展、高性能和功能强大的数据库来提升用户体验的现代应用程序(移动、Web 和游戏应用程序)

- 灵活性：NoSQL 的架构灵活，便于迭代开发；NoSQL 的数据结构灵活，支持非关系型数据结构
- 可扩展性：NoSQL 天然支持分布式，可以通过增加分布式硬件集群来横向扩展，而不必使用更高性能的服务器纵向扩展
- 高性能：NoSQL 针对特定的数据模型和查询模式进行优化
- 功能强大：NoSQL 提供各种功能强大的 API 和数据类型

### SQL vs NoSQL

|              | SQL                                                          | NoSQL                                              |
| ------------ | ------------------------------------------------------------ | -------------------------------------------------- |
| 数据存储模型 | 结构化存储，具有固定行和列的表格                             | 非结构化存储：JSON、键值对、节点和边               |
| 重点         | 减少数据重复                                                 | 提升可扩展性，减少大规模数据的存储成本             |
| ACID         | 提供原子性、一致性、隔离性、持久性                           | 为了可扩展、高性能，通常不支持 ACID 事务           |
| 性能         | 取决于磁盘子系统，需要通过优化查询、索引和表结构获得最佳性能 | 性能由底层硬件集群大小、网络延迟及调用应用程序决定 |
| 扩展         | 垂直(使用性能更强的服务器扩展)，读写分离，分库分表           | 横向(增加服务器，基于分片机制)                     |
| 用途         | 普通企业级的项目的数据存储                                   | 用途广泛                                           |
| 查询语法     | SQL                                                          | 因数据库而异                                       |

### 存储类型

- 键值：每个项目都包含 key 和 value，极为灵活的数据库类型，因为应用可以完全控制 value 字段中存储的内容，没有任何限制

- 文档：数据被存储在类似 JSON 的文档中，清晰直观，每个文档包含成对的字段和值

  ![](https://www.runoob.com/wp-content/uploads/2013/10/Figure-1-Mapping-Table-to-Collection-1.png)

- 图形：旨在轻松构建和运行与高度连接的数据集一起使用的应用程序，实体作为顶点，实体之间的关系则被作为边，图形数据库的典型使用包括社交网络、推荐引擎、欺诈检测、知识图形

- 宽列：适用于存储大量数据，数据按列存储，故可以压缩大量重复的数据

## MySQL

MySQL 是一种关系型数据库，主要用于持久化存储系统中一些数据

MySQL 开源免费且比较成熟，默认端口为 3306

### 优点

- 开源免费
- 成熟稳定，功能完善
- 文档丰富，易于学习使用
- 开箱即用，操作简单，维护成本低
- 兼容性好，支持常见的操作系统与开发语言
- 生态完善
- 事务支持优秀
- 支持分库分表、读写分离、高可用

### 字段类型

- 数值类型
- 字符串类型
- 日期时间类型

![MySQL 常见字段类型总结](https://oss.javaguide.cn/github/javaguide/mysql/summary-of-mysql-field-types.png)

MySQL 中没有布尔值，一般使用 TINYINT(1) 存储 0 和 1 表示

#### 整数类型的 UNSIGNED

表示不允许负值的无符号整数，使用 UNSIGNED 属性能够将正整数的上限提高一倍(不需要存储负值)

可以用于从 0 开始递增的 ID 列，提高 ID 的上限范围

#### CHAR vs VARCHAR

- CHAR 为定长字符串，在存储时会在右边填充空格以达到指定长度，检索时去除空格，适用于长度较短或长度相差不大的字符串(手机号、身份证号)
- VARCHAR 为变长字符串，在存储时使用 1-2 个额外字节记录字符串长度，检索时不需要处理，适用于存储长度较长或长度相差大的字符串

CHAR(M) 与 VARCHAR(M) 都表示最多能保存 M 个字符数，所有字符类型(数字、字母、汉字)都只占用一个字符

#### VARCHAR(10) vs VARCHAR(100)

- 最大长度：10 vs 100；当 VARCHAR(10) 需要存储超过 10 个字符时，需要修改表结构
- 存储占用空间：都存储相同字符数的字符串时，占用的磁盘存储空间相同
- 内存占用：在内存中操作时，VARCHAR(100) 会占用 100 个字符的内存空间，无论其实际使用的大小

#### DECIMAL vs FLOAT/DOUBLE

- DECIMAL 是定点数，可以存储精确的小数(类比 BigDecimal)
- FLOAT/DOUBLE 为浮点数，只能存储近似的小数值

#### TEXT & BLOB

TEXT 类似于 CHAR 和 VARCHAR，但能存储更长的字符串(长文本数据，文章内容)

BLOB 存储二进制大对象，如图片、音视频

不推荐使用 TEXT 与 BLOB：

- 不能有默认值
- 只能在磁盘使用临时表
- 检索效率低
- 不能直接创建索引，需要指定前缀长度
- 可能消耗大量网络和 IO 带宽
- 可能导致表上的 DML 操作变慢

#### DATETIME vs TIMESTAMP

- 时区：DATETIME 没有时区信息，只保存当前会话设置的时区对应的时间；TIMESTAMP 与时区相关，存储的值会自动换算成服务器时区
- 存储空间：8 字节 vs 4 字节；TIMESTAMP 表示的时间范围更小(2038 年)
  - MySQL 5.6.4 前，DATETIME 与 TIMESTAMP 的存储空间是固定的
  - MySQL 5.6.4 后，两者的存储空间会根据毫秒精度不同而变化，DATETIME 为 5-8 字节，TIMESTAMP 为 4-7 字节
- 性能：TIMESTAMP 需要根据时区进行转换，所以从毫秒转换为 TIMESTAMP 时还要调用操作系统底层的系统函数保证系统时区的一致性，并且需要加锁操作

字符串存储时间：占用空间更大，且无法使用 API，效率更低(逐个字符比较)

数字时间戳：日期的排序、比较效率更高，跨系统更方便，但可读性较差

#### NULL vs ''

NULL != ''

- 含义：NULL 表示不确定的值，两个 NULL 也不一定相等；'' 表示空字符串
- 占用空间：NULL 占用空间；'' 长度为 0，不占用空间
- 函数运算：NULL 影响聚合函数结果，部分聚合函数会忽略 NULL 值(SUM、AVG、MIN、MAX)，COUNT(*) 时会计算 NULL 行
- 查询：NULL 值只能使用 IS NULL 或 IS NOT NULL 查询

### MySQL 架构

![](https://pic1.zhimg.com/80/v2-b29359b4bc5e849601c5df10a2a8e484_720w.webp)

- 连接器：身份认证与权限相关
- 查询缓存：执行查询语句时会先查询缓存(MySQL 8.0 后移除，因为不太实用)
- 分析器：对 SQL 语句进行词法、语法分析，了解 SQL 语句的目的与检查 SQL 语句的语法是否正确
- 优化器：MySQL 对 SQL 语句进行优化(索引)
- 执行器：先判断权限，之后执行 SQL 语句后从存储引擎返回数据
- 插件式存储引擎：负责数据的存储和读取，采用插件式架构，支持多种存储引擎

### 存储引擎

MySQL 支持多种存储引擎，5.5.5 之前默认使用 MyISAM，之后默认使用 InnoDB，且只有 InnoDB 为事务性存储引擎(支持事务)

存储引擎采用插件式架构，支持多种存储引擎，存储引擎是基于表而不是数据库

#### MyISAM vs InnoDB

- 行级锁：MyISAM 只有表级锁，即 MyISAM 一锁就是锁住整张表，影响并发性能；InnoDB 默认为行级锁
- 事务：MyISAM 不提供事务支持；InnoDB 提供了事务支持，实现了 SQL 标准定义的四个隔离级别，具有 commit 和 rollback 事务的能力，InnoDB 默认使用可重读隔离级别能够解决幻读问题(基于 MVCC 和 Next-Key Lock)
- 外键：MyISAM 不支持外键；InnoDB 支持外键
  - 一般在应用层面实现外键的功能，因为数据库中使用外键会增加数据库开销和复杂度，且外键不支持分库分表
- 数据库异常崩溃后的安全恢复：MyISAM 不支持；InnoDB 在异常崩溃后，数据库重新启动时会保证数据库恢复到崩溃前的状态(redo log)
- MVCC：MVCC 可以看作行级锁的升级，可以有效减少加锁操作，提高性能
- 索引：两者都使用 B+ 树作为索引的底层实现
  - MyISAM 中索引文件和数据文件是分离的
  - InnoDB 中数据文件本身就是索引文件，其表数据文件本身就是按 B+ Tree 组织的一个索引结构，树的叶节点 data 域保存完整的数据记录
- 性能：MyISAM 读写不能并发；InnoDB 在读写混合或只读模式下，读写能力随 CPU 核数线性增长

![常见的几种 MySQL 存储引擎对比](https://oss.javaguide.cn/github/javaguide/mysql/comparison-of-common-mysql-storage-engines.png)

### 索引

索引是一种用于快速查询和检索数据的数据结构，本质是一种排序好的数据结构

InnoDB 与 MyISAM 中使用 B+ 树作为索引结构

- MyISAM 中 B+ 树叶节点存放数据的地址，在索引检索时需要先找到索引值，再由其地址读取对应的数据(非聚簇索引)
- InnoDB 中 B+ 树的叶节点存放的是完整的数据记录，以表的主键作为 key，即表数据文件本身就是主索引(聚簇索引)，其余索引为辅助索引，辅助索引中叶节点存储的是主键的值(非聚簇索引)
  - 根据主索引搜索时，直接找到 key 所在的节点即可取出数据
  - 根据辅助索引搜索时，需要找到 key 对应的主键的值，再使用主键值在主索引中搜索

优点：

- 索引能够大大加快数据检索的速度
- 唯一性索引能够保证数据的唯一性

缺点：

- 对数据做修改时也需要为索引的维护花费额外的开销
- 索引也会占用一部分物理空间

#### 底层数据结构

- 哈希表：使用哈希算法能通过键值对快速检索对应的数据(一次定位)，但是 InnoDB 不支持常规的哈希索引
  - InnoDB 提供了自适应哈希的实现，即使用 B+ 树作为哈希桶，减少哈希冲突链的长度，提高索引效率
  - 由于哈希表无法实现顺序、范围(每次只能查询一个)查找，故不常用
- BST：二叉搜索树的效率依赖于树的结构，退化成链表时效率极低 O(n)
- AVL 树：自平衡二叉搜索树会通过旋转操作保证左右子树高之差不超过 1，即搜索树不会退化，达到查找/插入/删除的平均效率都在 O(logn)
  - 但自平衡频繁的旋转操作会产生巨大的计算开销 O(logn)
  - 每个节点只能存储一个数据，即每次磁盘 IO 都只能读取一个节点数据，查询的数据分布在多个节点上时会进行多次磁盘 IO
- 红黑树：红黑树通过变色和旋转来维持黑高平衡，可能导致树的高度较高，查询效率降低，一些数据需要多次磁盘 IO 操作才能查到
  - 红黑树在插入和删除时只需要 O(1) 次数的旋转与变色，故插入和删除的效率较高
- B & B+ 树：B+ 树比 B 树具备更少的 IO 次数(直到叶节点才进行磁盘 IO)，更稳定的查询效率(查询必定到达叶节点)，更适于范围查询(叶节点保存指向兄弟节点的指针)
  - 数据存储：B 树的数据存储在叶节点与中间节点；B+ 树的数据只存储在叶节点
  - 叶节点：B 树的叶节点是独立的，无法直接获取兄弟节点信息；B+ 树的叶节点保存指向兄弟节点的指针
  - 检索顺序：B 树的检索过程类似二分查找，可能未到达叶节点就结束(中间节点也存储数据)；B+ 树的检索一定要到达叶节点(只有叶节点才存储数据)，检索效率更稳定
  - 范围查询：B 树中进行范围查询时，首先找到查询的下限，然后对 B 树进行中序遍历找到上限；B+ 树的范围查询只需要对叶节点的链表遍历

#### 索引类型

底层存储方式：

- 聚簇索引：索引结构与数据一起存放(InnoDB 中的主键索引)
  - 优点：
    - 查询速度快，不需要额外的磁盘 IO
    - 便于排序查找和范围查找：叶节点存储的数据有序且连续
  - 缺点：
    - 依赖于有序的数据：要求插入的数据是有序的，对于长且难排序的数据效率较低
    - 更新开销大：表数据更新时，索引存储的数据也需要同步更新，故对于主键索引来说，主键一般不可修改
- 非聚簇索引：索引结构与数据分开存放(InnoDB 中的辅助索引，MyISAM 中的索引)
  - 优点：
    - 更新开销小：叶节点存储的是指向主键/数据的地址，故表数据更新时维护索引的开销更小
  - 缺点：
    - 依赖于有序的数据
    - 二次查询(回表)：查到索引对于的指针/主键后，还需要再到对应的数据文件/表中查询，若查询的数据就是索引本身(查询主键)，则不需要回表

![聚簇索引和非聚簇索引](https://oss.javaguide.cn/github/javaguide/database/mysql20210420165326946.png)



应用维度：

- 主键索引：数据表的主键列使用的索引，唯一且不为 NULL，表中没有主键时，InnoDB 会选择表中有唯一索引且不允许 NULL 值的字段，否则会自动创建一个 6 Byte 的自增主键
- 辅助索引/二级索引：二级索引的叶节点存储的数据是主键，即通过二级索引定位主键的位置
  - 唯一索引：属性列不可重复，允许为 NULL，一张表中允许多个唯一索引，建立唯一索引主要用于确保对应属性列数据的唯一性
  - 普通索引：唯一作用是快速查询数据
  - 前缀索引：只适用于字符串类型，对文本的前几个字符创建索引，故比普通索引更小
  - 全文索引：为了检索大文本数据中的关键字信息，目前搜索引擎数据库使用的一种技术，效率极低，通常由搜索引擎(ElasticSearch) 代替
- 覆盖索引：将所有要查询的字段作为索引，减少回表次数
- 联合索引：使用表中多个字段创建索引
  - 最左前缀匹配原则：在使用联合索引时，MySQL 根据联合索引中的字段顺序，从左到右依次到查询条件中匹配(a 相等时再根据 b 排序)，全部字段匹配完成，或遇到范围查询(>、<)时停止匹配(a > 1 and b = 2，此时无法确定 a 的值不固定，无法确定 b 的顺序，即无法使用 B+ 树)

#### 索引下推

MySQL 5.6 中提供的一项索引优化功能，在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数

即先用索引中的信息对查询进行筛选

```sql
select * from tuser where name like '张%' and age=10;
```

不使用 ICP：浪费联合索引中的 age 字段

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c97ed6c5e395416181cb57591151fb09~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

使用 ICP：通过联合索引中的 age 字段先进行筛选

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8edc3c9af2e5403da79f77e50adaecd3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

#### 正确使用索引

- 选择合适的字段：
  - 不为 NULL：NULL 值难以优化，必要时可使用 0/1/true/false
  - 频繁查询的字段：索引应被频繁查询
  - 作为条件查询的字段
  - 频繁需要排序的字段：索引已被排序，这样查询可以直接利用索引的排序
  - 频繁用于连接的字段：提高多表连接查询效率
- 避免使用频繁更新的字段：字段更新需要同步维护索引
- 限制表索引数量：过多的索引会影响修改表的效率
- 联合索引优于单列索引：索引占用磁盘空间，若每个索引看作一个 B+ 树，大表的单列索引占用空间较多，且维护的开销更大，联合索引将多个字段结合，可以节省空间同时减少开销
- 避免冗余索引：索引 (a,b) 包含索引 (a)
- 字符串类型字段使用前缀索引替代普通索引：占用空间更小
- 删除长期未使用的索引
- 分析语句是否使用到索引查询：使用 EXPLAIN 命令

#### 索引失效

- 查询条件未遵守最左匹配原则
- 使用函数/计算：改变了索引列原来的值的操作会导致索引失效(函数不一定)
  - MySQL 8.0 增加了函数索引，既可以针对函数计算后的值建立一个索引
- Like %：范围比较小时('A%')使用较低级别的索引(普通索引)，范围非常大时('%A')索引失效
- OR 导致索引失效：OR 的两边含有非索引列
- IN 导致索引失效：IN 必定使用索引查询，但当范围过大时会使用全表扫描，导致索引失效
- ORDER BY：使用索引则需要回表排序，MySQL 会跟直接全表扫描排序的效率比较，选择更高的一方

#### select *

select * 不会导致索引失效(where 查询范围过大时会导致失效)，但仍不建议使用：

- 增加查询分析器解析成本
- 增减字段容易与 resultMap 不一致
- 无用字段增加网络消耗(text 类型字段)

### 查询缓存

执行查询语句时会先查找缓存，在 MySQL 8.0 中移除(不实用)

开启查询缓存后在同样的查询条件及数据情况下，会直接在缓存中返回结果

查询不命中：

- 两个查询的任何字符上的不同
- 查询中包含自定义函数、存储函数、用户变量、临时表、MySQL 系统表
- 缓存的表发生变化(数据、结构)

缓存虽然能提升查询效率，但维护缓存的开销较大(每次查询都要更新缓存，缓存失效时也要清除)

### 日志

- 错误日志：记录 MySQL 的启动、运行、关闭过程
- 二进制日志：binary log 记录更改数据库数据的 SQL 语句
- 一般查询日志：已建立连接的客户端发送给服务器的所有 SQL 记录，默认关闭(量比较大)
- 慢查询日志：记录执行时间超过阈值或没有使用索引的查询，解决 SQL 慢查询问题，默认关闭(实际项目中可能比较大)
- 事务日志：重做日志(redo log)，回滚日志(undo log)
- 中继日志：relay log 是复制过程中产生的日志，类似 binary log，主要针对主从复制的从库
- DDL 日志：记录 DDL 语句执行的元数据操作

#### 慢查询日志

记录执行时间超过阈值的查询，找到慢 SQL 是优化的第一步

```sql
-- 通过以下命令查看慢日志
show global status like '%Slow_queries%'
```

获取到慢 SQL 后，可以通过 EXPLAIN 命令获取执行计划相关信息，再根据其结果进行优化

#### binlog

二进制日志主要记录更新数据库数据的 SQL 语句(所有 DDL 和 DML 语句，不包括 SELECT/SHOW 等不修改数据库的语句)

```sql
-- 通过一下命令查看 binlog
show binary logs;
```

使用 MySQL 内置的 binlog 查看工具 mysqlbinlog 解析二进制文件

binlog 通过追加方式写入，大小没有限制，通过 max_binlog_size 参数设置每个文件最大容量，超出后会新增文件

##### 记录方式

一共有三种类型的二进制记录方式：

- Statement：记录每条会修改数据库的语句，MySQL 5.7.7 前默认为 Statement
  - 日志文件更小，磁盘 IO 压力较小，性能更好，但准确性更低
- Row：记录每一行的具体变更事件，MySQL 5.1.5 开始支持
  - 若一条 SQL 语句修改了 1000 条数据，Statement 只会记录一条 SQL 语句，Row 则会记录 1000 条修改记录
- Mixed：默认使用 Statement，少数特殊具体场景切换到 Row，MySQL 5.1.8 开始支持，MySQL 5.7.7 之后默认为 Mixed

##### 应用场景

binlog 主要用于主从复制，保证数据一致性，也可以用于数据恢复

主从复制：

![](https://pic4.zhimg.com/v2-12f36a0aa2ea88020809173182e54e73_r.jpg)

1. 主库将数据库中的变化写入 binlog
2. 从库连接主库
3. 从库创建 IO 线程向主库请求更新的 binlog
4. 主库创建一个 binlog dump 线程发送 binlog 由从库的 IO 线程接收
5. 从库的 IO 线程将接收的 binlog 写入 relay log 中
6. 从库的 SQL 线程读取 relay log 同步到本地数据(再执行一次 SQL)

##### binlog 写入磁盘

事务在执行过程中，会先把日志写入内存中的 binlog cache，只有事务提交时才真正写回磁盘中的 binlog(事务会回滚，且写入内存的效率更高)

由于事务的原子性，无论多大的事务都需要一次性写入 binlog，故当分配的 binlog cache 不足时，会将存储内容暂存到磁盘

binlog 写回磁盘的时机分为 0-N：

- 0：不强制要求，系统自行判断，MySQL 5.7 前默认为 0
- 1：每次提交事务都将 binlog 写回磁盘，MySQL 5.7 后默认为 1
- N：每提交 N 个事务才将 binlog 写回磁盘，有丢失的风险

##### 重写生成 binlog

- MySQL 服务器停止或重启
- 使用 flush logs 命令
- binlog 文件大小超出限制

#### redo log

InnoDB 以页为单位管理存储空间，即数据存储在页中

为了减少磁盘 IO，在内存中使用 Buffer Pool 缓冲池，当数据不在 Buffer Pool 中时，MySQL 会先将磁盘上的页缓存到 Buffer Pool 中，之后的操作也基于 Buffer Pool 中的页，提高读写性能

当事务提交至 Buffer Pool，还未写回磁盘时，MySQL 宕机，此时需要 redo log 来维护数据的持久性

redo log 记录页的修改，每一条记录包含表空间号、数据页号、偏移量、具体修改的数据，在事务提交时会将 redo log 按照写回磁盘的策略写到磁盘中，MySQL 故障重启后也能根据 redo log 恢复未写入的数据，即 redo log 提供了崩溃恢复的功能

![](https://pic2.zhimg.com/80/v2-8b45c811e7502bb04f0a370615380875_720w.webp)

redo log 写回磁盘的时机：

- 事务提交：事务提交时，log buffer 中的 redo log 会被写入磁盘
- log buffer 空间不足：log buffer 中缓存的 redo log 占据 log buffer 一半左右的空间时
- 事务日志缓存区满：InnoDB 使用事务日志缓冲区(transaction log buffer)来暂时存储事务的重做日志条目
- Checkpoint：InnoDB 定期执行检查点操作，将内存中的脏数据(已修改，未写回磁盘)写入到磁盘，同时将 redo log 写回磁盘保证数据的一致性
- 后台刷新线程：InnoDB 后台线程周期性地将脏页写回磁盘，并将相关的 redo log 写回磁盘，即未提交事务的 redo log 也可能写回磁盘
- 正常关闭服务器：MySQL 关闭时，redo log 会全部写回磁盘

redo log 写回磁盘的策略：

- 0：每次事务提交时不写回磁盘，性能最高，但最容易丢失信息
- 1：每次事务提交时都写回磁盘，性能最低，但最安全，默认为 1
- 2：每次事务提交时将 log buffer 中的 redo log 写入 page cache(文件系统缓存)

当 redo log 写入 log buffer 还未写入 page cache，或写入 page cache 还未写入磁盘时都可能发生丢失

redo log 采用循环写入的方式：

![](https://pic3.zhimg.com/80/v2-80c7219fb4a27e55110b8d6a0e3ee632_720w.webp)

write pos 表示 redo log 当前记录写到的位置，checkpoint 表示 redo log当前要写回磁盘的位置，当  write pos 追上 checkpoint 时表示 redo log 文件被写满，此时 MySQL 会阻塞所有数据库更新操作(无法写入 redo log)

##### 页修改后不直接写入磁盘

InnoDB 中的页比较大，可能只修改几个字节就要导致整个页都重新写入磁盘，且修改的页可能不相邻，若每次修改页都直接写回磁盘，则会产生大量的随机磁盘 IO，导致性能极差

redo log 的写入是顺序的磁盘 IO，且 redo log 相比页较小

#### binlog vs redo log

- 用途：binlog 用于还原数据库，属于数据级别的数据恢复，主要用于主从复制；redo log 主要用于保证事务的持久性，属于事务级别的数据恢复
- 实现：binlog 由存储引擎实现(InnoDB)；redo log 由 MySQL 的 Server 层实现
- 类型：binlog 属于逻辑日志，主要记录数据库执行的 DDL 与 DML 语句；redo log 属于物理日志，主要记录页的修改
- 文件大小：binlog 文件默认无上限，会一直追加；redo log 采用循环写方式，当写满时会阻塞所有更新操作

#### undo log

每个事务对数据的修改都会被记录到 undo log，当执行事务需要回滚时，MySQL 可以利用 undo log 将数据恢复到事务开始前的状态

undo log 属于逻辑日志，记录 SQL 语句，如事务执行一条 DELETE 语句，undo log 就会记录一条 INSERT 语句

MVCC 中也使用 undo log 获取当前数据行之前的版本信息(非锁定读取)

### 事务

事务是逻辑上的一组操作，要么都执行，要么都不执行

#### 数据库事务

数据库事务保证多个数据库操作构成逻辑上的整体

事务的特性：

- Atomic：原子性，即事务要么全部成功，要么全部失败
- Consistent：一致性，事务执行前后的数据具有一致性(转账操作，事务执行前后，无论成功与否，钱的总数是不变的)
- Isolate：独立性，多个事务之间互不影响
- Duration：持久性，事务执行的结果是持久的，即使数据库发生故障也不会影响

只有在实现了 AID 后才能实现 C，即 AID 是实现 C 的手段

#### 并发事务

- 脏读：事务 A 修改数据 X，还未提交时事务 B 读取 X，之后事务 A 回滚，导致事务 B 读到的数据 X 是错误的脏数据
- 丢失修改：事务 A 修改数据 X，还未提交时事务 B 也修改 X，导致事务 A 的修改丢失
- 不可重读：事务 B 在一个事务中多次读取 X，事务 A 在读取期间修改 X，导致事务 B 在一个事务中读到的 X 的值不同
  - 不可重读的重点为内容修改、记录减少
- 幻读：事务 A 在一个事务中范围读取 n 个数据，事务 B 同时插入一个数据，此时事务 A 在一个事务中读取到 n+1 个数据
  - 幻读的重点为记录新增(读到原本不存在的数据)

#### 隔离级别

- READ-UNCOMMIT：事务能够读到其他事务未提交的修改
  - 脏读、幻读、不可重读
- READ-COMMIT：事务只能读到其他事务已提交的修改
  - 幻读、不可重读
- REPEATABLE-READ(默认隔离级别)：保证一次事务中对同一字段的多次读取结果一致，基于 MVCC 与 读写锁(Next-Key Lock) 实现
  - 当前读可能出现幻读
- SERIALIZABLE：完全服从 ACID，手动为所有事务排序执行，串行即杜绝了所有并行的问题，基于锁实现，在分布式事务下使用

#### 多版本并发控制 MVCC

MVCC 是一种并发控制机制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。

通过在每个数据行维护多个版本的数据，当事务需要修改数据时，生成一份数据的快照，事务修改副本而不是直接修改原数据

- 读操作：事务的读操作是在数据副本上进行，数据库会选择不晚于事务开始时间的最新版本，因此不会读到其他事务产生的修改
- 写操作：事务的写操作会产生一个新的数据副本，该副本的版本号同事务的版本号，修改完成后会提交至数据库，旧版本的副本仍被保留，保证写操作前的读操作不受影响
- 提交与回滚：事务提交后会生成一个新版本的副本以供之后的事务操作；事务回滚后其生成的副本也被丢弃，对其他事务没有影响
- 版本回收：为了避免版本号无限增长，不再使用的版本号会被定期回收

实现：MVCC 通过数据行的**隐藏字段**和 **Read View** 判断数据的可见性，若不可见，通过数据行的隐藏字段找到 **undo log** 中的历史版本

- 隐藏字段：InnoDB 为每行数据都新增了两个隐藏字段
  - 表示最后一次插入/更新该行的事务 id(delete 被视为更新)
  - 指向该行 undo log 的指针
- Read View：执行事务时产生的，用于可见性判断，保存当前对本事务不可见的其他活跃事务，包含以下字段
  - **下一个将被分配的事务 Id**，大于等于这个 Id 的数据版本均不可见
  - 活跃事务列表中的**最小事务 Id**，小于这个 Id 的数据版本均可见
  - Read View 创建时**其他未提交的活跃事务 Id 列表**，创建 Read View 时，将当前未提交事务 Id 记录，后续即使这些事务已提交也不可见
  - **当前事务 Id**
- undo log：用于读取之前版本的数据
  - insert undo log：在 insert 操作中产生的 undo log，由于 insert 操作只对事务本身可见，故 insert undo log 在 insert 完成后可以直接删除
  - update undo log：在 update 和 delete 操作中产生，事务提交后加入 undo log 链表，等待 purge 线程进行最后的删除

RC 与 RR 隔离级别下的差异：

- 可读提交：每次 select 查询前都生成 Read View
  - 由于一个事务中每次 select 都会生成新的 Read View，故若在两次 select 之间有其他事务提交，则两次生成的 Read View 不同，可能导致不可重读
- 可重读：在事务开始后，第一次 select 前生成一个 Read View

#### 一致性非锁定读

对每行数据增加一个版本号/时间戳，若读操作的版本号大于数据行的版本号(数据已更新)则可以直接读取，否则读取数据快照(历史数据)

在可重读与可读已提交两个隔离级别下，执行普通的 select 语句(不包括 select ... lock in share mode，select ... for update)时使用一致性非锁定读

#### 锁定读

执行以下语句时使用锁定读：

- select ... lock in share mode
- select ... for update
- insert/update/delete

即每次读到的必定是最新的数据(当前读)

锁定读会对读取到数据加锁：

- 当前数据加读锁时，其他事务也可以加读锁，但不可以加写锁
- 当前数据加写锁时，其他事务不能加任何锁

幻读：若不加写锁，则事务在两次当前读的间隙中，插入新的数据就会产生幻读，InnoDB 使用 Next-key Lock 锁定事务当前读的间隙，防止其他事务在查询范围内插入数据

#### 当前读 vs 快照读

快照读即大部分 SELECT 语句，每行记录都存在多个历史版本，若读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会等待写锁释放，而是直接去读行的快照，适用于要求高性能且允许误差的场景

快照读只存在 RC 与 RR 的隔离级别中：

- RC：为事务中每个 SELECT 都生成一个 Read View
- RR：只在事务开始时生成 Read View

当前读保证读操作的结果一定是最新的，故需要读写锁保证数据的一致性，避免读到其他事务未提交的数据

### 锁

锁是常用的并发事务控制方法

#### 表锁 vs 行锁

- 粒度：表锁 → 整张表；行锁 → 相关记录(**针对索引字段加锁**，索引失效或 where 条件中字段没有命中唯一索引时会退化为表锁，即对全部行加锁)
- 开销：行锁的开销更大，加锁更慢，会出现死锁，但在并发场景的效率高于表锁
- 实现：表锁与存储引擎无关；行锁在存储引擎层面实现

#### 行锁种类

- 记录锁：属于单个行记录上的锁
- 间隙锁：锁定一个范围，不包括记录本身
- 临键锁：记录锁 + 间隙锁，锁定一个范围，包含记录本身，用于避免当前读的幻读问题
  - 在 RR 隔离级别下的默认行锁，但操作索引是唯一/主键时会自动优化为记录锁

#### 意向锁

事务加表锁时，需要判断表中是否存在行锁，若每行逐个判断效率太低，故引入意向锁提高效率

- 意向共享锁(IS)：每当要对行加共享锁时，必须先获取表的 IS 锁
- 意向互斥锁(IX)：每当要对行加互斥锁时，必须先获得表的 IX 锁

意向锁由数据库引擎自行维护

意向锁之间兼容，但意向互斥锁与互斥锁都不兼容

|       | IS 锁 | IX 锁 |
| ----- | ----- | ----- |
| IS 锁 | 兼容  | 兼容  |
| IX 锁 | 兼容  | 兼容  |
| S 锁  | 兼容  | 互斥  |
| X 锁  | 互斥  | 互斥  |

### 性能优化

#### 基本设计规范

- 数据库和表的字符集统一使用 UTF-8：兼容性更好，统一字符集避免字符集转换产生的乱码，不同字符集进行比较前需要进行转换会造成索引失效
  - 存储 emoji 时需要使用 utf8mb4
- 控制单表数据量(500w)：数据量过大会影响表的结构修改、备份、修复
  - 历史数据归档(日志数据)、分库分表(业务数据)
- 谨慎使用分区表：将表进行分区，划分为若干个小表，在物理上存储在多个文件中，在逻辑上表现为同一张表。执行查询时，优化器通过分区键筛选出数据所在的分区，从而避免扫描所有分区
  - 使用物理分表管理大数据
  - 谨慎选择分区键，跨分区的查询效率低
- 将经常一起使用的列放在同一个表中：避免更多的联表操作
- 禁止存储较大的二进制数据(文件、图片、视频)：严重影响数据库性能，消耗大量存储空间
  - 应存储在文件服务器，数据库中只存储地址

#### 字段设计规范

- 优先选择符合存储需要的最小数据类型：占用空间更小，性能更高
  - 使用数字类型存储字符串(IP)：INET_ATON() 将 ip → 无符号整型，INET_NTOA() 将整型的 ip → 地址
  - 使用无符号类型存储非负数
  - 使用 TINYINT 存储小数值
- 避免使用 TEXT 与 BLOB：MySQL 内存临时表不支持 TEXT 与 BLOB，即使用 TEXT/BLOB 时必须使用磁盘临时表，且 TEXT/BLOB 只支持前缀索引，效率较低
  - 必须使用时应将 TEXT/BLOB 列分离至单独的扩展表中，查询时只取必要的列
- 避免使用 ENUM 类型：
  - 修改需要使用 ALTER 语句
  - ORDER BY 操作效率低，需要额外操作
  - 使用数字作为枚举值时会混淆字面值与 ENUM 内部索引值
- 尽可能使用 NOT NULL 列：
  - 索引 NULL 列需要额外空间保存
  - 对 NULL 值进行比较与计算需要特别处理
- 避免使用字符串存储日期：
  - 难以比较，需要逐个字符对比，且无法使用日期相关 API
- 金额相关应使用 DECIMAL 字段：能够精确表示小数，且能存储更大的整数类型，但维护精度需要额外开销

#### 索引设计规范

- 限制表的索引数量：索引会影响表的插入与更新效率，过多的索引也会影响 MySQL 优化器生成执行计划的时间(需要选择使用哪个索引)
- 禁止全文索引：不适用于 OLTP 场景
- 禁止为每列创建单独的索引：效率低于联合索引
- 每个表都必须有主键：InnoDB 中数据存储的逻辑顺序和索引顺序时相同的，每个表都可以有多个索引，但表的存储顺序只能有一种，InnoDB 是按照主键索引的顺序来组织表的
  - 主键唯一，且不会频繁更新
  - 主键的值应保证顺序增长，建议使用自增 Id
- 常见索引列：
  - select/update/delete 的 where 从句中使用的字段
  - order by/group by/distinct 中使用的字段
  - 多表 join 的关联字段
  - 将上述的字段建立联合索引而不是单独创建索引
- 索引列的顺序：
  - **区分度高**的在左侧，区分度 = 列中不同值的数量 / 列的总行数
  - **字段长度小**的列在左侧，字段长度越小，页存储的数据越多，IO 性能越好
  - **使用频繁**的列在左侧
- 避免冗余索引和重复索引：会增加查询优化器生成执行计划的时间
  - 重复索引：为 id 创建主键索引、唯一索引、普通索引
  - 冗余索引：(a, b, c) (a, b) (a)
- 对频繁的查询使用覆盖索引：即将查询结果的所有字段作为索引，**避免回表**，且覆盖索引按键值的顺序存储，能将磁盘的随机 IO 转变为索引上的**顺序 IO**
- 避免使用外键约束：但一定要在表之间的关联键上建立索引(会被频繁使用)
  - 外键的使用与维护会影响数据库性能，外键的约束可以在业务层实现

#### SQL 开发规范

- 运算推迟到业务层执行：减轻数据库负担，数据库只负责存储和管理数据
- 优化性能较差的 SQL：利用慢日志与 EXPLAIN 找到并优化慢 SQL
- 充分利用索引：避免索引失效的 SQL
  - like '%X' → 避免前置的 %，只有后置的 % 时也可以使用前缀索引
  - \>，\< 范围查询
  - 修改值的函数与计算
  - 查询的范围过大(in) → 使用 left join 或 not exists 优化 not in
  - 不遵守最左匹配原则 → 将会破坏的字段放至右侧
- 禁止使用 SELECT *：
  - 无法使用优化器覆盖索引的优化
  - 需要额外的开销解析 *
  - 会检索无用的字段，增加开销
  - SELECT [字段列表] 可以减小表结构变化带来的影响
- 禁止使用不含字段列表的 INSERT 语句
- 使用预编译语句进行数据库操作：
  - 预编译效率更高
  - 解决动态 SQL 的注入问题
- 避免数据类型的隐式转换：隐式转换会导致索引失效
  - 当操作符与不同类型的操作数一起使用时，会发生类型转换意识操作数兼容，当 where 查询操作符左边为字符类型时发生隐式转换会导致索引失效
- 避免使用子查询：子查询的结果集无法使用索引，因为子查询的结果集会被存储到临时表中，临时表不存在索引
  - 子查询在 in 语句中且 SQL 简单时可以优化为 join 操作
- 避免使用 JOIN 关联太多表：
  - MySQL 会对关联操作分配关联缓存，若一个 SQL 中关联的表过多，可能导致分配过多关联缓存，占用大量服务器内存
  - 关联表也会产生临时表，影响查询效率
- 减少数据库交互次数：将多个相同操作合并，进行批量处理
- 对同一列进行 or 判断时，使用 in 代替：or 大多数情况下很少利用索引
- 禁止使用 order by rand() 随机排序：order by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。
  - 将随机值的生成转移到业务层实现
- 明显不会有重复值时使用 UNION ALL 代替 UNION：
  - UNION 将两个结果集的所有数据放入临时表中进行去重
  - UNION ALL 不会对结果集去重
- 将大 SQL 拆分成多个小 SQL：
  - 大 SQL 逻辑复杂，需要占用大量 CPU 资源计算
  - MySQL 中一个 SQL 只能使用一个 CPU，SQL 拆分后能并行执行
- 程序连接不同的数据库时使用不同账号，禁止跨库查询：
  - 便于分库分表和数据库迁移
  - 降低业务耦合度
  - 避免权限过大而产生的安全风险

#### 操作行为规范

- 大批量(100w)写操作(UPDATE/INSERT/DELETE)要分批多次进行操作：
  - 大批量操作可能造成严重的主从延迟：执行时间长，从库需要等待主库执行完毕才能同步
  - binlog 日志过大：当 binlog 日志为 row 模式时，会将大批量操作的所有行都记录，产生大量的日志，增加日志传输与数据恢复的时间
  - 大量数据被锁定：大批量操作构成大事务操作，从而锁定大量数据，导致大量阻塞，影响性能，且长时间阻塞会占满数据库的可用连接，导致其他应用无法连接数据库
- 对大表使用 pt-online-schema-change 修改表结构：会先建立一个与原表结构相同的新表，在新表上进行结构修改，再把原表的数据复制到新表中，同时在原表添加触发器以获取修改期间新增的数据，修改与数据复制完成后替换原表
  - 避免大表修改产生的主从延迟
  - 避免在对表字段修改时进行锁表

### 分析性能

使用 EXPLAIN 命令分析 SQL 的执行计划，即一条 SQL 语句在经过查询优化器优化后的具体执行方式

EXPLAIN 并不会真的执行 SQL，只通过查询优化器对语句进行分析

#### 执行计划

SQL 语句在经过查询优化器优化后具体的执行方式

通过 EXPLAIN 命令获取：

- id：查询的序列标识符
- select_type：关键字对应的查询类型
- table：用到的表名
- partitions：匹配的分区，未分区则为 NULL
- type：查询执行的类型，描述查询如何执行，执行效率递减
  - system：表行数统计精确且只有一行记录(系统表)
  - const：表中最多只有一行匹配记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件
  - eq_ref：联表查询时，前表的行在后表中只有一行与之对应，是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为联表条件
  - ref：使用普通索引作为查询条件，查询结果可能有多个
  - index_merge：查询条件中使用了多个索引，表示开启 index_merge 优化，此时执行计划中的 key 列出使用到的索引
  - range：对索引列进行范围查询，key 列表示使用到的索引
  - index：查询遍历整棵索引树
  - ALL：全表扫描
- possible_keys：可能用到的索引
- key：实际用到的索引，为 NULL 时表示未使用索引
- rows：估算查询所需读取的行数
- Extra：解析查询的额外信息，便于理解查询的执行
  - Using filesort：排序时使用外部的索引排序
  - Using temporary：创建临时表存储查询结果
  - Using index：使用覆盖索引，没有回表
  - Using index condition：使用索引下推
  - Using where：使用了 WHERE 子句进行条件过滤，未使用索引时出现
  - Using join buffer：使用联表查询缓存

### 读写分离

将读操作和写操作分散到不同的数据库节点，小幅提升写效率，大幅提升读效率

![读写分离示意图](https://oss.javaguide.cn/github/javaguide/high-performance/read-and-write-separation-and-library-subtable/read-and-write-separation.png)

#### 实现

读写分离的实现一般包括：

1. 部署多台数据库，选择其中的一台作为主数据库，其他的作为从数据库
2. 保证主从之间实时同步，即主从复制
3. 系统将写请求交给主数据库处理，读请求交给从数据库处理

##### 代理方式

![代理方式实现读写分离](https://oss.javaguide.cn/github/javaguide/high-performance/read-and-write-separation-and-library-subtable/read-and-write-separation-proxy.png)

在应用和数据间加入一个代理层，由代理层负责分离应用程序的读写请求，并将其路由到对应的数据库中

##### 组件方式

引入第三方组件来在应用层面处理读写请求，如 sharding-jdbc

#### 主从复制

1. 主库将修改操作记录在 binlog 中
2. 从库通过 IO 线程向主库请求更新的 binlog
3. 主库使用 binlog dump 线程响应
4. 从库将 IO 线程中返回的 binlog 写入自身的 relay log
5. 从库执行 relay log 中的语句，即将主库的 SQL 再执行一次

#### 主从延迟

主库更新到从库更新之间存在时间差，即主从延迟

出现延迟的情况：

- 从库机器性能低于主库：从库接收 binlog 的速度跟不上主库更新 binlog 的速度
  - 从库的硬件升级，软件优化
- 从库处理的读请求过多：大量的读请求占用了执行 relay log 的资源，从库执行 relay log 的速度跟不上接收 binlog 的速度
  - 引入缓存
  - 将读请求分散到不同的从库
  - 使用其他系统提供查询，如将 binlog 接入至 Hadoop、Elasticsearch
- 大事务：运行时间长，生成的 binlog 大，且会长时间阻塞，导致主从延迟大
  - 将大 SQL 切分为若干个小 SQL 执行
  - 分批执行大批量修改
- 从库太多：主库需要将 binlog 同步给所有从库，导致主库压力太大，同步的时间和开销变高(后面的从库需要等待前面的 binlog 传输完成)
  - 减少从库数量，或给从库分级，由上层从库同步给下层
- 网络延迟
- 单线程复制：MySQL 5.6 引入了多线程复制，MySQL 5.7 进一步完善
- 复制模式：
  - 异步：MySQL 默认为异步复制，必定产生延迟
  - 全同步：全同步复制不存在延迟，但性能过差
  - 半同步：减少了主从延迟(仍然存在)，从 MySQL 5.5 开始以插件形式支持

避免主从延迟的方案：

- 从库数据过期时直接读取主库，实现简单，但会增加主库压力

- 延迟读取：在对主库完成写操作后，避免立即进行读操作，如支付完成后跳转至支付成功页，而不是直接返回至个人信息页
  - 延迟读取无法保证完全避免主从延迟，只能减少概率，故实际项目不会使用

### 分库分表

主要用于解决数据库中数据量过大的情况，减轻 MySQL 的存储压力

#### 分库

将数据分布在不同的数据库中

- 垂直分库：把单一数据库按业务划分，不同的业务使用不同的数据库
- 水平分库：把同一个表按一定规则拆分到不同的数据库中，每个库可以存在于不同的服务器上，实现水平扩展，解决单表存储和性能的问题

#### 分表

对单表的数据进行拆分

- 垂直分表：对数据表列的拆分，把列比较多的表拆分为多个表
- 水平分表：对数据表行的拆分，把行比较多的表拆分为多个表，解决单表数据量过大的问题
  - 通常将水平拆分的表存储在不同的库中，即水平分表常常伴随水平分库

#### 应用场景

- 单表数据量过大(千万级别)，数据库读写缓慢
- 数据库中数据量过大，占用空间过大，备份时间过长
- 应用并发量过大，单库单表无法处理

#### 分片算法

用于解决数据被水平分片后，每行数据存放在哪个库的问题

- 哈希分片：通过数据的 key 的哈希值(id)决定数据应存放于哪个库，适用于随机读写的场景，不适合范围查询
- 范围分片：按照特定的范围区间(id、时间)决定数据应存放于哪个库，如 id 在 [1, 100] 的存放在第一个库，由于数据未被离散，故在随机读写场景可能出现热点数据的问题，但适用于范围查询的场景

#### 分库分表产生的问题

- join：由于一张表被切分存放在不同库中，故无法直接使用 join 进行联表查询
  - 手动进行数据封装，在一个库中查询到表 A 的数据后再取另一个库中找表 B 的数据
  - 由于 join 操作的效率低，可以在业务层多次查询后封装来代替 join 操作
- 分布式事务：MySQL 自带的事务只针对一张表，故将表切分后无法使用，需要额外引入分布式事务
- 分布式自增：由于表被切分至多个库，故无法直接使用自带的自增 id，需要引入分布式 id
- 跨库聚合查询：常规聚合查询操作(order by、group by)会变得异常复杂，需要在多个分片上进行数据汇总和排序，故需要编写复杂的业务代码，或使用中间件协调分片间的通信和数据传输，会增加开发和维护的成本，以及影响查询的性能和可扩展性

#### 方案

- Apache ShardingSphere：一款分布式数据库生态系统，可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力增加
- TiDB：分布式关系型数据库，不需要手动进行分库分表(数据库层面实现)，也不需要解决分库分表引入的问题

#### 数据迁移

将原本单库单表的数据迁移至分库分表后的新库：

- 停机更新
- 双写方案：实现麻烦，可以借助第三方工具(Canal，实现类似主从同步，依赖 binlog)
  - 对旧库的更新会同步到新库(双写)，保证新库的数据是最新的
  - 只会让被更新操作过的旧库中的数据同步到新库，同时需要校验旧库和新库数据的差异，插入缺失的，删除冗余的

![](https://img-blog.csdnimg.cn/20200131215509563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdW1pbmc2OTA0NTIwNzQ=,size_16,color_FFFFFF,t_70)

### 深度分页

查询偏移量过大导致查询性能较低，因为 limit 语句会先扫描 offset + n 行，再丢弃掉前 offset 行，返回 n 行

```sql
# 在无法利用索引的情况下跳过 1000000 条请求后再获取 10 条记录
SELECT * FROM t_order ORDER BY id LIMIT 1000000, 10
```

即上述 SQL 会扫描 1000010 行，且因为无法利用索引，所以会回表 1000010 次

#### 优化

- 范围查询：保证 Id 连续性时，根据 Id 范围进行分页
  - 限制较大，一般项目无法保证 Id 完全连续

```sql
# 查询指定 ID 范围的数据
SELECT * FROM t_order WHERE id > 100000 AND id <= 100010 ORDER BY id
# 也可以通过记录上次查询结果的最后一条记录的ID进行下一页的查询：
SELECT * FROM t_order WHERE id > 100000 LIMIT 10
```

- 子查询：通过子查询获取 offset 中第一行对应的主键值，由此转为使用主键索引查询，减少回表次数
  - 子查询产生临时表，影响性能，且数据量过大时，临时表可能导致 OOM

```sql
# 通过子查询来获取 id 的起始值，把 limit 1000000 的条件转移到子查询
SELECT * FROM t_order WHERE id >= (SELECT id FROM t_order limit 1000000, 1) LIMIT 10;
```

- 延迟关联：使用 inner join 进行子查询，由此转换为主键索引

```sql
SELECT t1.* FROM t_order t1
INNER JOIN (SELECT id FROM t_order limit 1000000, 10) t2
ON t1.id = t2.id
LIMIT 10;
```

- 覆盖索引：建立覆盖索引避免回表，若查询结果集占表的总行数的很大一部分，则自动转换为全表扫描

### 冷热分离

根据访问频率和业务重要性将数据分为冷数据与热数据，冷数据存储在低成本、低性能的介质中，热数据存储在高性能的介质中

热数据：频繁访问、修改，且对访问速度有要求

冷数据：不常使用，对当前项目价值较低，但仍需要保存的数据

冷热分离能够优化热数据的查询，节约服务器成本，但由于冷热分离会将数据分开存储，故增加了开发和维护的成本，增加数据错误的风险，降低了统计的效率

#### 冷数据迁移

- 业务层实现：在写操作前判断数据冷热，之后再写入对应的库
  - 冷热判断难以界定，且每次变更标准都要修改业务层代码
- 任务调度：利用任务调度平台定时扫描数据库，将满足冷数据条件的数据批量迁移到冷库
  - 修改代码非常少，适用于按照时间区分冷热的场景
- 监听数据库 binlog：将满足冷数据条件的数据从 binlog 中提取出来迁移到冷库
  - 不需要修改代码，不适用于按照时间区分冷热的场景

#### 冷数据存储

容量大、成本低、可靠性高，可以适当牺牲访问速度

- 直接使用项目当前的数据库，但需要解决跨库查询的问题
- Hbase、RocksDB、Doris、Cassandra
- TiDB 内置支持冷热分离

### 主键自增

自增主键并不能保证主键连续递增

- 自增初始值和步长不为 1：