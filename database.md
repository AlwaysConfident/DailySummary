# 数据库

- 元组：关系是一张表，表中的每行就是一个元组
- 码：唯一标识实体的属性，对应表中的列
- 候选码：关系中的某一属性/属性组的值能唯一标识一个元组，而其任何子集都不能再标识，则该属性组为候选码
  - 主键 → 学号
  - 候选码 → 姓名，班级(只有这两者也能唯一标识一个学生)
- 主键：从候选码中选出的一个，一个表中只能有一个且不能为空，不能重复
- 外键：一个关系中的属性是另一个关系中的主键，一个表中可以有多个外键，且可以为空，可以重复
  - 一般不适用外键：
    - 增加复杂性：每次 DELETE 和 UPDATE 都需要考虑外键约束；外键的关系是定死的，故需求变化时也需要对表做修改
    - 分库分表：分库分表下外键无法生效
  - 外键保证数据库的一致性和完整性，级联操作方便，减轻程序代码量，在不涉及分库分表且并发量不高的情况下可以使用
- 主属性：候选码中出现过的属性
- 非主属性：不在任何一个候选码中出现的属性

## 范式

- 1NF：属性不可再分
- 2NF：1NF 的基础上，消除了非主属性对于键的部分函数依赖(所以非主属性都依赖于主键)
- 3NF：2NF 的基础上，消除了非主属性对于键的传递函数依赖(所有非主属性都不依赖于其他非主属性)

范式有助于维护数据一致性和完整性，高级别的范式通常可以减少数据冗余，提高数据一致性，但也可能增加复杂性和查询性能的开销(联表查询)

### 1NF

属性不能再被分割，即这个字段只能是一个值，无法再分为多个其他的字段，1NF 是所有关系型数据库的基本要求

存在数据冗余过大、删除异常、插入异常、修改异常的问题

### 2NF

在 1NF 基础上，消除了非主属性对于键的部分函数依赖，2NF 在 1NF 的基础上增加了一个主键列，非主属性都依赖于主键

![第二范式](https://oss.javaguide.cn/github/javaguide/csdn/bd1d31be3779342427fc9e462bf7f05c.png)

- 函数依赖：在一张表中，可以由 X 确定 Y，即 X → Y，则 Y 函数依赖于 X
- 部分函数依赖：X → Y 且存在 X 的真子集 X0 → Y，则 Y 对X 部分函数依赖
  - 学生表 R(学号、身份证号、姓名)中，有 (学号、身份证号) → (姓名)、(学号) → (姓名)、(身份证号) → (姓名)，则姓名部分依赖于 (学号、身份证号)
- 完全函数依赖：某个非主属性数据项依赖于全部候选项，则为完全函数依赖
  - 学生表 R(学号、班级、姓名)中，有 (学号、班级) → (姓名)，即只有确定了学号和班级后才能唯一确定姓名，只知道学号或班级则无法确定姓名，故姓名完全函数依赖于 (学号、班级)
- 传递函数依赖：在 R(U) 中， X → Y，Y —/→ X，Y → Z，Z 不属于 Y，则 Z 对 X 传递函数依赖
  - 学生表 R(学号、姓名、系名、系主任) 中，学号 → 系名，系名 → 系主任，所以存在非主属性系名对学号的传递函数依赖

### 3NF

3NF 在 2NF 的基础上，消除了非主属性对键的传递函数依赖(任何非主属性不依赖于其他非主属性)，符合 3NF 要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常

## 存储过程

存储过程可以看作一些 SQL 语句的集合，中间加入逻辑控制语句，在业务复杂时比较实用，可以方便调用。

存储过程一旦调试完成后就能稳定运行，且使用存储过程比单纯 SQL 语句执行要快，因为存储过程预编译过

但存储过程在高并发、分库分表、需求更新频繁的场景应用不多，因为存储过程难以调试和扩展(无法配合中间件使用)，且没有移植性(数据库的升级、迁移)，还会消耗数据库资源

## drop vs delete vs truncate

|            | drop                                                         | delete                                              | truncate                                                     |
| ---------- | ------------------------------------------------------------ | --------------------------------------------------- | ------------------------------------------------------------ |
| 用法       | 删除表                                                       | 删除某一行数据，若不带筛选条件，则同 truncate       | 删除表数据，主键 id 从 1 开始                                |
| 数据库语言 | DDL，操作立即生效，原数据不放入 rollback segment，不能回滚，操作不触发 trigger | DML，操作放入 rollback segment 中，事务提交后才生效 | DDL                                                          |
| 执行速度   | 直接释放表占用的空间，速度最快                               | 执行时会产生数据库的 binlog 日志，需要消耗时间      | 执行时不会产生 binlog，但需要把表的自增值重置和索引恢复到初始大小 |

## NoSQL 

Not Only SQL，非关系型数据库，主要针对键值、文档、图形类型数据存储。

NoSQL 天生支持分布式、数据冗余、数据分片等特性，旨在提供可扩展的高可用高性能数据存储解决方案

NoSQL 适合需要灵活、可扩展、高性能和功能强大的数据库来提升用户体验的现代应用程序(移动、Web 和游戏应用程序)

- 灵活性：NoSQL 的架构灵活，便于迭代开发；NoSQL 的数据结构灵活，支持非关系型数据结构
- 可扩展性：NoSQL 天然支持分布式，可以通过增加分布式硬件集群来横向扩展，而不必使用更高性能的服务器纵向扩展
- 高性能：NoSQL 针对特定的数据模型和查询模式进行优化
- 功能强大：NoSQL 提供各种功能强大的 API 和数据类型

### SQL vs NoSQL

|              | SQL                                                          | NoSQL                                              |
| ------------ | ------------------------------------------------------------ | -------------------------------------------------- |
| 数据存储模型 | 结构化存储，具有固定行和列的表格                             | 非结构化存储：JSON、键值对、节点和边               |
| 重点         | 减少数据重复                                                 | 提升可扩展性，减少大规模数据的存储成本             |
| ACID         | 提供原子性、一致性、隔离性、持久性                           | 为了可扩展、高性能，通常不支持 ACID 事务           |
| 性能         | 取决于磁盘子系统，需要通过优化查询、索引和表结构获得最佳性能 | 性能由底层硬件集群大小、网络延迟及调用应用程序决定 |
| 扩展         | 垂直(使用性能更强的服务器扩展)，读写分离，分库分表           | 横向(增加服务器，基于分片机制)                     |
| 用途         | 普通企业级的项目的数据存储                                   | 用途广泛                                           |
| 查询语法     | SQL                                                          | 因数据库而异                                       |

### 存储类型

- 键值：每个项目都包含 key 和 value，极为灵活的数据库类型，因为应用可以完全控制 value 字段中存储的内容，没有任何限制

- 文档：数据被存储在类似 JSON 的文档中，清晰直观，每个文档包含成对的字段和值

  ![](https://www.runoob.com/wp-content/uploads/2013/10/Figure-1-Mapping-Table-to-Collection-1.png)

- 图形：旨在轻松构建和运行与高度连接的数据集一起使用的应用程序，实体作为顶点，实体之间的关系则被作为边，图形数据库的典型使用包括社交网络、推荐引擎、欺诈检测、知识图形

- 宽列：适用于存储大量数据，数据按列存储，故可以压缩大量重复的数据

## MySQL

MySQL 是一种关系型数据库，主要用于持久化存储系统中一些数据

MySQL 开源免费且比较成熟，默认端口为 3306

### 优点

- 开源免费
- 成熟稳定，功能完善
- 文档丰富，易于学习使用
- 开箱即用，操作简单，维护成本低
- 兼容性好，支持常见的操作系统与开发语言
- 生态完善
- 事务支持优秀
- 支持分库分表、读写分离、高可用

### 字段类型

- 数值类型
- 字符串类型
- 日期时间类型

![MySQL 常见字段类型总结](https://oss.javaguide.cn/github/javaguide/mysql/summary-of-mysql-field-types.png)

MySQL 中没有布尔值，一般使用 TINYINT(1) 存储 0 和 1 表示

#### 整数类型的 UNSIGNED

表示不允许负值的无符号整数，使用 UNSIGNED 属性能够将正整数的上限提高一倍(不需要存储负值)

可以用于从 0 开始递增的 ID 列，提高 ID 的上限范围

#### CHAR vs VARCHAR

- CHAR 为定长字符串，在存储时会在右边填充空格以达到指定长度，检索时去除空格，适用于长度较短或长度相差不大的字符串(手机号、身份证号)
- VARCHAR 为变长字符串，在存储时使用 1-2 个额外字节记录字符串长度，检索时不需要处理，适用于存储长度较长或长度相差大的字符串

CHAR(M) 与 VARCHAR(M) 都表示最多能保存 M 个字符数，所有字符类型(数字、字母、汉字)都只占用一个字符

#### VARCHAR(10) vs VARCHAR(100)

- 最大长度：10 vs 100；当 VARCHAR(10) 需要存储超过 10 个字符时，需要修改表结构
- 存储占用空间：都存储相同字符数的字符串时，占用的磁盘存储空间相同
- 内存占用：在内存中操作时，VARCHAR(100) 会占用 100 个字符的内存空间，无论其实际使用的大小

#### DECIMAL vs FLOAT/DOUBLE

- DECIMAL 是定点数，可以存储精确的小数(类比 BigDecimal)
- FLOAT/DOUBLE 为浮点数，只能存储近似的小数值

#### TEXT & BLOB

TEXT 类似于 CHAR 和 VARCHAR，但能存储更长的字符串(长文本数据，文章内容)

BLOB 存储二进制大对象，如图片、音视频

不推荐使用 TEXT 与 BLOB：

- 不能有默认值
- 只能在磁盘使用临时表
- 检索效率低
- 不能直接创建索引，需要指定前缀长度
- 可能消耗大量网络和 IO 带宽
- 可能导致表上的 DML 操作变慢

#### DATETIME vs TIMESTAMP

- 时区：DATETIME 没有时区信息，只保存当前会话设置的时区对应的时间；TIMESTAMP 与时区相关，存储的值会自动换算成服务器时区
- 存储空间：8 字节 vs 4 字节；TIMESTAMP 表示的时间范围更小(2038 年)
  - MySQL 5.6.4 前，DATETIME 与 TIMESTAMP 的存储空间是固定的
  - MySQL 5.6.4 后，两者的存储空间会根据毫秒精度不同而变化，DATETIME 为 5-8 字节，TIMESTAMP 为 4-7 字节
- 性能：TIMESTAMP 需要根据时区进行转换，所以从毫秒转换为 TIMESTAMP 时还要调用操作系统底层的系统函数保证系统时区的一致性，并且需要加锁操作

字符串存储时间：占用空间更大，且无法使用 API，效率更低(逐个字符比较)

数字时间戳：日期的排序、比较效率更高，跨系统更方便，但可读性较差

#### NULL vs ''

NULL != ''

- 含义：NULL 表示不确定的值，两个 NULL 也不一定相等；'' 表示空字符串
- 占用空间：NULL 占用空间；'' 长度为 0，不占用空间
- 函数运算：NULL 影响聚合函数结果，部分聚合函数会忽略 NULL 值(SUM、AVG、MIN、MAX)，COUNT(*) 时会计算 NULL 行
- 查询：NULL 值只能使用 IS NULL 或 IS NOT NULL 查询

### MySQL 架构

![](https://pic1.zhimg.com/80/v2-b29359b4bc5e849601c5df10a2a8e484_720w.webp)

- 连接器：身份认证与权限相关
- 查询缓存：执行查询语句时会先查询缓存(MySQL 8.0 后移除，因为不太实用)
- 分析器：对 SQL 语句进行词法、语法分析，了解 SQL 语句的目的与检查 SQL 语句的语法是否正确
- 优化器：MySQL 对 SQL 语句进行优化(索引)
- 执行器：先判断权限，之后执行 SQL 语句后从存储引擎返回数据
- 插件式存储引擎：负责数据的存储和读取，采用插件式架构，支持多种存储引擎

### 存储引擎

MySQL 支持多种存储引擎，5.5.5 之前默认使用 MyISAM，之后默认使用 InnoDB，且只有 InnoDB 为事务性存储引擎(支持事务)

存储引擎采用插件式架构，支持多种存储引擎，存储引擎是基于表而不是数据库

#### MyISAM vs InnoDB

- 行级锁：MyISAM 只有表级锁，即 MyISAM 一锁就是锁住整张表，影响并发性能；InnoDB 默认为行级锁
- 事务：MyISAM 不提供事务支持；InnoDB 提供了事务支持，实现了 SQL 标准定义的四个隔离级别，具有 commit 和 rollback 事务的能力，InnoDB 默认使用可重读隔离级别能够解决幻读问题(基于 MVCC 和 Next-Key Lock)
- 外键：MyISAM 不支持外键；InnoDB 支持外键
  - 一般在应用层面实现外键的功能，因为数据库中使用外键会增加数据库开销和复杂度，且外键不支持分库分表
- 数据库异常崩溃后的安全恢复：MyISAM 不支持；InnoDB 在异常崩溃后，数据库重新启动时会保证数据库恢复到崩溃前的状态(redo log)
- MVCC：MVCC 可以看作行级锁的升级，可以有效减少加锁操作，提高性能
- 索引：两者都使用 B+ 树作为索引的底层实现
  - MyISAM 中索引文件和数据文件是分离的
  - InnoDB 中数据文件本身就是索引文件，其表数据文件本身就是按 B+ Tree 组织的一个索引结构，树的叶节点 data 域保存完整的数据记录
- 性能：MyISAM 读写不能并发；InnoDB 在读写混合或只读模式下，读写能力随 CPU 核数线性增长

![常见的几种 MySQL 存储引擎对比](https://oss.javaguide.cn/github/javaguide/mysql/comparison-of-common-mysql-storage-engines.png)

### 索引

索引是一种用于快速查询和检索数据的数据结构，本质是一种排序好的数据结构

InnoDB 与 MyISAM 中使用 B+ 树作为索引结构

- MyISAM 中 B+ 树叶节点存放数据的地址，在索引检索时需要先找到索引值，再由其地址读取对应的数据(非聚簇索引)
- InnoDB 中 B+ 树的叶节点存放的是完整的数据记录，以表的主键作为 key，即表数据文件本身就是主索引(聚簇索引)，其余索引为辅助索引，辅助索引中叶节点存储的是主键的值(非聚簇索引)
  - 根据主索引搜索时，直接找到 key 所在的节点即可取出数据
  - 根据辅助索引搜索时，需要找到 key 对应的主键的值，再使用主键值在主索引中搜索

优点：

- 索引能够大大加快数据检索的速度
- 唯一性索引能够保证数据的唯一性

缺点：

- 对数据做修改时也需要为索引的维护花费额外的开销
- 索引也会占用一部分物理空间

#### 底层数据结构

- 哈希表：使用哈希算法能通过键值对快速检索对应的数据(一次定位)，但是 InnoDB 不支持常规的哈希索引
  - InnoDB 提供了自适应哈希的实现，即使用 B+ 树作为哈希桶，减少哈希冲突链的长度，提高索引效率
  - 由于哈希表无法实现顺序、范围(每次只能查询一个)查找，故不常用
- BST：二叉搜索树的效率依赖于树的结构，退化成链表时效率极低 O(n)
- AVL 树：自平衡二叉搜索树会通过旋转操作保证左右子树高之差不超过 1，即搜索树不会退化，达到查找/插入/删除的平均效率都在 O(logn)
  - 但自平衡频繁的旋转操作会产生巨大的计算开销 O(logn)
  - 每个节点只能存储一个数据，即每次磁盘 IO 都只能读取一个节点数据，查询的数据分布在多个节点上时会进行多次磁盘 IO
- 红黑树：红黑树通过变色和旋转来维持黑高平衡，可能导致树的高度较高，查询效率降低，一些数据需要多次磁盘 IO 操作才能查到
  - 红黑树在插入和删除时只需要 O(1) 次数的旋转与变色，故插入和删除的效率较高
- B & B+ 树：B+ 树比 B 树具备更少的 IO 次数(直到叶节点才进行磁盘 IO)，更稳定的查询效率(查询必定到达叶节点)，更适于范围查询(叶节点保存指向兄弟节点的指针)
  - 数据存储：B 树的数据存储在叶节点与中间节点；B+ 树的数据只存储在叶节点
  - 叶节点：B 树的叶节点是独立的，无法直接获取兄弟节点信息；B+ 树的叶节点保存指向兄弟节点的指针
  - 检索顺序：B 树的检索过程类似二分查找，可能未到达叶节点就结束(中间节点也存储数据)；B+ 树的检索一定要到达叶节点(只有叶节点才存储数据)，检索效率更稳定
  - 范围查询：B 树中进行范围查询时，首先找到查询的下限，然后对 B 树进行中序遍历找到上限；B+ 树的范围查询只需要对叶节点的链表遍历

#### 索引类型

底层存储方式：

- 聚簇索引：索引结构与数据一起存放(InnoDB 中的主键索引)
  - 优点：
    - 查询速度快，不需要额外的磁盘 IO
    - 便于排序查找和范围查找：叶节点存储的数据有序且连续
  - 缺点：
    - 依赖于有序的数据：要求插入的数据是有序的，对于长且难排序的数据效率较低
    - 更新开销大：表数据更新时，索引存储的数据也需要同步更新，故对于主键索引来说，主键一般不可修改
- 非聚簇索引：索引结构与数据分开存放(InnoDB 中的辅助索引，MyISAM 中的索引)
  - 优点：
    - 更新开销小：叶节点存储的是指向主键/数据的地址，故表数据更新时维护索引的开销更小
  - 缺点：
    - 依赖于有序的数据
    - 二次查询(回表)：查到索引对于的指针/主键后，还需要再到对应的数据文件/表中查询，若查询的数据就是索引本身(查询主键)，则不需要回表

![聚簇索引和非聚簇索引](https://oss.javaguide.cn/github/javaguide/database/mysql20210420165326946.png)



应用维度：

- 主键索引：数据表的主键列使用的索引，唯一且不为 NULL，表中没有主键时，InnoDB 会选择表中有唯一索引且不允许 NULL 值的字段，否则会自动创建一个 6 Byte 的自增主键
- 辅助索引/二级索引：二级索引的叶节点存储的数据是主键，即通过二级索引定位主键的位置
  - 唯一索引：属性列不可重复，允许为 NULL，一张表中允许多个唯一索引，建立唯一索引主要用于确保对应属性列数据的唯一性
  - 普通索引：唯一作用是快速查询数据
  - 前缀索引：只适用于字符串类型，对文本的前几个字符创建索引，故比普通索引更小
  - 全文索引：为了检索大文本数据中的关键字信息，目前搜索引擎数据库使用的一种技术，效率极低，通常由搜索引擎(ElasticSearch) 代替
- 覆盖索引：将所有要查询的字段作为索引，减少回表次数
- 联合索引：使用表中多个字段创建索引
  - 最左前缀匹配原则：在使用联合索引时，MySQL 根据联合索引中的字段顺序，从左到右依次到查询条件中匹配(a 相等时再根据 b 排序)，全部字段匹配完成，或遇到范围查询(>、<)时停止匹配(a > 1 and b = 2，此时无法确定 a 的值不固定，无法确定 b 的顺序，即无法使用 B+ 树)

#### 索引下推

MySQL 5.6 中提供的一项索引优化功能，在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数

即先用索引中的信息对查询进行筛选

```sql
select * from tuser where name like '张%' and age=10;
```

不使用 ICP：浪费联合索引中的 age 字段

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c97ed6c5e395416181cb57591151fb09~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

使用 ICP：通过联合索引中的 age 字段先进行筛选

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8edc3c9af2e5403da79f77e50adaecd3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

#### 正确使用索引

- 选择合适的字段：
  - 不为 NULL：NULL 值难以优化，必要时可使用 0/1/true/false
  - 频繁查询的字段：索引应被频繁查询
  - 作为条件查询的字段
  - 频繁需要排序的字段：索引已被排序，这样查询可以直接利用索引的排序
  - 频繁用于连接的字段：提高多表连接查询效率
- 避免使用频繁更新的字段：字段更新需要同步维护索引
- 限制表索引数量：过多的索引会影响修改表的效率
- 联合索引优于单列索引：索引占用磁盘空间，若每个索引看作一个 B+ 树，大表的单列索引占用空间较多，且维护的开销更大，联合索引将多个字段结合，可以节省空间同时减少开销
- 避免冗余索引：索引 (a,b) 包含索引 (a)
- 字符串类型字段使用前缀索引替代普通索引：占用空间更小
- 删除长期未使用的索引
- 分析语句是否使用到索引查询：使用 EXPLAIN 命令

#### 索引失效

- 查询条件未遵守最左匹配原则
- 使用函数/计算：改变了索引列原来的值的操作会导致索引失效(函数不一定)
  - MySQL 8.0 增加了函数索引，既可以针对函数计算后的值建立一个索引
- Like %：范围比较小时('A%')使用较低级别的索引(普通索引)，范围非常大时('%A')索引失效
- OR 导致索引失效：OR 的两边含有非索引列
- IN 导致索引失效：IN 必定使用索引查询，但当范围过大时会使用全表扫描，导致索引失效
- ORDER BY：使用索引则需要回表排序，MySQL 会跟直接全表扫描排序的效率比较，选择更高的一方

#### select *

select * 不会导致索引失效(where 查询范围过大时会导致失效)，但仍不建议使用：

- 增加查询分析器解析成本
- 增减字段容易与 resultMap 不一致
- 无用字段增加网络消耗(text 类型字段)

### 查询缓存

执行查询语句时会先查找缓存，在 MySQL 8.0 中移除(不实用)

开启查询缓存后在同样的查询条件及数据情况下，会直接在缓存中返回结果

查询不命中：

- 两个查询的任何字符上的不同
- 查询中包含自定义函数、存储函数、用户变量、临时表、MySQL 系统表
- 缓存的表发生变化(数据、结构)

缓存虽然能提升查询效率，但维护缓存的开销较大(每次查询都要更新缓存，缓存失效时也要清除)

### 日志

- 错误日志：记录 MySQL 的启动、运行、关闭过程
- 二进制日志：binary log 记录更改数据库数据的 SQL 语句
- 一般查询日志：已建立连接的客户端发送给服务器的所有 SQL 记录，默认关闭(量比较大)
- 慢查询日志：记录执行时间超过阈值或没有使用索引的查询，解决 SQL 慢查询问题，默认关闭(实际项目中可能比较大)
- 事务日志：重做日志(redo log)，回滚日志(undo log)
- 中继日志：relay log 是复制过程中产生的日志，类似 binary log，主要针对主从复制的从库
- DDL 日志：记录 DDL 语句执行的元数据操作

#### 慢查询日志

记录执行时间超过阈值的查询，找到慢 SQL 是优化的第一步

```sql
-- 通过以下命令查看慢日志
show global status like '%Slow_queries%'
```

获取到慢 SQL 后，可以通过 EXPLAIN 命令获取执行计划相关信息，再根据其结果进行优化

#### binlog

二进制日志主要记录更新数据库数据的 SQL 语句(所有 DDL 和 DML 语句，不包括 SELECT/SHOW 等不修改数据库的语句)

```sql
-- 通过一下命令查看 binlog
show binary logs;
```

使用 MySQL 内置的 binlog 查看工具 mysqlbinlog 解析二进制文件

binlog 通过追加方式写入，大小没有限制，通过 max_binlog_size 参数设置每个文件最大容量，超出后会新增文件

##### 记录方式

一共有三种类型的二进制记录方式：

- Statement：记录每条会修改数据库的语句，MySQL 5.7.7 前默认为 Statement
  - 日志文件更小，磁盘 IO 压力较小，性能更好，但准确性更低
- Row：记录每一行的具体变更事件，MySQL 5.1.5 开始支持
  - 若一条 SQL 语句修改了 1000 条数据，Statement 只会记录一条 SQL 语句，Row 则会记录 1000 条修改记录
- Mixed：默认使用 Statement，少数特殊具体场景切换到 Row，MySQL 5.1.8 开始支持，MySQL 5.7.7 之后默认为 Mixed

##### 应用场景

binlog 主要用于主从复制，保证数据一致性，也可以用于数据恢复

主从复制：

![](https://pic4.zhimg.com/v2-12f36a0aa2ea88020809173182e54e73_r.jpg)

1. 主库将数据库中的变化写入 binlog
2. 从库连接主库
3. 从库创建 IO 线程向主库请求更新的 binlog
4. 主库创建一个 binlog dump 线程发送 binlog 由从库的 IO 线程接收
5. 从库的 IO 线程将接收的 binlog 写入 relay log 中
6. 从库的 SQL 线程读取 relay log 同步到本地数据(再执行一次 SQL)

##### binlog 写入磁盘

事务在执行过程中，会先把日志写入内存中的 binlog cache，只有事务提交时才真正写回磁盘中的 binlog(事务会回滚，且写入内存的效率更高)

由于事务的原子性，无论多大的事务都需要一次性写入 binlog，故当分配的 binlog cache 不足时，会将存储内容暂存到磁盘

binlog 写回磁盘的时机分为 0-N：

- 0：不强制要求，系统自行判断，MySQL 5.7 前默认为 0
- 1：每次提交事务都将 binlog 写回磁盘，MySQL 5.7 后默认为 1
- N：每提交 N 个事务才将 binlog 写回磁盘，有丢失的风险

##### 重写生成 binlog

- MySQL 服务器停止或重启
- 使用 flush logs 命令
- binlog 文件大小超出限制

#### redo log

InnoDB 以页为单位管理存储空间，即数据存储在页中

为了减少磁盘 IO，在内存中使用 Buffer Pool 缓冲池，当数据不在 Buffer Pool 中时，MySQL 会先将磁盘上的页缓存到 Buffer Pool 中，之后的操作也基于 Buffer Pool 中的页，提高读写性能

当事务提交至 Buffer Pool，还未写回磁盘时，MySQL 宕机，此时需要 redo log 来维护数据的持久性

redo log 记录页的修改，每一条记录包含表空间号、数据页号、偏移量、具体修改的数据，在事务提交时会将 redo log 按照写回磁盘的策略写到磁盘中，MySQL 故障重启后也能根据 redo log 恢复未写入的数据，即 redo log 提供了崩溃恢复的功能

![](https://pic2.zhimg.com/80/v2-8b45c811e7502bb04f0a370615380875_720w.webp)

redo log 写回磁盘的时机：

- 事务提交：事务提交时，log buffer 中的 redo log 会被写入磁盘
- log buffer 空间不足：log buffer 中缓存的 redo log 占据 log buffer 一半左右的空间时
- 事务日志缓存区满：InnoDB 使用事务日志缓冲区(transaction log buffer)来暂时存储事务的重做日志条目
- Checkpoint：InnoDB 定期执行检查点操作，将内存中的脏数据(已修改，未写回磁盘)写入到磁盘，同时将 redo log 写回磁盘保证数据的一致性
- 后台刷新线程：InnoDB 后台线程周期性地将脏页写回磁盘，并将相关的 redo log 写回磁盘，即未提交事务的 redo log 也可能写回磁盘
- 正常关闭服务器：MySQL 关闭时，redo log 会全部写回磁盘

redo log 写回磁盘的策略：

- 0：每次事务提交时不写回磁盘，性能最高，但最容易丢失信息
- 1：每次事务提交时都写回磁盘，性能最低，但最安全，默认为 1
- 2：每次事务提交时将 log buffer 中的 redo log 写入 page cache(文件系统缓存)

当 redo log 写入 log buffer 还未写入 page cache，或写入 page cache 还未写入磁盘时都可能发生丢失

redo log 采用循环写入的方式：

![](https://pic3.zhimg.com/80/v2-80c7219fb4a27e55110b8d6a0e3ee632_720w.webp)

write pos 表示 redo log 当前记录写到的位置，checkpoint 表示 redo log当前要写回磁盘的位置，当  write pos 追上 checkpoint 时表示 redo log 文件被写满，此时 MySQL 会阻塞所有数据库更新操作(无法写入 redo log)

##### 页修改后不直接写入磁盘

InnoDB 中的页比较大，可能只修改几个字节就要导致整个页都重新写入磁盘，且修改的页可能不相邻，若每次修改页都直接写回磁盘，则会产生大量的随机磁盘 IO，导致性能极差

redo log 的写入是顺序的磁盘 IO，且 redo log 相比页较小

#### binlog vs redo log

- 用途：binlog 用于还原数据库，属于数据级别的数据恢复，主要用于主从复制；redo log 主要用于保证事务的持久性，属于事务级别的数据恢复
- 实现：binlog 由存储引擎实现(InnoDB)；redo log 由 MySQL 的 Server 层实现
- 类型：binlog 属于逻辑日志，主要记录数据库执行的 DDL 与 DML 语句；redo log 属于物理日志，主要记录页的修改
- 文件大小：binlog 文件默认无上限，会一直追加；redo log 采用循环写方式，当写满时会阻塞所有更新操作

#### undo log

每个事务对数据的修改都会被记录到 undo log，当执行事务需要回滚时，MySQL 可以利用 undo log 将数据恢复到事务开始前的状态

undo log 属于逻辑日志，记录 SQL 语句，如事务执行一条 DELETE 语句，undo log 就会记录一条 INSERT 语句

MVCC 中也使用 undo log 获取当前数据行之前的版本信息(非锁定读取)

### 事务

事务是逻辑上的一组操作，要么都执行，要么都不执行

#### 数据库事务

数据库事务保证多个数据库操作构成逻辑上的整体

事务的特性：

- Atomic：原子性，即事务要么全部成功，要么全部失败
- Consistent：一致性，事务执行前后的数据具有一致性(转账操作，事务执行前后，无论成功与否，钱的总数是不变的)
- Isolate：独立性，多个事务之间互不影响
- Duration：持久性，事务执行的结果是持久的，即使数据库发生故障也不会影响

只有在实现了 AID 后才能实现 C，即 AID 是实现 C 的手段

#### 并发事务

- 脏读：事务 A 修改数据 X，还未提交时事务 B 读取 X，之后事务 A 回滚，导致事务 B 读到的数据 X 是错误的脏数据
- 丢失修改：事务 A 修改数据 X，还未提交时事务 B 也修改 X，导致事务 A 的修改丢失
- 不可重读：事务 B 在一个事务中多次读取 X，事务 A 在读取期间修改 X，导致事务 B 在一个事务中读到的 X 的值不同
  - 不可重读的重点为内容修改、记录减少
- 幻读：事务 A 在一个事务中范围读取 n 个数据，事务 B 同时插入一个数据，此时事务 A 在一个事务中读取到 n+1 个数据
  - 幻读的重点为记录新增(读到原本不存在的数据)

#### 隔离级别

- READ-UNCOMMIT：事务能够读到其他事务未提交的修改
  - 脏读、幻读、不可重读
- READ-COMMIT：事务只能读到其他事务已提交的修改
  - 幻读、不可重读
- REPEATABLE-READ(默认隔离级别)：保证一次事务中对同一字段的多次读取结果一致，基于 MVCC 与 读写锁(Next-Key Lock) 实现
  - 当前读可能出现幻读
- SERIALIZABLE：完全服从 ACID，手动为所有事务排序执行，串行即杜绝了所有并行的问题，基于锁实现，在分布式事务下使用

#### 多版本并发控制 MVCC

MVCC 是一种并发控制机制，用于在多个并发事务同时读写数据库时保持数据的一致性和隔离性。

通过在每个数据行维护多个版本的数据，当事务需要修改数据时，生成一份数据的快照，事务修改副本而不是直接修改原数据

- 读操作：事务的读操作是在数据副本上进行，数据库会选择不晚于事务开始时间的最新版本，因此不会读到其他事务产生的修改
- 写操作：事务的写操作会产生一个新的数据副本，该副本的版本号同事务的版本号，修改完成后会提交至数据库，旧版本的副本仍被保留，保证写操作前的读操作不受影响
- 提交与回滚：事务提交后会生成一个新版本的副本以供之后的事务操作；事务回滚后其生成的副本也被丢弃，对其他事务没有影响
- 版本回收：为了避免版本号无限增长，不再使用的版本号会被定期回收

实现：MVCC 通过数据行的**隐藏字段**和 **Read View** 判断数据的可见性，若不可见，通过数据行的隐藏字段找到 **undo log** 中的历史版本

- 隐藏字段：InnoDB 为每行数据都新增了两个隐藏字段
  - 表示最后一次插入/更新该行的事务 id(delete 被视为更新)
  - 指向该行 undo log 的指针
- Read View：执行事务时产生的，用于可见性判断，保存当前对本事务不可见的其他活跃事务，包含以下字段
  - **下一个将被分配的事务 Id**，大于等于这个 Id 的数据版本均不可见
  - 活跃事务列表中的**最小事务 Id**，小于这个 Id 的数据版本均可见
  - Read View 创建时**其他未提交的活跃事务 Id 列表**，创建 Read View 时，将当前未提交事务 Id 记录，后续即使这些事务已提交也不可见
  - **当前事务 Id**
- undo log：用于读取之前版本的数据
  - insert undo log：在 insert 操作中产生的 undo log，由于 insert 操作只对事务本身可见，故 insert undo log 在 insert 完成后可以直接删除
  - update undo log：在 update 和 delete 操作中产生，事务提交后加入 undo log 链表，等待 purge 线程进行最后的删除

RC 与 RR 隔离级别下的差异：

- 可读提交：每次 select 查询前都生成 Read View
  - 由于一个事务中每次 select 都会生成新的 Read View，故若在两次 select 之间有其他事务提交，则两次生成的 Read View 不同，可能导致不可重读
- 可重读：在事务开始后，第一次 select 前生成一个 Read View

#### 一致性非锁定读

对每行数据增加一个版本号/时间戳，若读操作的版本号大于数据行的版本号(数据已更新)则可以直接读取，否则读取数据快照(历史数据)

在可重读与可读已提交两个隔离级别下，执行普通的 select 语句(不包括 select ... lock in share mode，select ... for update)时使用一致性非锁定读

#### 锁定读

执行以下语句时使用锁定读：

- select ... lock in share mode
- select ... for update
- insert/update/delete

即每次读到的必定是最新的数据(当前读)

锁定读会对读取到数据加锁：

- 当前数据加读锁时，其他事务也可以加读锁，但不可以加写锁
- 当前数据加写锁时，其他事务不能加任何锁

幻读：若不加写锁，则事务在两次当前读的间隙中，插入新的数据就会产生幻读，InnoDB 使用 Next-key Lock 锁定事务当前读的间隙，防止其他事务在查询范围内插入数据

#### 当前读 vs 快照读

快照读即大部分 SELECT 语句，每行记录都存在多个历史版本，若读取的记录正在执行 UPDATE/DELETE 操作，读取操作不会等待写锁释放，而是直接去读行的快照，适用于要求高性能且允许误差的场景

快照读只存在 RC 与 RR 的隔离级别中：

- RC：为事务中每个 SELECT 都生成一个 Read View
- RR：只在事务开始时生成 Read View

当前读保证读操作的结果一定是最新的，故需要读写锁保证数据的一致性，避免读到其他事务未提交的数据

### 锁

锁是常用的并发事务控制方法

#### 表锁 vs 行锁

- 粒度：表锁 → 整张表；行锁 → 相关记录(**针对索引字段加锁**，索引失效或 where 条件中字段没有命中唯一索引时会退化为表锁，即对全部行加锁)
- 开销：行锁的开销更大，加锁更慢，会出现死锁，但在并发场景的效率高于表锁
- 实现：表锁与存储引擎无关；行锁在存储引擎层面实现

#### 行锁种类

- 记录锁：属于单个行记录上的锁
- 间隙锁：锁定一个范围，不包括记录本身
- 临键锁：记录锁 + 间隙锁，锁定一个范围，包含记录本身，用于避免当前读的幻读问题
  - 在 RR 隔离级别下的默认行锁，但操作索引是唯一/主键时会自动优化为记录锁

#### 意向锁

事务加表锁时，需要判断表中是否存在行锁，若每行逐个判断效率太低，故引入意向锁提高效率

- 意向共享锁(IS)：每当要对行加共享锁时，必须先获取表的 IS 锁
- 意向互斥锁(IX)：每当要对行加互斥锁时，必须先获得表的 IX 锁

意向锁由数据库引擎自行维护

意向锁之间兼容，但意向互斥锁与互斥锁都不兼容

|       | IS 锁 | IX 锁 |
| ----- | ----- | ----- |
| IS 锁 | 兼容  | 兼容  |
| IX 锁 | 兼容  | 兼容  |
| S 锁  | 兼容  | 互斥  |
| X 锁  | 互斥  | 互斥  |

### 性能优化

#### 基本设计规范

- 数据库和表的字符集统一使用 UTF-8：兼容性更好，统一字符集避免字符集转换产生的乱码，不同字符集进行比较前需要进行转换会造成索引失效
  - 存储 emoji 时需要使用 utf8mb4
- 控制单表数据量(500w)：数据量过大会影响表的结构修改、备份、修复
  - 历史数据归档(日志数据)、分库分表(业务数据)
- 谨慎使用分区表：将表进行分区，划分为若干个小表，在物理上存储在多个文件中，在逻辑上表现为同一张表。执行查询时，优化器通过分区键筛选出数据所在的分区，从而避免扫描所有分区
  - 使用物理分表管理大数据
  - 谨慎选择分区键，跨分区的查询效率低
- 将经常一起使用的列放在同一个表中：避免更多的联表操作
- 禁止存储较大的二进制数据(文件、图片、视频)：严重影响数据库性能，消耗大量存储空间
  - 应存储在文件服务器，数据库中只存储地址

#### 字段设计规范

- 优先选择符合存储需要的最小数据类型：占用空间更小，性能更高
  - 使用数字类型存储字符串(IP)：INET_ATON() 将 ip → 无符号整型，INET_NTOA() 将整型的 ip → 地址
  - 使用无符号类型存储非负数
  - 使用 TINYINT 存储小数值
- 避免使用 TEXT 与 BLOB：MySQL 内存临时表不支持 TEXT 与 BLOB，即使用 TEXT/BLOB 时必须使用磁盘临时表，且 TEXT/BLOB 只支持前缀索引，效率较低
  - 必须使用时应将 TEXT/BLOB 列分离至单独的扩展表中，查询时只取必要的列
- 避免使用 ENUM 类型：
  - 修改需要使用 ALTER 语句
  - ORDER BY 操作效率低，需要额外操作
  - 使用数字作为枚举值时会混淆字面值与 ENUM 内部索引值
- 尽可能使用 NOT NULL 列：
  - 索引 NULL 列需要额外空间保存
  - 对 NULL 值进行比较与计算需要特别处理
- 避免使用字符串存储日期：
  - 难以比较，需要逐个字符对比，且无法使用日期相关 API
- 金额相关应使用 DECIMAL 字段：能够精确表示小数，且能存储更大的整数类型，但维护精度需要额外开销

#### 索引设计规范

- 限制表的索引数量：索引会影响表的插入与更新效率，过多的索引也会影响 MySQL 优化器生成执行计划的时间(需要选择使用哪个索引)
- 禁止全文索引：不适用于 OLTP 场景
- 禁止为每列创建单独的索引：效率低于联合索引
- 每个表都必须有主键：InnoDB 中数据存储的逻辑顺序和索引顺序时相同的，每个表都可以有多个索引，但表的存储顺序只能有一种，InnoDB 是按照主键索引的顺序来组织表的
  - 主键唯一，且不会频繁更新
  - 主键的值应保证顺序增长，建议使用自增 Id
- 常见索引列：
  - select/update/delete 的 where 从句中使用的字段
  - order by/group by/distinct 中使用的字段
  - 多表 join 的关联字段
  - 将上述的字段建立联合索引而不是单独创建索引
- 索引列的顺序：
  - **区分度高**的在左侧，区分度 = 列中不同值的数量 / 列的总行数
  - **字段长度小**的列在左侧，字段长度越小，页存储的数据越多，IO 性能越好
  - **使用频繁**的列在左侧
- 避免冗余索引和重复索引：会增加查询优化器生成执行计划的时间
  - 重复索引：为 id 创建主键索引、唯一索引、普通索引
  - 冗余索引：(a, b, c) (a, b) (a)
- 对频繁的查询使用覆盖索引：即将查询结果的所有字段作为索引，**避免回表**，且覆盖索引按键值的顺序存储，能将磁盘的随机 IO 转变为索引上的**顺序 IO**
- 避免使用外键约束：但一定要在表之间的关联键上建立索引(会被频繁使用)
  - 外键的使用与维护会影响数据库性能，外键的约束可以在业务层实现

#### SQL 开发规范

- 运算推迟到业务层执行：减轻数据库负担，数据库只负责存储和管理数据
- 优化性能较差的 SQL：利用慢日志与 EXPLAIN 找到并优化慢 SQL
- 充分利用索引：避免索引失效的 SQL
  - like '%X' → 避免前置的 %，只有后置的 % 时也可以使用前缀索引
  - \>，\< 范围查询
  - 修改值的函数与计算
  - 查询的范围过大(in) → 使用 left join 或 not exists 优化 not in
  - 不遵守最左匹配原则 → 将会破坏的字段放至右侧
- 禁止使用 SELECT *：
  - 无法使用优化器覆盖索引的优化
  - 需要额外的开销解析 *
  - 会检索无用的字段，增加开销
  - SELECT [字段列表] 可以减小表结构变化带来的影响
- 禁止使用不含字段列表的 INSERT 语句
- 使用预编译语句进行数据库操作：
  - 预编译效率更高
  - 解决动态 SQL 的注入问题
- 避免数据类型的隐式转换：隐式转换会导致索引失效
  - 当操作符与不同类型的操作数一起使用时，会发生类型转换意识操作数兼容，当 where 查询操作符左边为字符类型时发生隐式转换会导致索引失效
- 避免使用子查询：子查询的结果集无法使用索引，因为子查询的结果集会被存储到临时表中，临时表不存在索引
  - 子查询在 in 语句中且 SQL 简单时可以优化为 join 操作
- 避免使用 JOIN 关联太多表：
  - MySQL 会对关联操作分配关联缓存，若一个 SQL 中关联的表过多，可能导致分配过多关联缓存，占用大量服务器内存
  - 关联表也会产生临时表，影响查询效率
- 减少数据库交互次数：将多个相同操作合并，进行批量处理
- 对同一列进行 or 判断时，使用 in 代替：or 大多数情况下很少利用索引
- 禁止使用 order by rand() 随机排序：order by rand() 会把表中所有符合条件的数据装载到内存中，然后在内存中对所有数据根据随机生成的值进行排序，并且可能会对每一行都生成一个随机值，如果满足条件的数据集非常大，就会消耗大量的 CPU 和 IO 及内存资源。
  - 将随机值的生成转移到业务层实现
- 明显不会有重复值时使用 UNION ALL 代替 UNION：
  - UNION 将两个结果集的所有数据放入临时表中进行去重
  - UNION ALL 不会对结果集去重
- 将大 SQL 拆分成多个小 SQL：
  - 大 SQL 逻辑复杂，需要占用大量 CPU 资源计算
  - MySQL 中一个 SQL 只能使用一个 CPU，SQL 拆分后能并行执行
- 程序连接不同的数据库时使用不同账号，禁止跨库查询：
  - 便于分库分表和数据库迁移
  - 降低业务耦合度
  - 避免权限过大而产生的安全风险

#### 操作行为规范

- 大批量(100w)写操作(UPDATE/INSERT/DELETE)要分批多次进行操作：
  - 大批量操作可能造成严重的主从延迟：执行时间长，从库需要等待主库执行完毕才能同步
  - binlog 日志过大：当 binlog 日志为 row 模式时，会将大批量操作的所有行都记录，产生大量的日志，增加日志传输与数据恢复的时间
  - 大量数据被锁定：大批量操作构成大事务操作，从而锁定大量数据，导致大量阻塞，影响性能，且长时间阻塞会占满数据库的可用连接，导致其他应用无法连接数据库
- 对大表使用 pt-online-schema-change 修改表结构：会先建立一个与原表结构相同的新表，在新表上进行结构修改，再把原表的数据复制到新表中，同时在原表添加触发器以获取修改期间新增的数据，修改与数据复制完成后替换原表
  - 避免大表修改产生的主从延迟
  - 避免在对表字段修改时进行锁表

### 分析性能

使用 EXPLAIN 命令分析 SQL 的执行计划，即一条 SQL 语句在经过查询优化器优化后的具体执行方式

EXPLAIN 并不会真的执行 SQL，只通过查询优化器对语句进行分析

#### 执行计划

SQL 语句在经过查询优化器优化后具体的执行方式

通过 EXPLAIN 命令获取：

- id：查询的序列标识符
- select_type：关键字对应的查询类型
- table：用到的表名
- partitions：匹配的分区，未分区则为 NULL
- type：查询执行的类型，描述查询如何执行，执行效率递减
  - system：表行数统计精确且只有一行记录(系统表)
  - const：表中最多只有一行匹配记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件
  - eq_ref：联表查询时，前表的行在后表中只有一行与之对应，是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为联表条件
  - ref：使用普通索引作为查询条件，查询结果可能有多个
  - index_merge：查询条件中使用了多个索引，表示开启 index_merge 优化，此时执行计划中的 key 列出使用到的索引
  - range：对索引列进行范围查询，key 列表示使用到的索引
  - index：查询遍历整棵索引树
  - ALL：全表扫描
- possible_keys：可能用到的索引
- key：实际用到的索引，为 NULL 时表示未使用索引
- rows：估算查询所需读取的行数
- Extra：解析查询的额外信息，便于理解查询的执行
  - Using filesort：排序时使用外部的索引排序
  - Using temporary：创建临时表存储查询结果
  - Using index：使用覆盖索引，没有回表
  - Using index condition：使用索引下推
  - Using where：使用了 WHERE 子句进行条件过滤，未使用索引时出现
  - Using join buffer：使用联表查询缓存

### 读写分离

将读操作和写操作分散到不同的数据库节点，小幅提升写效率，大幅提升读效率

![读写分离示意图](https://oss.javaguide.cn/github/javaguide/high-performance/read-and-write-separation-and-library-subtable/read-and-write-separation.png)

#### 实现

读写分离的实现一般包括：

1. 部署多台数据库，选择其中的一台作为主数据库，其他的作为从数据库
2. 保证主从之间实时同步，即主从复制
3. 系统将写请求交给主数据库处理，读请求交给从数据库处理

##### 代理方式

![代理方式实现读写分离](https://oss.javaguide.cn/github/javaguide/high-performance/read-and-write-separation-and-library-subtable/read-and-write-separation-proxy.png)

在应用和数据间加入一个代理层，由代理层负责分离应用程序的读写请求，并将其路由到对应的数据库中

##### 组件方式

引入第三方组件来在应用层面处理读写请求，如 sharding-jdbc

#### 主从复制

1. 主库将修改操作记录在 binlog 中
2. 从库通过 IO 线程向主库请求更新的 binlog
3. 主库使用 binlog dump 线程响应
4. 从库将 IO 线程中返回的 binlog 写入自身的 relay log
5. 从库执行 relay log 中的语句，即将主库的 SQL 再执行一次

#### 主从延迟

主库更新到从库更新之间存在时间差，即主从延迟

出现延迟的情况：

- 从库机器性能低于主库：从库接收 binlog 的速度跟不上主库更新 binlog 的速度
  - 从库的硬件升级，软件优化
- 从库处理的读请求过多：大量的读请求占用了执行 relay log 的资源，从库执行 relay log 的速度跟不上接收 binlog 的速度
  - 引入缓存
  - 将读请求分散到不同的从库
  - 使用其他系统提供查询，如将 binlog 接入至 Hadoop、Elasticsearch
- 大事务：运行时间长，生成的 binlog 大，且会长时间阻塞，导致主从延迟大
  - 将大 SQL 切分为若干个小 SQL 执行
  - 分批执行大批量修改
- 从库太多：主库需要将 binlog 同步给所有从库，导致主库压力太大，同步的时间和开销变高(后面的从库需要等待前面的 binlog 传输完成)
  - 减少从库数量，或给从库分级，由上层从库同步给下层
- 网络延迟
- 单线程复制：MySQL 5.6 引入了多线程复制，MySQL 5.7 进一步完善
- 复制模式：
  - 异步：MySQL 默认为异步复制，必定产生延迟
  - 全同步：全同步复制不存在延迟，但性能过差
  - 半同步：减少了主从延迟(仍然存在)，从 MySQL 5.5 开始以插件形式支持

避免主从延迟的方案：

- 从库数据过期时直接读取主库，实现简单，但会增加主库压力

- 延迟读取：在对主库完成写操作后，避免立即进行读操作，如支付完成后跳转至支付成功页，而不是直接返回至个人信息页
  - 延迟读取无法保证完全避免主从延迟，只能减少概率，故实际项目不会使用

### 分库分表

主要用于解决数据库中数据量过大的情况，减轻 MySQL 的存储压力

#### 分库

将数据分布在不同的数据库中

- 垂直分库：把单一数据库按业务划分，不同的业务使用不同的数据库
- 水平分库：把同一个表按一定规则拆分到不同的数据库中，每个库可以存在于不同的服务器上，实现水平扩展，解决单表存储和性能的问题

#### 分表

对单表的数据进行拆分

- 垂直分表：对数据表列的拆分，把列比较多的表拆分为多个表
- 水平分表：对数据表行的拆分，把行比较多的表拆分为多个表，解决单表数据量过大的问题
  - 通常将水平拆分的表存储在不同的库中，即水平分表常常伴随水平分库

#### 应用场景

- 单表数据量过大(千万级别)，数据库读写缓慢
- 数据库中数据量过大，占用空间过大，备份时间过长
- 应用并发量过大，单库单表无法处理

#### 分片算法

用于解决数据被水平分片后，每行数据存放在哪个库的问题

- 哈希分片：通过数据的 key 的哈希值(id)决定数据应存放于哪个库，适用于随机读写的场景，不适合范围查询
- 范围分片：按照特定的范围区间(id、时间)决定数据应存放于哪个库，如 id 在 [1, 100] 的存放在第一个库，由于数据未被离散，故在随机读写场景可能出现热点数据的问题，但适用于范围查询的场景

#### 分库分表产生的问题

- join：由于一张表被切分存放在不同库中，故无法直接使用 join 进行联表查询
  - 手动进行数据封装，在一个库中查询到表 A 的数据后再取另一个库中找表 B 的数据
  - 由于 join 操作的效率低，可以在业务层多次查询后封装来代替 join 操作
- 分布式事务：MySQL 自带的事务只针对一张表，故将表切分后无法使用，需要额外引入分布式事务
- 分布式自增：由于表被切分至多个库，故无法直接使用自带的自增 id，需要引入分布式 id
- 跨库聚合查询：常规聚合查询操作(order by、group by)会变得异常复杂，需要在多个分片上进行数据汇总和排序，故需要编写复杂的业务代码，或使用中间件协调分片间的通信和数据传输，会增加开发和维护的成本，以及影响查询的性能和可扩展性

#### 方案

- Apache ShardingSphere：一款分布式数据库生态系统，可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力增加
- TiDB：分布式关系型数据库，不需要手动进行分库分表(数据库层面实现)，也不需要解决分库分表引入的问题

#### 数据迁移

将原本单库单表的数据迁移至分库分表后的新库：

- 停机更新
- 双写方案：实现麻烦，可以借助第三方工具(Canal，实现类似主从同步，依赖 binlog)
  - 对旧库的更新会同步到新库(双写)，保证新库的数据是最新的
  - 只会让被更新操作过的旧库中的数据同步到新库，同时需要校验旧库和新库数据的差异，插入缺失的，删除冗余的

![](https://img-blog.csdnimg.cn/20200131215509563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpdW1pbmc2OTA0NTIwNzQ=,size_16,color_FFFFFF,t_70)

### 深度分页

查询偏移量过大导致查询性能较低，因为 limit 语句会先扫描 offset + n 行，再丢弃掉前 offset 行，返回 n 行

```sql
# 在无法利用索引的情况下跳过 1000000 条请求后再获取 10 条记录
SELECT * FROM t_order ORDER BY id LIMIT 1000000, 10
```

即上述 SQL 会扫描 1000010 行，且因为无法利用索引，所以会回表 1000010 次

#### 优化

- 范围查询：保证 Id 连续性时，根据 Id 范围进行分页
  - 限制较大，一般项目无法保证 Id 完全连续

```sql
# 查询指定 ID 范围的数据
SELECT * FROM t_order WHERE id > 100000 AND id <= 100010 ORDER BY id
# 也可以通过记录上次查询结果的最后一条记录的ID进行下一页的查询：
SELECT * FROM t_order WHERE id > 100000 LIMIT 10
```

- 子查询：通过子查询获取 offset 中第一行对应的主键值，由此转为使用主键索引查询，减少回表次数
  - 子查询产生临时表，影响性能，且数据量过大时，临时表可能导致 OOM

```sql
# 通过子查询来获取 id 的起始值，把 limit 1000000 的条件转移到子查询
SELECT * FROM t_order WHERE id >= (SELECT id FROM t_order limit 1000000, 1) LIMIT 10;
```

- 延迟关联：使用 inner join 进行子查询，由此转换为主键索引

```sql
SELECT t1.* FROM t_order t1
INNER JOIN (SELECT id FROM t_order limit 1000000, 10) t2
ON t1.id = t2.id
LIMIT 10;
```

- 覆盖索引：建立覆盖索引避免回表，若查询结果集占表的总行数的很大一部分，则自动转换为全表扫描

### 冷热分离

根据访问频率和业务重要性将数据分为冷数据与热数据，冷数据存储在低成本、低性能的介质中，热数据存储在高性能的介质中

热数据：频繁访问、修改，且对访问速度有要求

冷数据：不常使用，对当前项目价值较低，但仍需要保存的数据

冷热分离能够优化热数据的查询，节约服务器成本，但由于冷热分离会将数据分开存储，故增加了开发和维护的成本，增加数据错误的风险，降低了统计的效率

#### 冷数据迁移

- 业务层实现：在写操作前判断数据冷热，之后再写入对应的库
  - 冷热判断难以界定，且每次变更标准都要修改业务层代码
- 任务调度：利用任务调度平台定时扫描数据库，将满足冷数据条件的数据批量迁移到冷库
  - 修改代码非常少，适用于按照时间区分冷热的场景
- 监听数据库 binlog：将满足冷数据条件的数据从 binlog 中提取出来迁移到冷库
  - 不需要修改代码，不适用于按照时间区分冷热的场景

#### 冷数据存储

容量大、成本低、可靠性高，可以适当牺牲访问速度

- 直接使用项目当前的数据库，但需要解决跨库查询的问题
- Hbase、RocksDB、Doris、Cassandra
- TiDB 内置支持冷热分离

### 主键自增

自增主键并不能保证主键连续递增

- 自增初始值和步长不为 1：手动插入的主键值大于原本下一个自增值时，会以步长逐步累加，直到找到大于插入主键的值作为下一个自增值，若步长不为 1，则可能导致不连续的 id
- 插入失败时自增值仍会修改：与 insert 的执行流程相关，SQL 失败/事务回滚时不会恢复自增值(提高性能，回滚自增值在并发场景会有冲突的风险)
  1. 执行器调用 InnoDB 引擎接口准备插入主键为 null 的记录
  2. InnoDB 发现用户没有指定自增 id 的值，则获取表当前的自增值 2
  3. 将传入记录的主键改为 2
  4. 将表的自增值改为 3
  5. 继续执行插入操作，此时报错/事务回滚，语句返回，但自增值并没有还原，导致之后插入的记录 id 不连续
- 批量插入语句：MySQL 提供的批量申请自增 id 的策略，同一个语句申请自增 id，每次申请到的自增 id 个数是上一次的两倍，避免大量数据逐个申请自增 id 带来的性能影响
  - 当批量插入的记录不为 2 的幂次方时，会分配多余的自增值，导致自增不连续

## Redis

将数据保存在内存中，存储 KV 键值对的 NoSQL 数据库

### Redis 的性能优势

- Redis 基于内存，内存的访问速度远快于磁盘
- Redis 基于 Reactor 模式实际开发了一套高效的事件处理模型，主要是单线程时间循环和 IO 多路复用
- Redis 内置了多种优化后的数据类型/结构

### 分布式缓存

#### Memcached vs Redis

- 共同点：
  - 基于内存的数据，一般用于缓存
  - 过期策略
  - 高性能
- 区别：
  - 数据类型：Redis 内置了多种优化过的数据类型/结构，支持更多应用场景；Memcached 只支持 KV 键值对
  - 数据持久化：Redis 支持将内存数据持久化到磁盘，重启后能够恢复(灾难恢复机制)，且内存耗尽后能将数据转移到磁盘；Memcached 只能将数据存储在内存，内存耗尽后会直接报错
  - 集群模式：Redis 原生支持 cluster 模式；Memcached 需要依赖客户端实现往集群中分片写入数据
  - 多线程：Redis 使用单线程的多路 IO 复用模型，在 Redis 6.0 中针对网络数据的读写引入了多线程；Memcached 使用多线程、非阻塞 IO 复用的网络模型
  - 扩展支持：Redis 支持发布订阅模式、事务、Lua 脚本等功能及多种编程语言
  - 过期策略：Redis 使用惰性删除与定期删除；Memcached 只用到惰性删除

### Redis 的必要性

- 高性能：若高频访问数据每次都从磁盘访问，带来的时间开销远大于从缓存访问(内存与磁盘)
- 高并发：Redis 的 QPS(每秒查询数)远大于 MySQL，即直接操作缓存能承受的请求数量远大于直接访问数据库，故使用缓存能提高系统整体的并发

### 缓存读写策略

#### 旁路缓存模式(Cache Aside Pattern)

服务端同时维护数据库和缓存(DB 和 cache)

写操作：

1. 写入数据库
2. 删除缓存：删除操作比更新操作更快，开销更少(只需要调用命令，不需要复杂的计算，且在读少写多的场景更有效)
   - 先删再写：由于写入数据库耗时较长，会导致在写入期间发生的读操作未命中缓存而将数据库中的旧数据写回缓存，使得缓存不一致
   - 先写再删：仍可能导致缓存不一致，但由于写入缓存的时间较短，不一致的概率较低
     1. 请求 A 读取数据库旧数据，未写回缓存
     2. 请求 B 更新数据库并删除缓存
     3. 请求 A 此时将旧数据写回缓存，导致缓存不一致

![](https://pic3.zhimg.com/80/v2-a6442ac36abd8c827bd53b7299380f26_720w.webp)

读操作：

1. 读取缓存
2. 缓存未命中则读取数据库，再将数据写回缓存

![](https://pic4.zhimg.com/80/v2-b6e237ce8bab2b688237781d7fdd3c1f_720w.webp)

缺点：

- 首次请求必须访问数据库：
  - 预热数据
- 频繁的写操作导致频繁删除缓存，降低缓存命中率
  - 写操作同步更新数据库与缓存，需要加锁保证线程安全
  - 延迟删除：允许短暂的缓存数据不一致，为缓存设置较短的过期时间，避免频繁更新导致的频繁删除

#### 读写穿透(Read/Write Through)

穿透即读写操作会通过缓存来对数据库执行

写操作：

1. 若缓存命中则直接更新缓存，再由缓存更新数据库
2. 缓存未命中则直接更新数据库

![](https://pic3.zhimg.com/80/v2-4262223ba42ac26bf8c5ba96a7cd39fa_720w.webp)

读操作：只从缓存获取数据

1. 缓存命中则直接返回
2. 缓存未命中则先从数据库中加载至缓存，再由缓存返回

![](https://pic1.zhimg.com/80/v2-67af24f125a1e7a772dab803b04e08cc_720w.webp)

读写穿透对旁路缓存进行封装，写回缓存的操作对客户端透明，虽然对客户端能够减少缓存数据不一致(客户端只会从缓存读取数据)，但 Redis 中并没有提供将缓存数据写回数据库的功能，且通过缓存负责数据库的读写会影响性能，故并不常用

缺点：

- 首次请求必须读取数据
  - 数据预热

#### 异步缓存写入(Write Behind Pattern)

与读写穿透一样由缓存负责数据库的读写，不同于读写穿透的同步更新，异步缓存写入会将缓存异步批量写回数据库

更难以维护数据一致性，若缓存还未写回数据库就崩溃，则会导致大量数据丢失

常用于消息队列中消息异步写入磁盘，InnoDB Buffer Pool，由于写性能高，适用于数据经常变化且对一致性要求不高的场景(浏览量、点赞)

### Redis Module

从 Redis 4.0 开始支持通过 Module 扩展 Redis 功能以满足特殊需求，Module 以动态链接库的形式加载到 Redis 中(灵活的动态扩展方式)

- RediSearch：搜索引擎
- RedisJSON：处理 JSON
- RedisBloom：实现布隆过滤器
- RedisCell：分布式限流

### 应用

#### 分布式锁

基于 Redisson 实现分布式锁

#### 限流

通过 Redis + Lua 脚本实现限流，使用 Redis 作为令牌桶或漏桶，由 Lua 脚本实现算法逻辑

#### 消息队列

使用 Redis 自带的 List 数据结构实现简单的消息队列

使用 Redis 5.0 引入的 Stream 类型，有主题和消费组的概念，支持消息持久化与 ACK 机制

#### 搜索引擎

引入 RediSearch 实现全文搜索引擎功能，支持中文分词、聚合统计、停用词、同义词、拼写检查、标签查询、向量相似度查询、多关键词搜索、分页搜索等功能

对比 Elasticsearch：

- 性能更高：Redis 基于内存存储；Elasticsearch 基于磁盘操作
- 占用内存更低：RediSearch 内部使用压缩的倒排索引(关键词 → 索引)，可以用较低的内存占用来实现索引的快速构建

RediSearch 搭配 RedisJSON 适用于小型项目的简单搜索场景，但在比较复杂或数据规模较大的场景有如下限制：

- 数据量限制：RediSearch 能存储的数据量受 Redis 可用内存限制
- 分布式能力差：RediSearch 虽然支持分布式部署，但仍需要处理数据分片、节点通信、数据一致性的问题
- 聚合功能弱：RediSearch 只支持简单的聚合操作

#### 延时队列

Redisson 内置延时队列，基于 Sorted Set 实现

#### 分布式 Session

利用 String 或 Hash 数据类型保存 Session 数据，所有服务器都可以访问

#### 复杂业务场景

- Bitmap 统计活跃用户
- Sorted Set 维护排行榜

### 数据类型

基本数据类型：

- String：二进制安全的数据类型，能够存储任何类型的数据
  - 底层为 Redis 构建的简单动态字符串(SDS)，可以保存文本数据及二进制数据，获取字符串长度复杂度为 O(1)，且 SDS API 是安全的，不会造成缓冲区溢出
  - 存储常规数据、简单计数(限流)、简易分布式锁
- List：Redis 实现的双向链表，可以基于 List 实现分页查询
  - 简易消息队列
- Set：无序且唯一的集合，可以轻易实现交集、并集、差集的操作
  - 统计场景：点赞统计
  - 集合操作：共同好友(交集)，好友推荐(差集)
  - 随机获取元素：抽奖
- Hash：String 类型的 KV 映射表，适用于存储对象
- Zset(Sorted Set)：通过权重参数 score 实现有序集合，且能通过 score 获取范围数据
  - 统计排行场景：实现排行榜

特殊数据类型：

- Bitmap：在 String 类型上定义的一组面向位的操作，Bitmap 存储连续的二进制数字(0/1)，只需要一个 bit 位表示某个元素对应的值或状态，key 就是对应元素本身，使用 Bitmap 本身会极大地节省存储空间
  - 需要保存状态信息(0/1 即可表示)：统计活跃用户 → 以日期为 key，用户 id 为 offset，活跃用户的 bit 设置为 1
- HyperLogLog：一种基数计数概率算法，占用空间极小，通过一定的概率统计方法预估基数值而不会直接存储元数据，因此 HyperLogLog 的计数结果存在误差，Redis 中提供两种计数方式：
  - 稀疏矩阵：计数较少，占用空间少
  - 稠密矩阵：计数达到阈值，占用 12k 的空间
  - 适用于海量计数场景：热门统计
- Geospatial：存储地理位置信息，基于 Sorted Set 实现，可以轻松计算两个位置距离、获取指定位置附近的元素(附近的人功能)

#### String vs Hash

- 存储内容：String 存储序列化后的整个对象数据；Hash 将对象的每个字段单独存储，可以只获取/修改其中的一部分，节省网络流量
- 占用空间：相同对象，String 占用空间约为 Hash 的一半，且便于存储具有多层嵌套的对象

对象中只有部分字段需要频繁改动/查询(购物车信息) → Hash

系统对性能与资源消耗敏感 → String

大多数情况下使用 String 即可

#### Sorted Set 底层实现

为了节约内存空间，集合元素的大小和数量小于阈值时由压缩列表(ziplist)存储，过大时才转换为跳表(dict + skiplist，使用字典提高获取指定元素的效率)

有序链表的增、删、查都为 O(n)，在数据量较大的场景性能较差，跳表通过添加多级索引，将复杂度降低至 O(logn)

![](https://img-blog.csdnimg.cn/2021052116261040.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTAzMjEwMTA=,size_16,color_FFFFFF,t_70)

跳表查询：

1. 从最高层开始，通过每一层的有序链表寻找目标节点位置
2. 找到则直接返回，否则在最大最小值处向下一层查询

跳表插入：

1. 新节点与各层索引节点比较，确定底层链表(原链表)插入位置
2. 插入底层链表后，通过随机算法确定是否提升为上一层索引

![](https://img-blog.csdnimg.cn/20210521162817416.gif#pic_center)

对比其他数据结构：

- AVL 树：增删改都为 O(logn)，且可以通过中序遍历实现范围查询，但每次插入/删除都需要旋转操作保持平衡
- 红黑树：只通过变色和旋转维持黑平衡，查询效率低于 AVL 树，但增删效率更高，跳表的实现更简单，且范围查询效率更高
- B+ 树：主要用于数据库和文件系统，核心是通过尽量少的磁盘 IO 定位到尽量多的索引来获取数据，但 Redis 基于内存且不会存储大量数据，使用跳表更容易实现与维护

### 持久化

将内存中的数据写回磁盘，便于重用(恢复)、同步

#### RDB 持久化

通过在特定时间点创建当前数据的副本(快照)来实现持久化 

创建快照后可以进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本(主从同步)，可以本地保存快照便于重启恢复

快照为 Redis 默认的持久化方式，通过 redis.conf 文件配置生成快照的时机：在 n 秒后，直到有 m 个 key 发生变化则创建快照

生成快照的命令：

- save：同步保存操作，阻塞 Redis 主线程
  - Redis 启动后以单线程完成工作
- bgsave：fork 出子线程执行，不阻塞主线程，默认选项
  - copy on write，子线程生成 RDB 过程中发生写操作，则会生成对应数据的拷贝供主线程操作，生成的 RDB 中不会包含该修改(RDB 为某个时刻的数据快照)


#### AOF 持久化

Append Only File，实时性更好的持久化方案，Redis 6.0 后默认开启

AOF 将每条修改数据的语句记录在缓冲区，再写入 AOF 文件(系统内核缓冲区中)，最后由系统调用 fsync 决定何时写入磁盘

##### 工作流程：

1. 命令追加(append)：将每条写命令追加到 AOF 缓冲区
2. 文件写入(write)：将 AOF 缓冲区的数据写入到系统内核缓冲区的 AOF 文件，需要调用 write 函数(系统调用)
   - write：写入系统内核缓冲区后直接返回，不同步到磁盘，产生数据丢失风险
3. 文件同步(fsync)：AOF 缓冲区根据 fsync 策略向磁盘做同步操作，需要 fsync 函数(系统调用)针对单个文件进行强制磁盘同步，fsync 阻塞至写入完成后返回，此时持久化完成
   - fsync：强制刷新系统内核缓冲区，确保写入磁盘后返回
4. 文件重写(rewrite)：定期对 AOF 文件进行重写、压缩，避免文件过大
5. 重启加载(load)：Redis 重启时可以通过 AOF 文件进行数据恢复

![AOF 工作基本流程](https://oss.javaguide.cn/github/javaguide/database/redis/aof-work-process.png)

##### 持久化方式：

- appendfsync always：写入(write)系统核心缓冲区后立即写回磁盘(fsync)，严重影响 Redis 性能
- appendfsync everysec：由后台线程每秒钟调用 fsync 函数同步
- appendfsync no：由操作系统决定何时调用 fsync 函数

从 Redis 7.0 开始使用 Multi Part AOF 机制，将 AOF 文件拆分成多个：

- BASE：基础 AOF 文件，由子进程通过重写产生，只能有一个
- INCR：增量 AOF 文件，在 AOFRW 开始执行时创建
- HISTORY：历史 AOF 文件，每次 AOFRW 完成时，之前的 BASE 和 INCR 会变为 HISTORY，此类 AOF 文件会被 Redis 自动删除

##### 先执行后记录：

- 避免额外检查开销，AOF 不对记录的语句进行语法检查
- 不阻塞命令执行
- 风险：
  - 数据丢失：刚执行完就崩溃
  - 阻塞后续命令执行：在 Redis 主线程记录日志

##### AOF 重写：

AOF 过大时，Redis 在后台自动重写 AOF 产生一个新的 AOF 文件，新的 AOF 文件和原有的 AOF 文件保存的数据库状态一致，且体积更小

AOF 重写只需要读取当前数据库中的所有键值对，而不需要对原有的 AOF 文件进行任何操作

AOF 重写涉及大量写操作，十分影响 Redis 性能，故重写操作在子进程中执行

在 AOF 重写过程中会维护 AOF 重写缓冲区，将重写期间的数据库修改命令记录在此，重写完成后再写入新的 AOF 文件(两次磁盘写，第一次将记录写入旧 AOF 文件)，在 Redis 7.0 后，利用 Multi Part AOF 的 BASE + INCR 独立文件存储方式优化内存和 IO 资源的开销(主进程在重写时将增量写入 INCR 文件)

Redis 7.0 前：

![](https://pic1.zhimg.com/80/v2-e64f2beffb455e8dec228f2bf6cef200_720w.webp)

Redis 7.0 后：由 manifest 管理 BASE 和 INCR，不再需要 aof_rewirite_buf，去掉对应的内存消耗，主进程和子进程之间也不再有数据传输和控制交互

![](https://pic3.zhimg.com/80/v2-ce157934471d8a75a0fd91bedb0d05e2_720w.webp)

##### AOF 校验机制：

通过校验和验证 AOF 文件是否完整

#### 混合持久化

Redis 4.0 开始支持 RDB 和 AOF 的混合持久化，AOF 会将 RDB 的内容写入 AOF 文件开头，快速加载的同时避免丢失过多数据，但 AOF 中 RDB 的部分可读性较差

#### RDB vs AOF

- 占用空间：RDB 存储压缩过的二进制数据，保存某个时间点的数据集，文件较小，便于数据备份和灾难恢复；AOF 存储写命令，文件较大，且重写开销较大(内存与磁盘 IO)
- 数据恢复：RDB 存储数据本身，在恢复时可以直接使用，速度较快；AOF 存储写命令，数据恢复时需要逐个执行
- 数据安全性：RDB 存储的数据需要经过处理，时间的开销导致无法实现实时或秒级持久化，且子进程生成快照也会造成 CPU 和内存开销；AOF 直接将写命令存储至系统内核缓冲区，再由操作系统写回磁盘，操作更轻量，能够实现秒级持久化(appendfsync everysec)
- 兼容性：旧版本 Redis 生成的 RDB 二进制文件在新版本中可能无法解析
- 可读性：RDB 存储的是二进制数据，可读性较差；AOF 文件中为 Redis 写命令，能够进行分析，且可以直接使用 AOF 进行操作

对数据安全性要求不是很严格的场景可以使用 RDB

使用 AOF 的同时定时生成 RDB 有助于数据快速恢复/重启

数据安全性要求较高的情况下应同时开启 RDB 与 AOF，或开启混合持久化

### Redis 线程模型

- 读写命令：单线程
- 大键值对的异步删除：Redis 4.0 引入多线程
  - 大键值对的删除需要释放大量的内存空间，即会耗费较长的阻塞时间，同步处理会影响 Redis 处理请求的性能
- 网络请求：Redis 6.0 引入多线程，默认关闭
  - Redis 的性能受限于内存与网络 IO
  - 通过 IO 线程对客户端请求进行读取与解析后==将命令交给主线程执行==
  - 将命令执行的返回通过 IO 线程响应给客户端

#### Redis 单线程模型

基于 Reactor 模型开发的网络事件处理器(文件事件处理器)，通过 IO 多路复用程序监听多个网络请求并根据当前执行的任务为其关联相关的事件处理器，当监听到请求准备好执行相关操作(accept/read/write/close)时，调用之前关联的事件处理器进行处理

IO 多路复用程序使单线程的文件事件处理器既实现了高性能的网络通信模型，又保持了 Redis 内部单线程设计的简单性

##### IO 多路复用监听大量客户端连接

![](https://img2020.cnblogs.com/blog/1323607/202006/1323607-20200613165540238-1561612908.png)

IO 多路复用程序会监听大量的客户端(socket)连接，将有效的请求注册到内核中进行监听，通过 select 及类似函数同时监控多个文件描述符(客户端连接)的可读可写情况，当某些文件描述符可读或可写时，select 方法返回可读及可写的文件描述符个数

使用 IO 多路复用可以避免 Redis 创建额外的线程监听客户端的大量连接，降低资源消耗

##### Redis 使用单线程的原因

- 可维护性：多线程会增加程序开发与维护的成本(并发控制、锁)，并发情况下需要考虑程序执行顺序
- 可用性：单线程也可以实现多线程的相关功能，利用 IO 多路复用程序能并发监听和处理大量的客户端请求
- 性能瓶颈(决定性原因)：多线程主要使程序充分利用 CPU 并发执行，但 Redis 在不开启 AOF 持久化的情况下完全不会涉及 IO 操作(基于内存)，即 ==Redis 不是 CPU 密集型的服务，其性能瓶颈主要在网络 IO(网络传输的延迟与客户端数据传输的阻塞)==
  - Redis 在普通的 Linux 服务器上也能达到 1000000/s 的处理速度，若不能满足时应先考虑分片交给多个 Redis 服务器处理
  - 且使用多线程也会带来线程上下文切换的开销

#### Redis 后台线程

主要逻辑通过主线程完成(单线程)，比较耗时的操作通过后台线程完成：

- 释放 AOF/RDB 产生的临时文件
- 调用 fsync 函数将系统内核缓冲区数据写回磁盘
- 回收大对象删除后占用的空间

### 内存管理

#### 过期时间

必要性：

- ==Redis 基于内存实现==，若存储的数据永久存在，则会耗费大量的内存空间(OOM)
- Redis 作为缓存，其中的很多数据都不需要长期保存，部分数据在业务上有过期的需求(验证码)

Redis 中只有 String 类型有内置的默认过期时间，其他类型都需要 expire 命令手动设置，且通过 persist 命令移除一个键的过期时间

过期判断：通过过期字典(类似哈希表)存储所有数据的过期时间

- key：存储数据的 key
- value：longlong 类型的 Unix 时间戳

![redis过期字典](https://oss.javaguide.cn/github/javaguide/database/redis/redis-expired-dictionary.png)

删除策略：key 存活时间到期时如何删除

- 惰性删除：只有 key 被请求时才进行过期检查，对 CPU 友好，但可能堆积大量未删除数据
- 定期删除：定时抽取部分 key 进行过期检查并删除，Redis 底层会限制删除操作执行的时长和频率来保证不会占用过多 CPU 资源

#### 内存淘汰机制

仅使用惰性删除 + 定期删除的策略仍可能导致大量未删除数据的堆积(海量数据情况下)，从而浪费大量内存空间，故需要内存淘汰机制主动将权重较低的数据清除(即使未到期)：

- volatile 从已设置过期时间的数据集中选取
  - LRU：最近最少用到的数据
  - TTL：最快要过期的数据
  - RANDOM：随机选取淘汰数据
  - LFU：最近最不常用的数据，Redis 4.0 引入
- allkeys：内存不足以容纳新写入数据时
  - LRU
  - RANDOM
  - no-eviction：不允许淘汰数据，内存不足时直接报错
  - LFU

### 事务

==Redis 事务不同于关系型数据库事务==，只提供将多个命令请求打包，再按顺序执行打包的所有命令，且中途不会被打断的功能

Redis 事务不满足原子性和持久性，且事务中的每条命令都会与 Redis 服务器进行网络交互，浪费大量资源(一次批量执行也能达到相同效果)

- 不支持原子性：Redis 事务不支持回滚，开发者认为回滚操作会增加复杂性且影响性能，命令执行错误应该在开发过程而非生产过程发现
- 不满足原子性的情况下自然不能满足持久性，且 Redis 的持久化方案(RDB/AOF)也不能完全保证数据一致性( RDB 生成快照/AOF 写回磁盘前崩溃)

利用 Lua 脚本批量执行多条 Redis 命令：

- 一段 Lua 脚本执行过程中不会有其他脚本/命令同时执行
- Lua 脚本批量执行只需要一次网络交互

但 Lua 脚本不会提供回滚功能，即仍不能保证原子性

### 性能优化

主要从网络 IO 层面进行优化

Redis 命令的执行流程：

1. 客户端发送命令
2. 命令排队
3. 命令执行
4. 返回结果

#### 批量操作减少网络传输

从发送命令与返回结果耗费的时间之和为 RTT(往返时间)，即数据在网络传输的时间

通过将多个命令合并成一次批量操作可以==减少网络传输时间==，减小网络通信开销

批量操作也能==减少 socket I/O 成本==(涉及上下文切换，read/write 系统调用)

实现：

- 原生批量操作命令(原子操作)：Redis 提供的原生批量操作命令能够实现批量操作，但在分片集群的场景仍可能需要多次网络传输
  - 无法保证所有 key 在同一个 hash slot(哈希槽)，需要手动维护 key 与 hash slot 之间的关系

- pipeline：对于不支持批量操作的命令，可以使用 pipeline 封装后一次性提交到 Redis 服务器，需要控制封装大小，且在分片集群场景也需要手动维护 key 与 hash slot 的关系
  - 无法保证命令执行的顺序
- Lua 脚本：一段 Lua 脚本可以视作一条命令执行(原子操作)，且 Lua 脚本支持简单的逻辑处理
  - 没有实现回滚，只能保证错误后不再继续执行，已经执行的写操作不会撤回
  - 分片集群场景无法保证原子性，即需要手动维护 key 与 hash slot 的关系

#### 大量 key 集中过期

定期删除由主线程执行，即删除期间会阻塞客户端请求，若大量 key 同时过期，则会耗费大量时间进行清理

- 随机过期时间
- lazy-free：Redis 4.0 引入，开启子线程进行键值对的回收

#### Redis bigkey

bigkey 即一个 key 对应的 value 占用大量空间(1 MB/5000 个元素)，bigkey 的产生多为设计不当：

- String 存储二进制文件
- 业务数据规模考虑不周，集合类型快速增长
- 未及时清理垃圾数据，哈希表中冗余大量无用数据

bigkey 会耗费大量内存空间和带宽，造成阻塞问题：处理 bigkey 时需要大量时间，且 bigkey 会影响主从同步和集群扩容

- 客户端超时阻塞：单线程执行命令耗时长且阻塞响应，即客户端长时间得不到响应
- 网络阻塞：bigkey 在网络传输需要花费更多时间和带宽
- 工作线程阻塞：删除 bigkey 会造成长时间阻塞

定位 bigkey：

- --bigkeys 参数：扫描 Redis 中的所有 key，影响性能，且只能找到占用内存最大的 String 与包含元素最多的复合数据类型
- SCAN 命令：按照一定的模式和数量返回匹配的 key
- 第三方工具：通过第三方工具分析 RDB 文件中的 bigkey
- 公有云的 Redis 分析服务

处理 bigkey：

- 分割：将 bigkey 分割为若干个小 key
  - Hash 通过二次哈希分割
- 手动删除：UNLINK 命令异步删除指定 key；SCAN + DEL 命令分批删除
- 优化数据结构：
  - String 存储文件路径
  - HyperLogLog 存储网站 UV
  - Bitmap 保存状态
- 开启 lazy-free

#### Redis hotkey

热点数据，对 hotkey 的访问量远大于其他 key

==hotkey 会成为 Redis 性能的瓶颈==，Redis 将大量资源用于处理 hotkey 的请求，影响其他 key 的正常处理，且若 hotkey 的请求量超出 Redis 的处理能力，Redis 崩溃，大量请求涌入数据库，导致数据库崩溃

定位 hotkey：

- --hotkeys 参数：返回所有 key 的访问次数(全表扫描)，要求开启 LFU 的内存淘汰机制
- MONITOR 命令：实时查看 Redis 的所有操作，性能影响大
  - 短暂开启，将输出写入文件，关闭后分析输出文件
- 第三方工具
- 根据业务情况预估
- 在业务代码中计数
- 公有云的 Redis 分析服务

解决 hotkey：

- 读写分离：主库执行写操作，多个从库分担读操作压力
- Redis Cluster：将热点数据分布在多个 Redis 集群
- 二级缓存：将 hotkey 备份至 JVM 本地内存中缓存(caffeine)，业务服务器直接返回缓存而不需要访问 Redis 服务器
- 公有云的解决方案

#### 慢查询

慢查询统计命令执行所花费的时间，筛选出耗时长的命令

Redis 中的命令大多为 O(1) 的时间复杂度，但也存在 O(n) 及以上的命令(列表排序、范围查询)，在全表扫描时耗时极长

定位慢查询：

- 慢查询日志：类似于 MySQL，Redis 会将执行时长超出阈值的命令记录在慢查询日志中，日志采用 FIFO 进行淘汰
  - SHOWLOG GET：获取慢日志内容

#### 内存碎片

- Redis 通过自身实现的 zmalloc 函数为数据分配内存空间时，会分配额外的空间(PREFIX_SIZE)
  - ==Redis 的内存分配器只能分配固定大小的内存==
- 数据修改时，==Redis 不会轻易将由此空出的内存空间释放==，减少 Redis 向操作系统请求内存的次数

清理碎片：

- Redis 4.0 后自带的内存碎片清理机制，可能影响性能

```bash
# 内存碎片占用空间达到 500mb 的时候开始清理
config set active-defrag-ignore-bytes 500mb
# 内存碎片率大于 1.5 的时候开始清理
config set active-defrag-threshold-lower 50
```

- 通过重启节点整理内存碎片：在高可用架构的 Redis 集群中，将碎片率过高的节点转换为从节点进行安全重启

### Redis 生产问题

#### 缓存穿透

==大量请求穿过缓存直接到达关系型数据库，导致关系型数据库压力过大==

==非法请求的 key 既不存在于 Redis，也不存在于关系型数据库中==，故即使在数据库中查询过后也不会写回到缓存，导致此类请求一直由数据库处理

解决方案：首先要对请求参数进行校验，初步过滤一部分非法请求(参数范围、格式)，直接在业务层返回报错

- 缓存无效 key：当数据库中查询不到相关的 key 时，也将其写回到缓存中，并设置较短的过期时间，仅适用于请求的 key 变化不频繁的情况
  - 当恶意攻击构造大量不同的无效请求时，导致缓存空间被大量的无效 key 占用
- 布隆过滤器：布隆过滤器使用类似位数组的结构，将数据的哈希值进行存储，其判断的结果只有必定不存在与可能存在，且可能存在的误差随元素的增大而增大
  - 将所有可能的请求值存储于布隆过滤器中，若判断请求不存在则直接返回报错

![加入布隆过滤器之后的缓存处理流程图](https://oss.javaguide.cn/github/javaguide/database/redis/redis-cache-penetration-bloom-filter.png)

- 接口限流

#### 缓存击穿

==hotkey 失效(到期、更新操作删除缓存)，导致大量请求直接到达数据库==

==请求的 key 不存在于缓存，但存在于数据库==

解决方案：

- 延长 hotkey 过期时间
- 预热
- 为数据库中的热点数据加锁，保证删除缓存到写入缓存期间只有一个请求到达数据库

#### 缓存雪崩

==缓存中的 key 大规模同时失效，导致大量请求涌入数据库==

解决方案：

- Redis 不可用情况：
  - Redis Cluster：使用集群避免单机失效导致服务不可用
  - 限流：大规模失效时限制请求数量以减轻数据库压力
  - 多级缓存：将部分数据缓存至 JVM 本地内存
- 数据失效情况：
  - 随机过期时间
  - 预热

##### 缓存预热

- 定时任务：定时触发缓存预热逻辑，将热点数据写入缓存
  - xxl-job
- 消息队列：将数据库中的热点数据的主键/Id 发送到消息队列，由缓存服务消费消息队列中的数据，根据主键/Id 查询数据库并更新缓存
  - 异步方式进行预热

#### 缓存数据一致性

需要权衡维护数据一致性造成的开销与开发维护的难度

要保持缓存与数据库的一致性，需要保证写操作的同步：

更新 + 更新：在并发情况下可能导致后写入的被之前的覆盖(写入数据库和写入缓存存在时间差)

- 先写数据库，再更新缓存：
  - 缓存更新失败，需要等待缓存过期失效后才能再次更新
- 先写缓存，再更新数据库：
  - 数据库更新失败导致不一致
  - 缓存失效导致无法写入数据库

更新 + 删除：由于缓存未命中时会写回缓存，在并发情况下会造成不一致，但由于删除缓存的速度极快(只需要调用相关命令 O(1))

- 先更新数据库，再删除缓存：
  - 线程 A 读取数据库后，线程 B 修改数据库并写入缓存，线程 A 再使用旧数据覆盖
  - 缓存删除失败
- 先删除，后更新数据库：
  - 线程 A 删除缓存，线程 B 从数据库获取旧数据，线程 A 写入缓存，线程 B 使用旧数据覆盖
  - 数据库更新失败

解决以上两种方案第二步失败的情况：

- 同步重试：执行失败后一直重试
  - 立即重试较大概率失败
  - 重试次数
  - 重试会阻塞线程，无法服务其他请求
- 异步重试：将重试请求写入消息队列，由专门的消费者进行重试
  - 需要处理写入消息队列失败的情况，增加维护成本
    - 同时失败概率较小，且消息队列可以重用
  - 重试成功前项目重启，即重试请求丢失，导致数据不一致
    - 消息队列保证可靠性，消息成功消费前不会丢失
- 订阅模式：利用数据库的 binlog 进行类似主从同步的操作
  - MySQL 的 binlog 保证可靠性，即写操作成功则一定会记录在 binlog
  - 第三方工具实现 binlog 自动投递到下游消息队列(canal)

#### Redis 阻塞

- O(n) 命令：时间复杂度高的命令耗时较长，会长时间占用执行的主线程，导致客户端阻塞
  - 限定命令的 N 值，避免全表扫描
- SAVE 创建 RDB 快照：同步保存操作，阻塞主线程
  - 使用 bgsave 命令，fork 子线程进行保存操作
- AOF：
  - 日志记录阻塞：AOF 在当前命令执行完后写入系统内核缓存，不会阻塞当前命令，但可能==阻塞下一条命令==
  - 磁盘阻塞：fsync 强制将系统内核缓存区的数据写入磁盘，当==磁盘压力太大时会阻塞 fsync 指令==，导致主线程调用 write 指令写入系统内核缓冲区阻塞
  - 重写阻塞：AOF 文件重写时会将重写期间的写操作记录在 Redis 维护的重写缓冲区，==当子线程重写完毕后将缓冲区内存加入 AOF 文件==，此时会产生阻塞
- bigkey：key 对应的 value 大小超过 1MB 或集合元素超过 5000 个时为 bigkey，由于占用内存较大，导致处理时间长、网络运输时间长、删除回收时间长，造成阻塞
  - 删除 bigkey 后，==操作系统需要将释放的内存插入空闲内存块的链表==，以便后续的管理和再分配，此时会阻塞当前释放内存的应用
- 清空数据库
- 集群扩容：节点的动态扩缩容为了保证迁移的一致性，所有操作都是同步操作，需要人工介入
  - 执行迁移时，两端的 Redis 均会进入时长不等的阻塞状态
- 内存交换(Swap)：类似虚拟内存，当内存空间不足时，将一部分数据转移到磁盘中，由于 Redis 基于内存，故 Swap 的性能影响极大
  - 预防：
    - 升级硬件
    - 限制实例的最大可用内存，避免内存不可控地增长(集合类型)
    - 降低 swap 优先级
- 网络阻塞：连接拒绝，网络延迟

### Redis 集群

### Redis 使用规范

- 避免频繁创建/关闭客户端连接
- 使用时间复杂度更低的命令，O(n) 的命令应限定 n 的范围
- 使用批量操作减少网络传输
- 避免使用 Redis 事务
- 禁止长时间开启 Monitor
- 控制 key 的过期时间

## MongoDB

基于**分布式文件存储**的 NoSQL 数据库，提供**面向文档**的存储方式，支持**无模式**的数据建模，可以存储复杂的数据类型

MongoDB 天然支持水平扩展和高可用，可以方便地添加更多节点/实例以保证服务性能和可用性

MongoDB 可以用于代替传统的关系型数据库或键值存储方式，为 Web 应用提供可扩展的高可用高性能数据存储解决方案 

### 存储结构

- 文档：基本单元，由 BSON(Binary JSON) 键值对组成，类似关系型数据库中的行
  - BSON 文档由键值对组成，字段值可以包括其他文档、数组、文档数组
- 集合：一个集合包含多个文档，类似关系型数据库中的表
  - 没有固定结构(无模式)
  - 不需要手动创建，当第一个文档插入或第一个索引创建时，会自动创建一个新的集合
- 数据库：一个数据库包含多个表

### 特点

- 数据基于文档存储：MongoDB 中的记录为一个 BSON 文档
- 无模式：集合不需要定义任何模式，能够用更少的数据对象表现复杂的领域模型
- 支持多种查询方式：CRUD、数据聚合、文本搜索、地理空间查询
- 支持事务：MongoDB 支持 ACID 事务
  - MongoDB 单文档原生支持原子性，也具备事务特性
  - MongoDB 4.0 加入多文档事务支持，但只支持复制集部署模式下的事务
  - MongoDB 4.2 引入分布式事务，增加对分片集群上多文档事务的支持
- 高效的二进制存储：Binary JSON
- 自带数据压缩功能：存储同样数据所需资源更少
- mapreduce：通过分治方式完成复杂的聚合任务
- 支持多种类型的索引：单字段索引、复合索引、多见索引、哈希索引、文本索引、地理位置索引
- failover：自动故障恢复，主节点故障时，自动将从节点升级为主节点
- 分片集群
- 大文件存储

### 应用场景

MongoDB 的优势在于数据模型与存储引擎的灵活性，架构的可扩展性，强大的索引支持

- BSON 保存数据能否满足业务需求
- 需要大数据量存储，快速水平扩展
- 需要更多类型的索引

### 存储引擎

MongoDB 采用插件式的存储引擎架构

- WiredTiger：适用于大多数工作负载，建议用于新部署
  - 使用 B+ 树作为存储结构(大多数 NoSQL 使用 LSM 树实现)，以 page 为单位进行磁盘 IO
- In-Memory：将文档存储在内存以获得更可预测的数据延迟

### MongoDB 聚合

聚合操作：将多个文档/集合汇总到一起计算分析并返回计算后的结果

- 将多个文档的值组合
- 对集合中的数据进行运算
- 分析数据随时间变化

MongoDB 提供的聚合方法：

- 聚合管道：由多个阶段组成，每个阶段在文档通过管道时转换文档，每个阶段接收前一个阶段的输出，进一步处理数据，并将其作为输入数据发送到下一个阶段

- 单一目的聚合方法：单一作用的聚合函数，count()、distinct()、estimateDocumentCount()

### MongoDB 事务

单文档原生支持原子性，且具备事务特性

多文档的事务支持在 MongoDB 4.0 引入，但存在限制，只支持复制集部署模式下的事务，集事务的作用域限制为一个副本集内

MongoDB 4.2 引入分布式事务的支持

### MongoDB 数据压缩

WiredTiger 使用 Snappy 压缩算法对所有集合使用块压缩，对所有索引使用前缀压缩