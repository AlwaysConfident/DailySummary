# 计算机网络

## 网络分层模型

网络分层：

- 相互独立：各层之间不需要关心其他层如何实现，只需要调用相关功能(接口调用)
- 灵活性：各层独立，改变一层的内部实现不会影响其他层的功能(高内聚，低耦合)
- 解决问题：分层便于定位问题的所在，且只需要修改出现问题的层

### OSI 七层模型

- 应用层：为用户提供服务
- 表示层：数据处理(编解码，加解密，加解压)
- 会话层：管理应用程序间的会话
- 传输层：为两台主机通信提供通用的数据传输服务
- 网络层：路由与寻址
- 链路层：帧编码和误差纠正控制
- 物理层：传输比特流

![osi七层模型2](https://oss.javaguide.cn/github/javaguide/osi七层模型2.png)

七层模型的理论完备，实现复杂且不实用(有些功能在多个层中重复出现)



### TCP/IP 四层模型

- 应用层：为用户提供服务
- 传输层：管理两台主机之间的通信
- 网络层：帧编码与误差控制
- 物理链路层：传输比特流

![TCP/IP 四层模型](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-ip-4-model.png)

#### 应用层

应用层用于**为两台终端的应用程序提供通信服务**，定义了**交互的信息格式(报文)**，再通过传输层进行传输

协议：

- HTTP：超文本传输协议，基于 TCP，用于传输超文本和多媒体内容

  - 客户端发起 HTTP Request，服务端响应 HTTP Response
  - HTTP 1.1 协议默认 Keep-Alive，即建立一次连接后可以重复使用，之后的请求无需再次建立
  - HTTP 协议是无状态的，故需要使用 Cookie/Token 等手段记录访问的客户状态(登录、购物车)

- Websocket：全双工通信协议，基于 TCP，客户端与服务器可以同时发送和接收数据，用于弥补 HTTP 协议无法建立持久连接的不足

  - Websocket 只需要一次握手就可以建立连接

    ![](![Websocket 示意图](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b1b07779d35f4d33afa13e23e0baeba2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

    1. 客户端向服务器发送升级为 Websocket 连接的请求
    2. 若服务器支持 Websocket，则返回带有相关头的响应
    3. 客户端与服务器可以通过帧通信，数据被分为若干个数据帧发送，接收方再将其重组
    4. 连接建立后通过心跳机制确保通信双方都存活，保证连接的稳定性和活跃性
    5. 双方都可以发送一个结束帧表示结束此次连接，收到结束帧的一方也会返回关闭帧，然后关闭 TCP 连接

  - Websocket 实现实时消息推送：

    - 后端注册为 Websocket 服务器
    - 前端连接后持续监听事件

  - Websocket vs HTTP：

    - 双向 vs 单向
    - ws:// wss:// vs http:// https://
    - Websocket 支持扩展，用户可以扩展协议，实现部分自定义的子协议(压缩、加密)
    - WebSocket 通信数据格式比价轻量，用于协议控制的数据包头部较小；HTTP 通信每次都要携带完整的头部

  - Websocket vs SSE(Server Send Event)：主要出于单/双向、传输内容来决定选择

    - SSE 基于 HTTP 协议，无需额外引入；Websocket 需要单独的服务器处理协议
    - 单向 vs 双向
    - SSE 实现简单，开发成本低；Websocket 传输数据需要二次解析
    - SSE 默认支持断线重连；Websocket 需要扩展
    - SSE 只能传输文本数据，二进制数据需要编码后传输；Websocket 默认支持二进制数据传输

- SMTP：简单邮件发送协议，基于 TCP，用于向邮件服务器发送邮件，且只负责发送而不能接受

  1. 通过 SMTP 协议将写好的邮件交给发送方对应的 SMTP 服务器
  2. 发送方服务器通过域名转发给对应的接收方 SMTP 服务器
  3. 接收方服务器判断目标地址是否有效
  4. 接收方服务器通知接收邮件

- POP3/IMAP：邮件接收协议，基于 TCP

- FTP：文件传输协议，基于 TCP，可以屏蔽操作系统与文件存储方式，在两台终端之间传输文件，SFTP 是 FTP 的安全版本，会对传输过程对数据加密

  - FTP 在两台终端建立两条 TCP 连接，一条用于传送控制信息，一条用于数据传送

- Telnet：远程登录协议，基于 TCP，用于通过一个终端登录到其他服务器，由于登录过程的所有数据(账号密码)都是明文传输，故已被更安全的 SSH 淘汰

- SSH：安全网络传输协议，基于 TCP，通过加密和认证机制实现安全的访问和文件传输等业务

- RTP：实时传输协议，基于 UDP，也支持 TCP，提供 P2P 实时传输数据的功能，但不包含资源预留存，不保证实时传输质量

- DNS：域名管理系统，基于 UDP，用于解决域名与 IP 的映射问题

#### 传输层

传输层负责为两台终端的进程间提供通用的通信协议

- TCP：面向连接、可靠
- UDP：无连接、不可靠、简单高效

#### 网络层

网络层负责两台终端之间的通信，将传输层的报文进行封装成分组和包，再通过路由转发到对应的终端

- IP：定义数据包格式、对数据包进行路由和寻址，以便能够正确地传播到目标地址
- ARP：Address Resolution Protocol，地址解析协议，解决网络层与链路层的差异(网络层使用逻辑地址 IP，链路层使用物理地址 MAC)
- ICMP：Internet Control Message Protocol，网络控制报文协议，用于传输网络状态和错误消息的协议
- NAT：Network Address Table，网络地址转换协议，用于转换内网与外网的地址，如在 LAN 内各主机使用内网地址，在 WAN 中需要统一的 IP 地址标识 LAN 在 Internet 上的位置
- OSPF：Open Shortest Path First，开放式最短路径优先，广泛使用的动态路由协议，考虑了链路带宽、延迟等
- RIP：动态路由协议，只考虑路由路径的跳数
- BGP：动态路由协议，用于在路由选择域之间交换网络层可达性信息

#### 网络接口层

包含链路层与物理层

- 链路层：将 IP 数据包封装成帧，在两个相邻节点间的链路上传送帧，每一帧包括数据和控制信息(同步信息，地址信息，差错控制)
- 物理层：实现相邻计算机节点之间比特流的透明传送

## 访问网页流程

1. 浏览器输入网站 URL
2. 通过 DNS 将域名解析为 IP 地址
3. 通过 IP + 端口向服务器请求建立 TCP 连接
4. 向服务器发送 HTTP 请求
5. 服务器将页面的 HTML 代码与相关资源封装到 HTTP 响应中返回
6. 浏览器解析 HTML
7. 关闭时客户端发送 HTTP 关闭请求

### URL

Uniform Resource Link，统一资源定位器，类似于文件路径，通过 URL 可以访问对应的网络资源，一个 URL 对应一个网络资源，一个网络资源可以通过重定向由多个 URL 指向

- 协议：HTTP/HTTPS/FTP
- 域名：IP 地址的别名，便于记忆
- 端口：指定的访问端口
- 资源路径：
- 参数
- 锚点

#### URL vs URI

- URI：统一资源标志符，可以唯一标识一个资源

- URL：统一资源定位符，提供资源的路径，是一种具体的 URI，即 URL 标识资源的同时提供了访问路径

### DNS

基于 UDP 的应用层协议，用于解决 IP 与域名的映射关系，host 表中存在对应关系时不需要通过 DNS 解析

DNS 服务器自下而上分为四个层级：

- 根服务器：提供顶域服务器的 IP 地址
- 顶域服务器：顶域指域名的后缀(com/edu/org/cn)，提供权威服务器的 IP 地址
- 权威服务器：在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的 DNS 记录，这些记录将主机名映射为 IP 地址
- 本地服务器：由 ISP 提供的 DNS 服务器，主机发出 DNS 请求时首先由本地服务器代理转发到 DNS 层次结构中，严格上不属于 DNS 层级结构

#### 工作流程

迭代式：

![](https://oss.javaguide.cn/github/javaguide/cs-basics/network/DNS-process.png)

1. 主机 --(DNS 请求)--> 本地 DNS 服务器
2. 本地服务器检查缓存，若存在则之间返回，否则请求根服务器
3. 根服务器由顶域将对应的顶域服务器 IP 地址返回给本地服务器
4. 本地服务器请求返回的顶域服务器
5. 顶域服务器由域名前缀将对应的权威服务器 IP 地址返回给本地服务器
6. 本地服务器请求返回的权威服务器
7. 权威服务器将备案过的域名 IP 地址返回
8. 本地服务器将获取的 IP 地址返回给主机

递归式：

![](![](https://oss.javaguide.cn/github/javaguide/cs-basics/network/DNS-process2.png))

与迭代式的不同之处在于请求会 DNS 体系内直到确认对应的 IP 地址是否存在后才逐级返回至本地服务器

#### DNS 劫持

DNS 劫持是一种网络攻击，通过修改 DNS 服务器的解析结果，使用户访问的域名指向错误的 IP 地址，导致用户无法访问正常的网站或被引导到恶意网站

DNS 劫持方法：

- 利用 DNS 服务器进行 DDoS 攻击：攻击者得到被攻击者的 IP 地址，对其 DNS 服务器发送大量解析请求，这些请求最终会返回给被攻击者，导致被攻击者的网络被拖垮至中断。由于攻击者没有直接与被攻击者通讯，故难以追查原始的攻击者
- DNS 缓存感染：攻击者使用 DNS 请求将数据放入一个具有漏洞的 DNS 服务器的缓存中，这些缓存信息会在用户进行 DNS 访问时返回，从而把用户对正常域名的访问引导至恶意网站
- DNS 信息劫持：攻击者通过监听客户端和 DNS 服务器的对话，可以猜测服务器响应给客户端的 DNS 查询 Id(DNS 通过 DNS 报文的 16 位 Id 号获取请求源位置)，攻击者在 DNS 服务器之前将虚假的响应交给用户，从而引导用户访问恶意网站
- DNS 重定向：攻击者将 DNS 名称查询重定向到恶意 DNS 服务器上，被劫持域名的解析就完全由攻击者控制

预防：

- 绕过运营商的 DNS，向具备 DNS 解析功能的 HTTP WEB 服务器发起查询(直接向 DNS 发送更加安全的 HTTP 请求)
  - 核心业务向 HTTP DNS 发送请求
  - 非核心业务先尝试 LocalDNS，发生异常时走 HTTP DNS

## HTTP

- 基于 TCP 的应用层协议
- 用于传输超文本与多媒体资源
- 默认为 80 端口
- HTTP 1.1 默认开启 Keep-Alive，避免每次请求都要重新建立连接
- 无状态的协议，不维护任何客户端过去所发请求的信息(维护状态的开销大，且双方因为故障导致状态不一致时代价更高)，需要额外的 Cookie/Token 来记录客户端状态(登录、购物车)
- 扩展性强、速度快、跨平台

### HTTP 状态码

- 1xx：信息性状态码
- 2xx：成功状态码
  - 200：请求成功处理
  - 201：请求成功处理，且在服务器上创建了新的资源
  - 202：服务器收到请求，但未处理
  - 204：请求成功处理，但未返回任何内容
- 3xx：重定向状态码
  - 301：资源被永久重定向(网站的网址更换)
  - 302：资源被临时重定向
- 4xx：客户端错误状态码
  - 400：发送的请求存在问题(参数不合法、请求方法错误)
  - 401：请求未认证
  - 403：服务器拒绝请求，一般针对非法请求
  - 404：请求的资源不存在
  - 409：请求的资源与服务器当前状态冲突，无法处理请求
- 5xx：服务端错误状态码
  - 500：服务器出 bug，请求未正常处理
  - 502：网关将请求转发到服务器，服务器返回的式错误的响应
  - 504：请求超时

### HTTPS

- 基于 SSL/TLS 协议，SSL/TLS 基于 TCP
- 双方传输的数据采用对称加密，对称加密所用的密钥由服务器的证书进行非对称加密
- 安全性高、开销更大

#### SSL vs TLS 

两者没有太大区别，TLS 是基于 SSL 的升级版(SSL 3.0)

#### 非对称加密

- 发送方使用接收方的公钥对数据进行加密
- 接收方使用自己的私钥对数据进行解密

公钥只能加密，无法解密，只有私钥才能解密，公私钥的生成依赖单向陷门函数(只能由 a -> b，无法由 b -> a，但存在 x 能够得到 b -> a )

非对称加密的算法开销大，效率低

#### 对称加密

发送方与接收方使用相同的密钥对传输数据进行加解密

传输数据的保密性完全依赖于密钥的保密性，因此常使用非对称加密传输对称加密所用的密钥

#### 公钥传输问题

由于：

- 任何人可以捕获通信包
- 通信包的保密性由发送者设计
- 公钥加密算法是公开的

则存在客户 C，服务器 S，攻击者 A：

- C 向 S 发送获取公钥的请求
- A 拦截请求并使用自己的公钥 Pub_A 伪造响应
- C 得到 Pub_A 并以此加密数据发送给 S
- A 拦截发送的数据并用自己的 Pri_A 解密
  - 由于加密使用的是 Pub_A，故攻击者能够解密出客户端想要发送的数据，造成数据的泄漏

为此产生了权威的第三方证书颁发机构(CA)，HTTPS 请求会先验证公钥是否有 CA 认证，若有则表示此公钥为目标服务器的公钥，否则不能保证该公钥的合法性

CA 利用数字签名(散列 + 加密的组合技术)防止证书被伪造，客户端会通过 CA 的公钥解密服务器返回的证书，得到 CA 生成的摘要，对比客户端自己对获取到的服务器公钥进行散列得到的摘要，由此确定公钥的合法性

证书 = 服务器端的消息 + CA 私钥加密过的 CA 生成的散列

即：

- S 信任 CA，CA 已知 Pub_S，向 S 颁发证书并附上 CA 私钥对摘要的数字签名
- S 将证书返回给 C
- C 信任 CA 且得到 CA 公钥，使用 Pub_CA 对 S 证书上的签名解密，同时对消息进行散列处理得到摘要，对比解密得到的摘要与客户端对消息散列得到的摘要
- C 验证 S 证书真实则信任 S 的公钥

#### HTTP vs HTTPS

- 端口：HTTP 默认为 80；HTTPS 默认为 443
- 域名：http vs https
- 性能：HTTP 性能更好；HTTPS 为了保证安全性，存在算法开销与证书/密钥的传输
- 搜索引擎：搜索引擎倾向于返回 HTTPS 的结果

### HTTP 1.0 vs HTTP 1.1

- 状态码：HTTP 1.0 只有 16 种，HTTP 1.1 新增了 24 种
- 缓存处理：
  - HTTP 1.0：使用 Expired 标签标志一个响应体，在标志时间内的请求都会获得缓存，由 Last-Modified 标记被请求资源的最后一次修改。在请求头中使用 If-Modified-Since 表示在该时间后资源是否被修改，若未修改则返回 304 告知客户端缓存仍可用，否则返回 200 并附带更新后的资源
  - HTTP 1.1：在 1.0 的基础上引入了 Cache-Control 请求头，对缓存增加了更多细致的特性
- 连接方式：协议上的连接，真正实现需要客户端与服务器都支持长连接
  - HTTP 1.0：默认使用短连接，每次请求都需要新建连接，产生大量的握手与挥手报文占用带宽，可以使用 Connection: Keep-alive 开启长连接
  - HTTP 1.1：默认为长连接，建立连接后一直存在，可以使用 Connection: close 表示此为短连接
- Host 头处理：DNS 支持多个域名绑定到同一 IP
  - HTTP 1.0 的请求报文不会加入主机名，服务器端无法理解客户端想请求的真正网址
  - HTTP 1.1 中加入了 Host 字段，由此确定客户端想访问的网址
- 带宽优化：
  - HTTP 1.1 通过 Range 请求头实现范围请求，服务端可以只返回一部分数据，也可以忽略 Range，范围请求的返回状态码为 206，表示该响应不是一个完整的数据响应。Content-Range 头标识指示出该数据块的偏移量和数据库长度
  - HTTP 1.1 中引入 100 状态码，表示服务器不愿意响应某些较大的文件请求，进一步向客户端确认请求的必要性，若客户端确认需要则会正常返回
  - HTTP 1.1 提供了比 HTTP 1.0 更细致的压缩细节选择

### HTTP 1.1 vs HTTP 2.0

- 多路复用：HTTP 2.0 在同一连接上可以同时传输多个请求和响应，互不干扰，在处理多个请求时效率更高
- 二进制帧：HTTP 2.0 使用比 HTTP 1.1 的文本格式更高效的二进制帧进行数据传输，减少传输的数据量和带宽消耗
- 头部压缩：HTTP 2.0 支持 Header 压缩，HTTP 1.1 只能对 Body 压缩
- 服务器推送：HTTP 2.0 支持服务器在响应客户端时主动将相关资源一并返回，减少客户端请求次数；HTTP 1.1 只能由客户端逐个发起请求

### HTTP 2.0 vs HTTP 3.0

- 传输协议：HTTP 3.0 新增了 QUIC(Quick UDP Internet Connection) 协议实现可靠传输，提供与 SSL/TLS 相当的安全性，具有较低的连接和传输延迟
- 连接建立：HTTP 3.0 基于 QUIC，连接建立仅需要 0-RTT 或 1-RTT(TLS 1.3 支持 0-1 个 RTT 握手)，即 QUIC 在最佳情况下不需要任何额外往返时间即可建立新连接
- 队头阻塞：HTTP 2.0 在多路复用时，一旦发生丢包就会阻塞所有 HTTP 请求；HTTP 3.0 基于多路复用 + 轮询，在一个连接建立多个不同且独立的数据流
- 错误恢复：HTTP 3.0 在出现丢包、延迟等网络问题时能更快地进行恢复与重传；HTTP 2.0 基于 TCP 的错误恢复机制
- 安全性：HTTP 3.0 改为基于 QUIC 内置的加密和身份验证机制，提供更强的安全性

### HTTP 维护用户状态

利用 Session 机制，通过服务端为用户创建特定的 Session 来标识用户并跟踪

服务器保存 Session：

- 内存 + 数据库(redis)

#### Cookie vs Session

- Session 用于通过服务端记录用户的状态，通过 Session 标识与跟踪用户，Session保存在服务器，安全性更高
- Cookie 数据保存在客户端(浏览器)，不需要占用服务器资源

## TCP vs UDP

- 面向连接：TCP 需要先建立连接，结束后要释放连接；UDP 不需要建立连接
- 可靠：TCP 使用失败重传、拥塞控制、确认、窗口等机制保证数据传输的可靠性；UDP 只负责发送，不保证可靠，接收数据后不需要返回确认
- 维护状态：TCP 会记录通信双方的状态以保证数据传输的可靠性(数据是否已发送/已接收)，需要维护复杂的连接状态表；UDP 无连接故不需要维护状态
- 效率：TCP 存在建立连接、可靠性的开销；UDP 则只需要发送
- 传输形式：TCP 面向字节流(建立连接后双方发送字节流)；UDP 面向报文(直接发送报文)
- 首部开销：TCP 首部开销存在连接状态等(20-60 字节)；UDP 则不需要这么大(8 字节)
- 广播或多播：TCP 要求通信双方建立连接，故不支持广播或多播；UDP 没有连接的限制，可以任意对任意地发送
- 场景：TCP 用于对传输准确性高的场景(文件传输、远程连接、邮件)；UDP 用于对效率要求高、允许出现差错的场景(视频、语音、即时通讯)

### HTTP 与 TCP/UDP

HTTP 2.0 及之前是基于 TCP 的，HTTP 3.0 提供了基于 UDP 的 QUIC 协议实现

### 三次握手

1. 客户端向服务器发出连接请求
   - 服务器可以确认客户端能正常发送
2. 服务器响应建立连接的请求
   - 客户端可以确认服务器能正常发送与接收
3. 客户端响应收到连接已建立的请求
   - 服务器可以确认客户端能正常接收

三次握手能够确认通信双方都能正常发送与接收

### 四次挥手

1. 客户端发出释放连接请求
2. 服务器响应，表示开始释放，客户端进入半关闭状态
   - 客户端需要等待服务器处理剩余请求，无法直接关闭
3. 服务器处理完剩余的请求后向客户端发送请求关闭连接的请求
   - 服务器表示已经将所有请求处理完毕，可以真正关闭连接
4. 客户端收到后发送已收到的请求，服务器收到后真正关闭连接，客户端等待一段时间(2 * MSL，避免客户端发送的 ACK 丢失)后默认服务器已关闭连接
   - 客户端表示没有新的请求，可以真正关闭

四次挥手的期间连接都可以正常使用(传输数据)

### TCP 确保可靠性

- 基于数据块传输：应用数据被分割为 TCP 认为合适发送的数据块(报文段)
- 排序去重：通过对报文段的序列号对其进行排序，并丢弃重复的报文段(超时的包被重传，最后两个包都到达)
- 校验和：通过报文段的首部与数据的校验和确定报文段未被修改，否则直接丢弃
- 重传：接收方正常收到报文段后会发送 ACK 响应告知该报文段已被正确接收，否则发送方等待一定时间后为收到确认即重发
  - 超时重传：根据网络延迟动态调整超时时长，每个数据包都有相应的计时器。接收方收到乱序的包时不会返回 ACK，即客户端会重发从乱序开始的所有包
    - 服务器收到 6、7、8、9，缺失 5，但是不返回 ACK，客户端会重发 5、6、7、8、9
  - 快速重传：服务器收到乱序的包也会返回乱序起点的 ACK，客户端连续三次收到重复的 ACK 时会立即重发对应的包
    - 服务器收到 6、7、8、9，每次收到都响应 ACK = 5，客户端收到 3 个 ACK = 5 时重发 5
  - SACK：带选择确认的重传，在快速重传的基础上，返回最近收到的报文段的序列号范围
  - D-SACK：重复 SACK，在 SACK 的基础上，额外携带信息，告知发送方有哪些数据包自己重复接收了
- 流量控制：接收方维护一个缓存区(滑动窗口)，当缓存区满时表示发送数据的速率大于处理的速率，会告知发送方降低发送速率，否则会因为接收方直接丢弃放不下的包导致发送方不停重发

- 拥塞控制：发送方基于网络情况控制发送的速率，由发送方的拥塞窗口根据网络情况维护的值，即发送速率 = min(拥塞窗口，滑动窗口)

#### 流量控制

为了避免接收方缓存区已满，直接丢弃后续发送的包，导致发送方一直重传，接收方会根据滑动窗口情况告知发送方降低发送速率

发送窗口分为四部分：

- 已发送并确认
- 已发送未确认
- 可发送
- 不可发送

![TCP发送窗口结构](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-send-window.png)

接收窗口分为三部分：

- 已接受并确认
- 等待接收未确认
- 不可接受

![TCP接收窗口结构](https://oss.javaguide.cn/github/javaguide/cs-basics/network/tcp-receive-window.png)

接收窗口的大小根据接收方处理数据的速度动态调整

#### 拥塞控制

拥塞控制防止过多的数据注入到网络中，避免网络中的路由/链路过载

![TCP的拥塞控制](https://img-blog.csdnimg.cn/20190731184935595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNDMxNDA2,size_16,color_FFFFFF,t_70)

发送方需要维护一个拥塞窗口(cwnd)的状态变量，拥塞窗口大小取决于网络的拥塞程度且动态变化

拥塞控制的四种算法：

- 慢开始：由于当前网络状况未知，故从小到大逐渐增大拥塞窗口，探测网络阻塞情况
  - 每经过一个传播轮次，cwnd 加倍
- 拥塞避免：让拥塞窗口缓慢增大
  - 每经过一个往返时间 RTT，cwnd + 1
- 快重传：接收方收到乱序的包时会返回乱序起点的 ACK，当发送方连续收到三次 ACK 时会立即重发对应的包，而不需要等到超时后重发，从而增大网络吞吐量
- 快恢复：发送方通过快重传得知当前只是丢失了个别报文段，故还不需要使用慢开始算法从底层重新开始，而是执行快恢复算法
  - 将慢开始门限 ssthresh 值和拥塞窗口 cwnd 值调整为当前窗口的一半再执行拥塞避免算法

### ARQ

自动重传请求，OSI 中链路层与传输层的错误纠正协议之一，通过使用确认和超时机制在不可靠服务基础上建立可靠的数据传输，发送方在发送后一段时间内没有收到 ACK，则会重复发送到收到或超出次数为止

#### 等待停止 ARQ

每发完一个分组就停止发送，等待 ACK(设置定时器)，超时则重发

接收方收到重复分组时丢弃，但仍会发送 ACK(防止因 ACK 丢失或迟到而导致的重发)

#### 连续 ARQ

发送方维持一个发送窗口，位于发送窗口内的分组可以连续发送出去而不需要等待确认

接收方采用累计确认，对按序到达的最后一个分组发送确认，表示到此为止的分组都确认收到

- 信道利用率高，易于实现，ACK 丢失也不必重传
- 不能反映出正确收到所有分组信息，如：收到 1、2、4、5 时返回 ACK = 2，则会重发 3、4、5

## IP

定义数据包格式，对数据包进行路由和寻址，以便可以跨网络传播到正确的地址

每个接入互联网的设备/域都被分配一个 IP 地址，作为唯一标识符

### IPv4 vs IPv6

- 地址空间：IPv4 为 32 位；IPv6 为 128 位
- 无状态地址自动配置：主机可以直接通过根据接口标识和网络前缀生成全局唯一的 IPv6 地址，无需依赖 DHCP 服务器，简化了网络配置和管理
- NAT：IPv4 需要 NAT 来将 LAN 子网 IP 地址与 WAN 公网 IP 地址做映射；IPv6 中地址资源充足，可以为每台设备分配独立地址，故可以不使用 NAT
- 标头结构：IPv6 标头结构更加简化和高效，减少处理开销，提高网络性能
- 扩展头：允许在 IPv6 标头中添加不同的扩展头，用于实现不同类型的功能和选项
- ICMPv6：改进了 IPv4 中的 ICMP，如邻居发现、路径 MTU 发现等功能，提升了网络的可靠性和性能

### 获取客户端真实 IP

- 应用层：通过 X-Forwarded-For 请求头获取，简单方便
  - X-Forwarded-For 可以被伪造，无法保证真实性
  - X-Forwarded-For 会附带请求链中的所有代理服务器 IP 地址，故可能会有多个值
  - 只适用于 HTTP 和 SMTP 协议
- 传输层：
  - 利用 TCP Options 字段承载真实源 IP 信息，适用于任何基于 TCP 的协议，但需要对通信双方进行改造
  - 通过 Proxy Protocol 协议传递客户端 IP 和 Port 信息，可以利用 Nginx 或其他支持该协议的反向代理服务器来获取真实 IP 或在业务服务器解析真实 IP
- 网络层：隧道 + DSR 模式，适用于任何协议，但实现复杂且存在限制

### NAT

将私有 IP 地址(LAN)映射为公有 IP 地址(LAN)或反向映射，从而实现局域网内的多个设备通过单一公有 IP 地址访问互联网

不仅用于缓解 IPv4 地址紧张的情况，也可以将子网与公网隔离，公网的服务器不知道具体哪个客户端发出了请求，只能得到连接公网的路由器的 IP 地址

## ARP

地址解析协议，解决网络层地址(IP)和链路层地址(MAC)之间的转换

### MAC 地址

媒体访问控制地址，网络资源由 IP 地址标识，网络设备则由 MAC 地址唯一标识

MAC 地址长度为 6 字节，地址空间大小为 2^48，由 IEEE 统一管理与分配，理论上分配的 MAC 地址是永久的，前 24 bit 由 IEEE 统一管理，后 24 bit 由生产商管理

### 工作原理

每个网络设备都维护自己的 ARP 表，记录了其他网络设备的 IP-MAC 映射关系

- 同一局域网内的 MAC 寻址：主机 A 向主机 B 发送 IP 数据报，整个过程为广播问询，单播响应
  1. A 先查询自身的 ARP 表中是否有 B 的 IP-MAC 映射关系，若有则直接发送
  2. A 中没有 B 的映射关系，则打包一份 ARP 查询报文，广播到所在的局域网中
  3. 主机 C 收到 ARP 报文，但因为查询分组中的接收 IP 地址不是自身，故直接丢弃
  4. 主机 B 收到 ARP 报文，发现自己是接收方，则将自身的 ARP 表一并返回给 A
  5. A 收到响应，更新 ARP 表并开始发送数据
- 不同局域网内的 MAC 寻址：主机 A 与主机 B 处在不同的子网中，两个子网通过一台路由器连接
  1. A 通过目标 IP 地址得知 B 处于不同的子网，查询 ARP 表中是否存在能够转发到该子网的路由器接口的 MAC 地址
  2. A 构造 ARP 查询分组，得到路由器接口的响应，更新 ARP 表
  3. A 构造 IP 数据报(目标 IP 为 B)，封装成帧(目标地址为路由器接口)，发送到对应的路由器
  4. 路由器获取到帧，在自身的 ARP 表查询 B 的 IP-MAC 映射关系，若找到则直接返回
  5. 路由器未找到则广播轮询，等待 B 响应
  6. 路由器获取到 B 响应后返回给 A

## 网络攻击

### IP 欺骗

通过伪造某台具有特权或被信任的主机 IP，从而被识别为被伪造的主机

IP 伪造 DDoS：攻击者伪造合法用户的 IP，向服务器发送带有 RST 位的 TCP 数据段，服务器会误以为连接需要重置，则清空缓冲区中建立好的连接，此时原本的合法用户就需要再次建立连接才能发送请求。当伪造大量的 IP 时服务器就可能不会为合法用户服务

![IP 欺骗 DDoS 攻击](https://oss.javaguide.cn/p3-juejin/7547a145adf9404aa3a05f01f5ca2e32~tplv-k3u1fbpfcp-zoom-1.png)

#### 缓解

由于无法区分 IP 是否被伪造，故 IP 欺骗无法预防，只能采取措施组织伪造数据包渗透网络

入口过滤式防范欺骗的一种常用措施，通常在网络边缘设备上实施，用于检测传入的 IP 数据包并确定器源标头

### SYN Flood 洪水

最原始、经典的 DDoS 攻击，旨在消耗服务器资源，令其无法正常服务合法用户

利用 TCP 的三次握手机制，通过工具或大量僵尸主机向服务器发送海量的变源 IP 地址或变端口的 TCP SYN 报文，服务器响应了这些报文就会生成大量的半连接，耗费大量服务器资源

1. 攻击者发出 SYN 请求，要求建立 TCP 连接
2. 服务器响应并分配内核资源维护半连接状态，等待客户端响应
3. 攻击者不再回复，服务器一直处于等待连接完成的状态并会不断重发半连接状态的请求

#### 预防

预防 SYN Flood 的关键在于判断哪些连接请求来自于真实源，屏蔽非真实源的请求以保障正常的业务请求

- 直接攻击：攻击者不伪造 IP 地址，直接由单一源设备发起攻击。该方式易于定位与解决(直接阻止恶意系统的 IP 地址)
- 欺骗攻击：攻击者伪造发送的各个 SYN 数据包的 IP 地址，加大身份暴露难度。该方式难以检测，但仍可以通过数据包追根溯源，在 ISP 的帮助下会更易实现
- 分布式攻击(DDoS)：使用僵尸网络发起攻击，追溯源头的可能性很低

#### 缓解

- 扩展积压工作队列：增加操作系统允许的半开连接数量
- 回收最先创建的 TCP 半开连接：完全建立合法连接的时间低于恶意 SYN 数据包填充积压工作的时间时回收最先创建的半开连接，当攻击量增加或积压工作规模小于实际需求时无效(回收后立即被使用)
- SYN Cookie：服务器不使用内存维护半连接状态，而是创建 Cookie 随 SYN-ACK 响应，合法请求将 Cookie 发回服务器时重建 SYN 积压工作队列条目，虽然会损失一些 TCP 连接信息，但仍优于直接拒绝合法请求

### UDP Flood

将大量的 UDP 数据包发送到目标服务器，压倒设备的处理和响应能力，防火墙保护目标服务器也可能因 UDP 泛滥而耗尽，从而导致拒绝服务合法用户

服务器收到 UDP 数据包：

1. 检查监听对应端口的程序是否正在运行
2. 若没有程序能处理该数据包，则使用 ICMP 数据包响应，告知发送方目的地不可达

由于目标服务器利用资源检查并响应每个接收到的 UDP 数据包的结果，当收到大量 UDP 数据包时，目标的资源可能会快速耗尽，导致拒绝服务合法用户

#### 缓解

限制 ICMP 报文的响应速率，但也会导致合法的数据包可能被过滤

### HTTP Flood

利用 HTTP 请求使目标服务器不堪重负

- HTTP GET 攻击：多台终端相互协调，向目标服务器发送多个资源请求，目标被传入的请求和响应所淹没时，来自正常流量源的其他请求将被拒绝
- HTTP POST 攻击：POST 请求时，服务器可能需要处理表单数据、与数据库交互持久化修改的场景(提交表单)，其开销远大于发出 POST 请求的开销，利用相对资源消耗的差异，直接向目标服务发送许多 POST 请求，直到目标服务器的容量饱和并拒绝服务为止

#### 防护

HTTP Flood 的防护十分复杂，因为难以区分恶意与正常请求

- 对发出请求的设备进行质询，测试是否为机器
- Web 应用程序防火墙(WAF)

### DNS Flood

使用大量流量淹没某个域的 DNS 服务器，以尝试中断该域的 DNS 解析，使得合法用户无法访问

#### 防护

借助轻易获得的高带宽僵尸网络，攻击者现能针对大型组织发动攻击。除非被破坏的 IoT 设备得以更新或替换，否则抵御这些攻击的唯一方法是使用一个超大型、高度分布式的 DNS 系统，以便实时监测、吸收和阻止攻击流量。

### TCP 重置攻击

通过伪造 TCP 报文段，向通信的一方/双方发送断开连接的请求，从而使通信双方中断

正常情况下，客户端发现到达的报文段对于相关连接而言是不正确的，TCP 就会发送一个重置报文段，从而导致 TCP 连接的快速拆卸，TCP 重置攻击利用这一机制，向通信方发送伪造的重置报文段。由于组装和发送伪造的报文段需要时间，故该攻击只针对长连接

伪造 TCP 报文段并不困难，因为 TCP/IP 没有广泛采用的验证服务端身份的内置方法，客户端只能接收报文段

### 中间人攻击

攻击者与通信双方都建立独立的连接，并交换其收到的数据，使通信双方认为是在与对方进行私密的连接，但实际上整个会话都由攻击者控制

#### 预防

- 摘要算法
- 数字证书与签名